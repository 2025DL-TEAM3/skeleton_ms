===== Training started at 0 =====
Batch size: 2, LR: 3e-05, Epochs: 10
Steps per file: 50, Grad. accum: 4, Warmup rate: 0.1
Validation dataset loaded with 128 steps, using seed 42, max files 128, steps/file 1, batch size 8
Total validation batches: 16
Warmup steps: 3750, Total optimizer steps: 37500
[Epoch 1] step 0 loss 0.3287 lr 0.000000
[Epoch 1] step 100 loss 0.5973 lr 0.000000
[Epoch 1] step 200 loss 0.4126 lr 0.000000
[Epoch 1] step 300 loss 0.7721 lr 0.000001
[Epoch 1] step 400 loss 0.3951 lr 0.000001
[Epoch 1] step 500 loss 0.3037 lr 0.000001
[Epoch 1] step 600 loss 0.6577 lr 0.000001
[Epoch 1] step 700 loss 0.3589 lr 0.000001
[Epoch 1] step 800 loss 0.3021 lr 0.000002
[Epoch 1] step 900 loss 0.1452 lr 0.000002
[Epoch 1] step 1000 loss 0.1056 lr 0.000002
[Epoch 1] step 1100 loss 0.0872 lr 0.000002
[Epoch 1] step 1200 loss 0.1129 lr 0.000002
[Epoch 1] step 1300 loss 0.0995 lr 0.000003
[Epoch 1] step 1400 loss 0.0836 lr 0.000003
[Epoch 1] step 1500 loss 0.1283 lr 0.000003
[Epoch 1] step 1600 loss 0.1199 lr 0.000003
[Epoch 1] step 1700 loss 0.0694 lr 0.000003
[Epoch 1] step 1800 loss 0.0513 lr 0.000004
[Epoch 1] step 1900 loss 0.0640 lr 0.000004
[Epoch 1] step 2000 loss 0.0349 lr 0.000004
[Epoch 1] step 2100 loss 0.1339 lr 0.000004
[Epoch 1] step 2200 loss 0.1879 lr 0.000004
[Epoch 1] step 2300 loss 0.1357 lr 0.000005
[Epoch 1] step 2400 loss 0.0311 lr 0.000005
[Epoch 1] step 2500 loss 0.0406 lr 0.000005
[Epoch 1] step 2600 loss 0.1167 lr 0.000005
[Epoch 1] step 2700 loss 0.0967 lr 0.000005
[Epoch 1] step 2800 loss 0.1790 lr 0.000006
[Epoch 1] step 2900 loss 0.0252 lr 0.000006
[Epoch 1] step 3000 loss 0.1186 lr 0.000006
[Epoch 1] step 3100 loss 0.0454 lr 0.000006
[Epoch 1] step 3200 loss 0.0594 lr 0.000006
[Epoch 1] step 3300 loss 0.1053 lr 0.000007
[Epoch 1] step 3400 loss 0.1027 lr 0.000007
[Epoch 1] step 3500 loss 0.1631 lr 0.000007
[Epoch 1] step 3600 loss 0.2026 lr 0.000007
[Epoch 1] step 3700 loss 0.1170 lr 0.000007
[Epoch 1] step 3800 loss 0.0770 lr 0.000008
[Epoch 1] step 3900 loss 0.1339 lr 0.000008
[Epoch 1] step 4000 loss 0.0387 lr 0.000008
[Epoch 1] step 4100 loss 0.0795 lr 0.000008
[Epoch 1] step 4200 loss 0.0617 lr 0.000008
[Epoch 1] step 4300 loss 0.0499 lr 0.000009
[Epoch 1] step 4400 loss 0.0436 lr 0.000009
[Epoch 1] step 4500 loss 0.0290 lr 0.000009
[Epoch 1] step 4600 loss 0.0494 lr 0.000009
[Epoch 1] step 4700 loss 0.0453 lr 0.000009
[Epoch 1] step 4800 loss 0.0213 lr 0.000010
[Epoch 1] step 4900 loss 0.0678 lr 0.000010
[Validation] global_step 5000 loss 0.2362 accuracy 0.4258
Validation accuracy improved from 0.0000 to 0.4258, Validation loss improved from inf to 0.2362
[Epoch 1] step 5000 loss 0.0790 lr 0.000010
[Epoch 1] step 5100 loss 0.0822 lr 0.000010
[Epoch 1] step 5200 loss 0.0288 lr 0.000010
[Epoch 1] step 5300 loss 0.0642 lr 0.000011
[Epoch 1] step 5400 loss 0.0476 lr 0.000011
[Epoch 1] step 5500 loss 0.0197 lr 0.000011
[Epoch 1] step 5600 loss 0.0575 lr 0.000011
[Epoch 1] step 5700 loss 0.0850 lr 0.000011
[Epoch 1] step 5800 loss 0.0146 lr 0.000012
[Epoch 1] step 5900 loss 0.0642 lr 0.000012
[Epoch 1] step 6000 loss 0.0816 lr 0.000012
[Epoch 1] step 6100 loss 0.1047 lr 0.000012
[Epoch 1] step 6200 loss 0.1014 lr 0.000012
[Epoch 1] step 6300 loss 0.0050 lr 0.000013
[Epoch 1] step 6400 loss 0.1491 lr 0.000013
[Epoch 1] step 6500 loss 0.1572 lr 0.000013
[Epoch 1] step 6600 loss 0.0460 lr 0.000013
[Epoch 1] step 6700 loss 0.0336 lr 0.000013
[Epoch 1] step 6800 loss 0.0658 lr 0.000014
[Epoch 1] step 6900 loss 0.0452 lr 0.000014
[Epoch 1] step 7000 loss 0.1091 lr 0.000014
[Epoch 1] step 7100 loss 0.0281 lr 0.000014
[Epoch 1] step 7200 loss 0.0708 lr 0.000014
[Epoch 1] step 7300 loss 0.0111 lr 0.000015
[Epoch 1] step 7400 loss 0.1217 lr 0.000015
[Epoch 1] step 7500 loss 0.0492 lr 0.000015
[Epoch 1] step 7600 loss 0.0266 lr 0.000015
[Epoch 1] step 7700 loss 0.0431 lr 0.000015
[Epoch 1] step 7800 loss 0.0608 lr 0.000016
[Epoch 1] step 7900 loss 0.0573 lr 0.000016
[Epoch 1] step 8000 loss 0.0385 lr 0.000016
[Epoch 1] step 8100 loss 0.0584 lr 0.000016
[Epoch 1] step 8200 loss 0.0793 lr 0.000016
[Epoch 1] step 8300 loss 0.0364 lr 0.000017
[Epoch 1] step 8400 loss 0.1035 lr 0.000017
[Epoch 1] step 8500 loss 0.0374 lr 0.000017
[Epoch 1] step 8600 loss 0.0708 lr 0.000017
[Epoch 1] step 8700 loss 0.0386 lr 0.000017
[Epoch 1] step 8800 loss 0.0793 lr 0.000018
[Epoch 1] step 8900 loss 0.0716 lr 0.000018
[Epoch 1] step 9000 loss 0.1068 lr 0.000018
[Epoch 1] step 9100 loss 0.0161 lr 0.000018
[Epoch 1] step 9200 loss 0.0414 lr 0.000018
[Epoch 1] step 9300 loss 0.1000 lr 0.000019
[Epoch 1] step 9400 loss 0.0519 lr 0.000019
[Epoch 1] step 9500 loss 0.0263 lr 0.000019
[Epoch 1] step 9600 loss 0.0362 lr 0.000019
[Epoch 1] step 9700 loss 0.0925 lr 0.000019
[Epoch 1] step 9800 loss 0.0785 lr 0.000020
[Epoch 1] step 9900 loss 0.0570 lr 0.000020
[Validation] global_step 10000 loss 0.2035 accuracy 0.4180
Validation loss improved from 0.2362 to 0.2035
[Epoch 1] step 10000 loss 0.0860 lr 0.000020
[Epoch 1] step 10100 loss 0.0259 lr 0.000020
[Epoch 1] step 10200 loss 0.1284 lr 0.000020
[Epoch 1] step 10300 loss 0.0082 lr 0.000021
[Epoch 1] step 10400 loss 0.1029 lr 0.000021
[Epoch 1] step 10500 loss 0.0327 lr 0.000021
[Epoch 1] step 10600 loss 0.0246 lr 0.000021
[Epoch 1] step 10700 loss 0.0198 lr 0.000021
[Epoch 1] step 10800 loss 0.0267 lr 0.000022
[Epoch 1] step 10900 loss 0.1035 lr 0.000022
[Epoch 1] step 11000 loss 0.0339 lr 0.000022
[Epoch 1] step 11100 loss 0.0571 lr 0.000022
[Epoch 1] step 11200 loss 0.0498 lr 0.000022
[Epoch 1] step 11300 loss 0.1097 lr 0.000023
[Epoch 1] step 11400 loss 0.0319 lr 0.000023
[Epoch 1] step 11500 loss 0.0110 lr 0.000023
[Epoch 1] step 11600 loss 0.0494 lr 0.000023
[Epoch 1] step 11700 loss 0.0996 lr 0.000023
[Epoch 1] step 11800 loss 0.0894 lr 0.000024
[Epoch 1] step 11900 loss 0.0312 lr 0.000024
[Epoch 1] step 12000 loss 0.1104 lr 0.000024
[Epoch 1] step 12100 loss 0.0498 lr 0.000024
[Epoch 1] step 12200 loss 0.0507 lr 0.000024
[Epoch 1] step 12300 loss 0.0216 lr 0.000025
[Epoch 1] step 12400 loss 0.0197 lr 0.000025
[Epoch 1] step 12500 loss 0.0276 lr 0.000025
[Epoch 1] step 12600 loss 0.1174 lr 0.000025
[Epoch 1] step 12700 loss 0.0848 lr 0.000025
[Epoch 1] step 12800 loss 0.0455 lr 0.000026
[Epoch 1] step 12900 loss 0.0133 lr 0.000026
[Epoch 1] step 13000 loss 0.0626 lr 0.000026
[Epoch 1] step 13100 loss 0.0331 lr 0.000026
[Epoch 1] step 13200 loss 0.0319 lr 0.000026
[Epoch 1] step 13300 loss 0.0816 lr 0.000027
[Epoch 1] step 13400 loss 0.0310 lr 0.000027
[Epoch 1] step 13500 loss 0.0072 lr 0.000027
[Epoch 1] step 13600 loss 0.0433 lr 0.000027
[Epoch 1] step 13700 loss 0.0349 lr 0.000027
[Epoch 1] step 13800 loss 0.0148 lr 0.000028
[Epoch 1] step 13900 loss 0.1137 lr 0.000028
[Epoch 1] step 14000 loss 0.0175 lr 0.000028
[Epoch 1] step 14100 loss 0.0439 lr 0.000028
[Epoch 1] step 14200 loss 0.0438 lr 0.000028
[Epoch 1] step 14300 loss 0.0589 lr 0.000029
[Epoch 1] step 14400 loss 0.0643 lr 0.000029
[Epoch 1] step 14500 loss 0.1510 lr 0.000029
[Epoch 1] step 14600 loss 0.0436 lr 0.000029
[Epoch 1] step 14700 loss 0.0675 lr 0.000029
[Epoch 1] step 14800 loss 0.0421 lr 0.000030
[Epoch 1] step 14900 loss 0.0825 lr 0.000030
[Validation] global_step 15000 loss 0.2236 accuracy 0.4531
Validation accuracy improved from 0.4258 to 0.4531
Epoch 1 avg loss 0.0902
[Epoch 2] step 0 loss 0.0943 lr 0.000030
[Epoch 2] step 100 loss 0.0765 lr 0.000030
[Epoch 2] step 200 loss 0.0272 lr 0.000030
[Epoch 2] step 300 loss 0.0998 lr 0.000030
[Epoch 2] step 400 loss 0.2068 lr 0.000030
[Epoch 2] step 500 loss 0.1122 lr 0.000030
[Epoch 2] step 600 loss 0.1283 lr 0.000030
[Epoch 2] step 700 loss 0.0511 lr 0.000030
[Epoch 2] step 800 loss 0.1026 lr 0.000030
[Epoch 2] step 900 loss 0.0450 lr 0.000030
[Epoch 2] step 1000 loss 0.0416 lr 0.000030
[Epoch 2] step 1100 loss 0.0320 lr 0.000030
[Epoch 2] step 1200 loss 0.0825 lr 0.000030
[Epoch 2] step 1300 loss 0.0428 lr 0.000030
[Epoch 2] step 1400 loss 0.0300 lr 0.000030
[Epoch 2] step 1500 loss 0.1264 lr 0.000030
[Epoch 2] step 1600 loss 0.0684 lr 0.000030
[Epoch 2] step 1700 loss 0.1485 lr 0.000030
[Epoch 2] step 1800 loss 0.0349 lr 0.000030
[Epoch 2] step 1900 loss 0.1138 lr 0.000030
[Epoch 2] step 2000 loss 0.1161 lr 0.000030
[Epoch 2] step 2100 loss 0.1002 lr 0.000030
[Epoch 2] step 2200 loss 0.0584 lr 0.000030
[Epoch 2] step 2300 loss 0.0215 lr 0.000029
[Epoch 2] step 2400 loss 0.0494 lr 0.000029
[Epoch 2] step 2500 loss 0.0243 lr 0.000029
[Epoch 2] step 2600 loss 0.0787 lr 0.000029
[Epoch 2] step 2700 loss 0.1207 lr 0.000029
[Epoch 2] step 2800 loss 0.0717 lr 0.000029
[Epoch 2] step 2900 loss 0.0320 lr 0.000029
[Epoch 2] step 3000 loss 0.0620 lr 0.000029
[Epoch 2] step 3100 loss 0.0228 lr 0.000029
[Epoch 2] step 3200 loss 0.0115 lr 0.000029
[Epoch 2] step 3300 loss 0.0225 lr 0.000029
[Epoch 2] step 3400 loss 0.0443 lr 0.000029
[Epoch 2] step 3500 loss 0.0725 lr 0.000029
[Epoch 2] step 3600 loss 0.0480 lr 0.000029
[Epoch 2] step 3700 loss 0.0287 lr 0.000029
[Epoch 2] step 3800 loss 0.0217 lr 0.000029
[Epoch 2] step 3900 loss 0.2408 lr 0.000029
[Epoch 2] step 4000 loss 0.0347 lr 0.000029
[Epoch 2] step 4100 loss 0.0621 lr 0.000029
[Epoch 2] step 4200 loss 0.0427 lr 0.000029
[Epoch 2] step 4300 loss 0.1531 lr 0.000029
[Epoch 2] step 4400 loss 0.0032 lr 0.000029
[Epoch 2] step 4500 loss 0.0495 lr 0.000029
[Epoch 2] step 4600 loss 0.1032 lr 0.000029
[Epoch 2] step 4700 loss 0.0438 lr 0.000029
[Epoch 2] step 4800 loss 0.0335 lr 0.000029
[Epoch 2] step 4900 loss 0.0227 lr 0.000029
[Validation] global_step 20000 loss 0.2274 accuracy 0.4414
Validation metrics did not improve. Patience: 1/10
[Epoch 2] step 5000 loss 0.1046 lr 0.000029
[Epoch 2] step 5100 loss 0.0614 lr 0.000029
[Epoch 2] step 5200 loss 0.0818 lr 0.000029
[Epoch 2] step 5300 loss 0.0380 lr 0.000029
[Epoch 2] step 5400 loss 0.0575 lr 0.000029
[Epoch 2] step 5500 loss 0.0504 lr 0.000029
[Epoch 2] step 5600 loss 0.0193 lr 0.000029
[Epoch 2] step 5700 loss 0.0957 lr 0.000029
[Epoch 2] step 5800 loss 0.0796 lr 0.000029
[Epoch 2] step 5900 loss 0.0422 lr 0.000029
[Epoch 2] step 6000 loss 0.0292 lr 0.000029
[Epoch 2] step 6100 loss 0.0793 lr 0.000029
[Epoch 2] step 6200 loss 0.0640 lr 0.000029
[Epoch 2] step 6300 loss 0.0539 lr 0.000029
[Epoch 2] step 6400 loss 0.0571 lr 0.000029
[Epoch 2] step 6500 loss 0.0255 lr 0.000029
[Epoch 2] step 6600 loss 0.0724 lr 0.000029
[Epoch 2] step 6700 loss 0.0363 lr 0.000029
[Epoch 2] step 6800 loss 0.0972 lr 0.000028
[Epoch 2] step 6900 loss 0.0395 lr 0.000028
[Epoch 2] step 7000 loss 0.0975 lr 0.000028
[Epoch 2] step 7100 loss 0.1366 lr 0.000028
[Epoch 2] step 7200 loss 0.0560 lr 0.000028
[Epoch 2] step 7300 loss 0.0324 lr 0.000028
[Epoch 2] step 7400 loss 0.0771 lr 0.000028
[Epoch 2] step 7500 loss 0.0655 lr 0.000028
[Epoch 2] step 7600 loss 0.0831 lr 0.000028
[Epoch 2] step 7700 loss 0.0345 lr 0.000028
[Epoch 2] step 7800 loss 0.0019 lr 0.000028
[Epoch 2] step 7900 loss 0.0051 lr 0.000028
[Epoch 2] step 8000 loss 0.1015 lr 0.000028
[Epoch 2] step 8100 loss 0.0406 lr 0.000028
[Epoch 2] step 8200 loss 0.0244 lr 0.000028
[Epoch 2] step 8300 loss 0.1794 lr 0.000028
[Epoch 2] step 8400 loss 0.0851 lr 0.000028
[Epoch 2] step 8500 loss 0.0941 lr 0.000028
[Epoch 2] step 8600 loss 0.0482 lr 0.000028
[Epoch 2] step 8700 loss 0.0694 lr 0.000028
[Epoch 2] step 8800 loss 0.0262 lr 0.000028
[Epoch 2] step 8900 loss 0.1419 lr 0.000028
[Epoch 2] step 9000 loss 0.0718 lr 0.000028
[Epoch 2] step 9100 loss 0.0781 lr 0.000028
[Epoch 2] step 9200 loss 0.0292 lr 0.000028
[Epoch 2] step 9300 loss 0.0151 lr 0.000028
[Epoch 2] step 9400 loss 0.0808 lr 0.000028
[Epoch 2] step 9500 loss 0.0675 lr 0.000028
[Epoch 2] step 9600 loss 0.0107 lr 0.000028
[Epoch 2] step 9700 loss 0.0279 lr 0.000028
[Epoch 2] step 9800 loss 0.0403 lr 0.000028
[Epoch 2] step 9900 loss 0.1108 lr 0.000028
[Validation] global_step 25000 loss 0.2605 accuracy 0.4492
Validation metrics did not improve. Patience: 2/10
[Epoch 2] step 10000 loss 0.0160 lr 0.000028
[Epoch 2] step 10100 loss 0.0134 lr 0.000028
[Epoch 2] step 10200 loss 0.0693 lr 0.000028
[Epoch 2] step 10300 loss 0.0974 lr 0.000028
[Epoch 2] step 10400 loss 0.0648 lr 0.000028
[Epoch 2] step 10500 loss 0.0146 lr 0.000028
[Epoch 2] step 10600 loss 0.0298 lr 0.000028
[Epoch 2] step 10700 loss 0.2096 lr 0.000028
[Epoch 2] step 10800 loss 0.0525 lr 0.000028
[Epoch 2] step 10900 loss 0.0826 lr 0.000028
[Epoch 2] step 11000 loss 0.0142 lr 0.000028
[Epoch 2] step 11100 loss 0.0823 lr 0.000028
[Epoch 2] step 11200 loss 0.1073 lr 0.000028
[Epoch 2] step 11300 loss 0.0952 lr 0.000027
[Epoch 2] step 11400 loss 0.0301 lr 0.000027
[Epoch 2] step 11500 loss 0.0774 lr 0.000027
[Epoch 2] step 11600 loss 0.0088 lr 0.000027
[Epoch 2] step 11700 loss 0.0690 lr 0.000027
[Epoch 2] step 11800 loss 0.0702 lr 0.000027
[Epoch 2] step 11900 loss 0.1002 lr 0.000027
[Epoch 2] step 12000 loss 0.0216 lr 0.000027
[Epoch 2] step 12100 loss 0.0711 lr 0.000027
[Epoch 2] step 12200 loss 0.0378 lr 0.000027
[Epoch 2] step 12300 loss 0.0343 lr 0.000027
[Epoch 2] step 12400 loss 0.0434 lr 0.000027
[Epoch 2] step 12500 loss 0.0548 lr 0.000027
[Epoch 2] step 12600 loss 0.1171 lr 0.000027
[Epoch 2] step 12700 loss 0.0370 lr 0.000027
[Epoch 2] step 12800 loss 0.0410 lr 0.000027
[Epoch 2] step 12900 loss 0.0522 lr 0.000027
[Epoch 2] step 13000 loss 0.0721 lr 0.000027
[Epoch 2] step 13100 loss 0.0381 lr 0.000027
[Epoch 2] step 13200 loss 0.1582 lr 0.000027
[Epoch 2] step 13300 loss 0.0406 lr 0.000027
[Epoch 2] step 13400 loss 0.0770 lr 0.000027
[Epoch 2] step 13500 loss 0.0845 lr 0.000027
[Epoch 2] step 13600 loss 0.0605 lr 0.000027
[Epoch 2] step 13700 loss 0.0835 lr 0.000027
[Epoch 2] step 13800 loss 0.0958 lr 0.000027
[Epoch 2] step 13900 loss 0.0472 lr 0.000027
[Epoch 2] step 14000 loss 0.1362 lr 0.000027
[Epoch 2] step 14100 loss 0.0468 lr 0.000027
[Epoch 2] step 14200 loss 0.0518 lr 0.000027
[Epoch 2] step 14300 loss 0.0498 lr 0.000027
[Epoch 2] step 14400 loss 0.0444 lr 0.000027
[Epoch 2] step 14500 loss 0.0248 lr 0.000027
[Epoch 2] step 14600 loss 0.0560 lr 0.000027
[Epoch 2] step 14700 loss 0.0281 lr 0.000027
[Epoch 2] step 14800 loss 0.0609 lr 0.000027
[Epoch 2] step 14900 loss 0.0469 lr 0.000027
[Validation] global_step 30000 loss 0.2577 accuracy 0.4258
Validation metrics did not improve. Patience: 3/10
Epoch 2 avg loss 0.0656
[Epoch 3] step 0 loss 0.0343 lr 0.000027
[Epoch 3] step 100 loss 0.0513 lr 0.000027
[Epoch 3] step 200 loss 0.0495 lr 0.000027
[Epoch 3] step 300 loss 0.0254 lr 0.000027
[Epoch 3] step 400 loss 0.0532 lr 0.000027
[Epoch 3] step 500 loss 0.0685 lr 0.000027
[Epoch 3] step 600 loss 0.0403 lr 0.000027
[Epoch 3] step 700 loss 0.0290 lr 0.000027
[Epoch 3] step 800 loss 0.0431 lr 0.000026
[Epoch 3] step 900 loss 0.0413 lr 0.000026
[Epoch 3] step 1000 loss 0.0477 lr 0.000026
[Epoch 3] step 1100 loss 0.0721 lr 0.000026
[Epoch 3] step 1200 loss 0.0220 lr 0.000026
[Epoch 3] step 1300 loss 0.0164 lr 0.000026
[Epoch 3] step 1400 loss 0.0156 lr 0.000026
[Epoch 3] step 1500 loss 0.0976 lr 0.000026
[Epoch 3] step 1600 loss 0.1003 lr 0.000026
[Epoch 3] step 1700 loss 0.1888 lr 0.000026
[Epoch 3] step 1800 loss 0.0490 lr 0.000026
[Epoch 3] step 1900 loss 0.0425 lr 0.000026
[Epoch 3] step 2000 loss 0.0011 lr 0.000026
[Epoch 3] step 2100 loss 0.0541 lr 0.000026
[Epoch 3] step 2200 loss 0.0828 lr 0.000026
[Epoch 3] step 2300 loss 0.0234 lr 0.000026
[Epoch 3] step 2400 loss 0.0474 lr 0.000026
[Epoch 3] step 2500 loss 0.0711 lr 0.000026
[Epoch 3] step 2600 loss 0.0089 lr 0.000026
[Epoch 3] step 2700 loss 0.0420 lr 0.000026
[Epoch 3] step 2800 loss 0.0684 lr 0.000026
[Epoch 3] step 2900 loss 0.0495 lr 0.000026
[Epoch 3] step 3000 loss 0.0316 lr 0.000026
[Epoch 3] step 3100 loss 0.0460 lr 0.000026
[Epoch 3] step 3200 loss 0.0658 lr 0.000026
[Epoch 3] step 3300 loss 0.0636 lr 0.000026
[Epoch 3] step 3400 loss 0.1626 lr 0.000026
[Epoch 3] step 3500 loss 0.0289 lr 0.000026
[Epoch 3] step 3600 loss 0.0833 lr 0.000026
[Epoch 3] step 3700 loss 0.1167 lr 0.000026
[Epoch 3] step 3800 loss 0.0488 lr 0.000026
[Epoch 3] step 3900 loss 0.0392 lr 0.000026
[Epoch 3] step 4000 loss 0.1160 lr 0.000026
[Epoch 3] step 4100 loss 0.0955 lr 0.000026
[Epoch 3] step 4200 loss 0.0734 lr 0.000026
[Epoch 3] step 4300 loss 0.0342 lr 0.000026
[Epoch 3] step 4400 loss 0.0504 lr 0.000026
[Epoch 3] step 4500 loss 0.0552 lr 0.000026
[Epoch 3] step 4600 loss 0.0241 lr 0.000026
[Epoch 3] step 4700 loss 0.0489 lr 0.000026
[Epoch 3] step 4800 loss 0.0409 lr 0.000026
[Epoch 3] step 4900 loss 0.0628 lr 0.000026
[Validation] global_step 35000 loss 0.2744 accuracy 0.4414
Validation metrics did not improve. Patience: 4/10
[Epoch 3] step 5000 loss 0.0194 lr 0.000026
[Epoch 3] step 5100 loss 0.0622 lr 0.000026
[Epoch 3] step 5200 loss 0.1145 lr 0.000026
[Epoch 3] step 5300 loss 0.1052 lr 0.000025
[Epoch 3] step 5400 loss 0.0309 lr 0.000025
[Epoch 3] step 5500 loss 0.0716 lr 0.000025
[Epoch 3] step 5600 loss 0.0567 lr 0.000025
[Epoch 3] step 5700 loss 0.1328 lr 0.000025
[Epoch 3] step 5800 loss 0.0719 lr 0.000025
[Epoch 3] step 5900 loss 0.0893 lr 0.000025
[Epoch 3] step 6000 loss 0.0458 lr 0.000025
[Epoch 3] step 6100 loss 0.0424 lr 0.000025
[Epoch 3] step 6200 loss 0.0965 lr 0.000025
[Epoch 3] step 6300 loss 0.1177 lr 0.000025
[Epoch 3] step 6400 loss 0.1632 lr 0.000025
[Epoch 3] step 6500 loss 0.1361 lr 0.000025
[Epoch 3] step 6600 loss 0.0124 lr 0.000025
[Epoch 3] step 6700 loss 0.0427 lr 0.000025
[Epoch 3] step 6800 loss 0.0737 lr 0.000025
[Epoch 3] step 6900 loss 0.0418 lr 0.000025
[Epoch 3] step 7000 loss 0.0780 lr 0.000025
[Epoch 3] step 7100 loss 0.1149 lr 0.000025
[Epoch 3] step 7200 loss 0.0225 lr 0.000025
[Epoch 3] step 7300 loss 0.0344 lr 0.000025
[Epoch 3] step 7400 loss 0.0897 lr 0.000025
[Epoch 3] step 7500 loss 0.0636 lr 0.000025
[Epoch 3] step 7600 loss 0.0221 lr 0.000025
[Epoch 3] step 7700 loss 0.0572 lr 0.000025
[Epoch 3] step 7800 loss 0.0103 lr 0.000025
[Epoch 3] step 7900 loss 0.0579 lr 0.000025
[Epoch 3] step 8000 loss 0.0216 lr 0.000025
[Epoch 3] step 8100 loss 0.0569 lr 0.000025
[Epoch 3] step 8200 loss 0.0500 lr 0.000025
[Epoch 3] step 8300 loss 0.0181 lr 0.000025
[Epoch 3] step 8400 loss 0.2081 lr 0.000025
[Epoch 3] step 8500 loss 0.0284 lr 0.000025
[Epoch 3] step 8600 loss 0.0892 lr 0.000025
[Epoch 3] step 8700 loss 0.1523 lr 0.000025
[Epoch 3] step 8800 loss 0.1309 lr 0.000025
[Epoch 3] step 8900 loss 0.1418 lr 0.000025
[Epoch 3] step 9000 loss 0.0773 lr 0.000025
[Epoch 3] step 9100 loss 0.0623 lr 0.000025
[Epoch 3] step 9200 loss 0.0749 lr 0.000025
[Epoch 3] step 9300 loss 0.0596 lr 0.000025
[Epoch 3] step 9400 loss 0.0705 lr 0.000025
[Epoch 3] step 9500 loss 0.0767 lr 0.000025
[Epoch 3] step 9600 loss 0.0385 lr 0.000025
[Epoch 3] step 9700 loss 0.0270 lr 0.000025
[Epoch 3] step 9800 loss 0.0632 lr 0.000024
[Epoch 3] step 9900 loss 0.0503 lr 0.000024
[Validation] global_step 40000 loss 0.2697 accuracy 0.4492
Validation metrics did not improve. Patience: 5/10
[Epoch 3] step 10000 loss 0.1494 lr 0.000024
[Epoch 3] step 10100 loss 0.0743 lr 0.000024
[Epoch 3] step 10200 loss 0.0290 lr 0.000024
[Epoch 3] step 10300 loss 0.0692 lr 0.000024
[Epoch 3] step 10400 loss 0.0404 lr 0.000024
[Epoch 3] step 10500 loss 0.0477 lr 0.000024
[Epoch 3] step 10600 loss 0.0319 lr 0.000024
[Epoch 3] step 10700 loss 0.1565 lr 0.000024
[Epoch 3] step 10800 loss 0.1601 lr 0.000024
[Epoch 3] step 10900 loss 0.0511 lr 0.000024
[Epoch 3] step 11000 loss 0.0673 lr 0.000024
[Epoch 3] step 11100 loss 0.0456 lr 0.000024
[Epoch 3] step 11200 loss 0.1037 lr 0.000024
[Epoch 3] step 11300 loss 0.0856 lr 0.000024
[Epoch 3] step 11400 loss 0.0844 lr 0.000024
[Epoch 3] step 11500 loss 0.0928 lr 0.000024
[Epoch 3] step 11600 loss 0.0667 lr 0.000024
[Epoch 3] step 11700 loss 0.1573 lr 0.000024
[Epoch 3] step 11800 loss 0.0237 lr 0.000024
[Epoch 3] step 11900 loss 0.0811 lr 0.000024
[Epoch 3] step 12000 loss 0.0240 lr 0.000024
[Epoch 3] step 12100 loss 0.0803 lr 0.000024
[Epoch 3] step 12200 loss 0.0728 lr 0.000024
[Epoch 3] step 12300 loss 0.0457 lr 0.000024
[Epoch 3] step 12400 loss 0.0332 lr 0.000024
[Epoch 3] step 12500 loss 0.1156 lr 0.000024
[Epoch 3] step 12600 loss 0.2444 lr 0.000024
[Epoch 3] step 12700 loss 0.0114 lr 0.000024
[Epoch 3] step 12800 loss 0.0410 lr 0.000024
[Epoch 3] step 12900 loss 0.0626 lr 0.000024
[Epoch 3] step 13000 loss 0.0428 lr 0.000024
[Epoch 3] step 13100 loss 0.0619 lr 0.000024
[Epoch 3] step 13200 loss 0.0125 lr 0.000024
[Epoch 3] step 13300 loss 0.0630 lr 0.000024
[Epoch 3] step 13400 loss 0.0777 lr 0.000024
[Epoch 3] step 13500 loss 0.0615 lr 0.000024
[Epoch 3] step 13600 loss 0.0691 lr 0.000024
[Epoch 3] step 13700 loss 0.0350 lr 0.000024
[Epoch 3] step 13800 loss 0.0362 lr 0.000024
[Epoch 3] step 13900 loss 0.0366 lr 0.000024
[Epoch 3] step 14000 loss 0.0933 lr 0.000024
[Epoch 3] step 14100 loss 0.1788 lr 0.000024
[Epoch 3] step 14200 loss 0.0671 lr 0.000024
[Epoch 3] step 14300 loss 0.0436 lr 0.000023
[Epoch 3] step 14400 loss 0.0506 lr 0.000023
[Epoch 3] step 14500 loss 0.0842 lr 0.000023
[Epoch 3] step 14600 loss 0.1083 lr 0.000023
[Epoch 3] step 14700 loss 0.0421 lr 0.000023
[Epoch 3] step 14800 loss 0.0412 lr 0.000023
[Epoch 3] step 14900 loss 0.0318 lr 0.000023
[Validation] global_step 45000 loss 0.2567 accuracy 0.4414
Validation metrics did not improve. Patience: 6/10
Epoch 3 avg loss 0.0729
[Epoch 4] step 0 loss 0.0349 lr 0.000023
[Epoch 4] step 100 loss 0.0537 lr 0.000023
[Epoch 4] step 200 loss 0.0505 lr 0.000023
[Epoch 4] step 300 loss 0.1980 lr 0.000023
[Epoch 4] step 400 loss 0.0523 lr 0.000023
[Epoch 4] step 500 loss 0.0993 lr 0.000023
[Epoch 4] step 600 loss 0.0567 lr 0.000023
[Epoch 4] step 700 loss 0.0370 lr 0.000023
[Epoch 4] step 800 loss 0.1049 lr 0.000023
[Epoch 4] step 900 loss 0.0459 lr 0.000023
[Epoch 4] step 1000 loss 0.0410 lr 0.000023
[Epoch 4] step 1100 loss 0.0480 lr 0.000023
[Epoch 4] step 1200 loss 0.0280 lr 0.000023
[Epoch 4] step 1300 loss 0.0639 lr 0.000023
[Epoch 4] step 1400 loss 0.0557 lr 0.000023
[Epoch 4] step 1500 loss 0.0255 lr 0.000023
[Epoch 4] step 1600 loss 0.0232 lr 0.000023
[Epoch 4] step 1700 loss 0.0367 lr 0.000023
[Epoch 4] step 1800 loss 0.0882 lr 0.000023
[Epoch 4] step 1900 loss 0.0420 lr 0.000023
[Epoch 4] step 2000 loss 0.0544 lr 0.000023
[Epoch 4] step 2100 loss 0.0398 lr 0.000023
[Epoch 4] step 2200 loss 0.1079 lr 0.000023
[Epoch 4] step 2300 loss 0.0581 lr 0.000023
[Epoch 4] step 2400 loss 0.0827 lr 0.000023
[Epoch 4] step 2500 loss 0.0613 lr 0.000023
[Epoch 4] step 2600 loss 0.0341 lr 0.000023
[Epoch 4] step 2700 loss 0.0781 lr 0.000023
[Epoch 4] step 2800 loss 0.0560 lr 0.000023
[Epoch 4] step 2900 loss 0.0444 lr 0.000023
[Epoch 4] step 3000 loss 0.2033 lr 0.000023
[Epoch 4] step 3100 loss 0.0449 lr 0.000023
[Epoch 4] step 3200 loss 0.0642 lr 0.000023
[Epoch 4] step 3300 loss 0.0304 lr 0.000023
[Epoch 4] step 3400 loss 0.0252 lr 0.000023
[Epoch 4] step 3500 loss 0.0728 lr 0.000023
[Epoch 4] step 3600 loss 0.0561 lr 0.000023
[Epoch 4] step 3700 loss 0.0383 lr 0.000023
[Epoch 4] step 3800 loss 0.0147 lr 0.000022
[Epoch 4] step 3900 loss 0.1847 lr 0.000022
[Epoch 4] step 4000 loss 0.0818 lr 0.000022
[Epoch 4] step 4100 loss 0.0383 lr 0.000022
[Epoch 4] step 4200 loss 0.0563 lr 0.000022
[Epoch 4] step 4300 loss 0.0616 lr 0.000022
[Epoch 4] step 4400 loss 0.0302 lr 0.000022
[Epoch 4] step 4500 loss 0.0946 lr 0.000022
[Epoch 4] step 4600 loss 0.0412 lr 0.000022
[Epoch 4] step 4700 loss 0.1966 lr 0.000022
[Epoch 4] step 4800 loss 0.0757 lr 0.000022
[Epoch 4] step 4900 loss 0.1068 lr 0.000022
[Validation] global_step 50000 loss 0.2472 accuracy 0.4688
Validation accuracy improved from 0.4531 to 0.4688
[Epoch 4] step 5000 loss 0.0493 lr 0.000022
[Epoch 4] step 5100 loss 0.1449 lr 0.000022
[Epoch 4] step 5200 loss 0.0443 lr 0.000022
[Epoch 4] step 5300 loss 0.0555 lr 0.000022
[Epoch 4] step 5400 loss 0.1748 lr 0.000022
[Epoch 4] step 5500 loss 0.0225 lr 0.000022
[Epoch 4] step 5600 loss 0.1028 lr 0.000022
[Epoch 4] step 5700 loss 0.0100 lr 0.000022
[Epoch 4] step 5800 loss 0.0199 lr 0.000022
[Epoch 4] step 5900 loss 0.0482 lr 0.000022
[Epoch 4] step 6000 loss 0.0944 lr 0.000022
[Epoch 4] step 6100 loss 0.0268 lr 0.000022
[Epoch 4] step 6200 loss 0.0190 lr 0.000022
[Epoch 4] step 6300 loss 0.0514 lr 0.000022
[Epoch 4] step 6400 loss 0.0323 lr 0.000022
[Epoch 4] step 6500 loss 0.0637 lr 0.000022
[Epoch 4] step 6600 loss 0.1644 lr 0.000022
[Epoch 4] step 6700 loss 0.0895 lr 0.000022
[Epoch 4] step 6800 loss 0.0653 lr 0.000022
[Epoch 4] step 6900 loss 0.0387 lr 0.000022
[Epoch 4] step 7000 loss 0.1501 lr 0.000022
[Epoch 4] step 7100 loss 0.0842 lr 0.000022
[Epoch 4] step 7200 loss 0.1803 lr 0.000022
[Epoch 4] step 7300 loss 0.0611 lr 0.000022
[Epoch 4] step 7400 loss 0.0546 lr 0.000022
[Epoch 4] step 7500 loss 0.0585 lr 0.000022
[Epoch 4] step 7600 loss 0.0626 lr 0.000022
[Epoch 4] step 7700 loss 0.0572 lr 0.000022
[Epoch 4] step 7800 loss 0.0849 lr 0.000022
[Epoch 4] step 7900 loss 0.0144 lr 0.000022
[Epoch 4] step 8000 loss 0.0670 lr 0.000022
[Epoch 4] step 8100 loss 0.0151 lr 0.000022
[Epoch 4] step 8200 loss 0.0925 lr 0.000022
[Epoch 4] step 8300 loss 0.1241 lr 0.000021
[Epoch 4] step 8400 loss 0.0525 lr 0.000021
[Epoch 4] step 8500 loss 0.1127 lr 0.000021
[Epoch 4] step 8600 loss 0.0593 lr 0.000021
[Epoch 4] step 8700 loss 0.0166 lr 0.000021
[Epoch 4] step 8800 loss 0.0351 lr 0.000021
[Epoch 4] step 8900 loss 0.0388 lr 0.000021
[Epoch 4] step 9000 loss 0.0869 lr 0.000021
[Epoch 4] step 9100 loss 0.1115 lr 0.000021
[Epoch 4] step 9200 loss 0.1602 lr 0.000021
[Epoch 4] step 9300 loss 0.0631 lr 0.000021
[Epoch 4] step 9400 loss 0.0669 lr 0.000021
[Epoch 4] step 9500 loss 0.1043 lr 0.000021
[Epoch 4] step 9600 loss 0.0488 lr 0.000021
[Epoch 4] step 9700 loss 0.1133 lr 0.000021
[Epoch 4] step 9800 loss 0.0922 lr 0.000021
[Epoch 4] step 9900 loss 0.2274 lr 0.000021
[Validation] global_step 55000 loss 0.2529 accuracy 0.4492
Validation metrics did not improve. Patience: 1/10
[Epoch 4] step 10000 loss 0.0189 lr 0.000021
[Epoch 4] step 10100 loss 0.0734 lr 0.000021
[Epoch 4] step 10200 loss 0.0937 lr 0.000021
[Epoch 4] step 10300 loss 0.2563 lr 0.000021
[Epoch 4] step 10400 loss 0.0761 lr 0.000021
[Epoch 4] step 10500 loss 0.0735 lr 0.000021
[Epoch 4] step 10600 loss 0.0314 lr 0.000021
[Epoch 4] step 10700 loss 0.0307 lr 0.000021
[Epoch 4] step 10800 loss 0.0904 lr 0.000021
[Epoch 4] step 10900 loss 0.0640 lr 0.000021
[Epoch 4] step 11000 loss 0.1243 lr 0.000021
[Epoch 4] step 11100 loss 0.0421 lr 0.000021
[Epoch 4] step 11200 loss 0.0415 lr 0.000021
[Epoch 4] step 11300 loss 0.0254 lr 0.000021
[Epoch 4] step 11400 loss 0.0450 lr 0.000021
[Epoch 4] step 11500 loss 0.0874 lr 0.000021
[Epoch 4] step 11600 loss 0.1094 lr 0.000021
[Epoch 4] step 11700 loss 0.1375 lr 0.000021
[Epoch 4] step 11800 loss 0.0326 lr 0.000021
[Epoch 4] step 11900 loss 0.0520 lr 0.000021
[Epoch 4] step 12000 loss 0.1953 lr 0.000021
[Epoch 4] step 12100 loss 0.0213 lr 0.000021
[Epoch 4] step 12200 loss 0.0613 lr 0.000021
[Epoch 4] step 12300 loss 0.0493 lr 0.000021
[Epoch 4] step 12400 loss 0.0454 lr 0.000021
[Epoch 4] step 12500 loss 0.0435 lr 0.000021
[Epoch 4] step 12600 loss 0.1450 lr 0.000021
[Epoch 4] step 12700 loss 0.0891 lr 0.000021
[Epoch 4] step 12800 loss 0.1266 lr 0.000020
[Epoch 4] step 12900 loss 0.0431 lr 0.000020
[Epoch 4] step 13000 loss 0.0113 lr 0.000020
[Epoch 4] step 13100 loss 0.1242 lr 0.000020
[Epoch 4] step 13200 loss 0.0240 lr 0.000020
[Epoch 4] step 13300 loss 0.1272 lr 0.000020
[Epoch 4] step 13400 loss 0.0425 lr 0.000020
[Epoch 4] step 13500 loss 0.0947 lr 0.000020
[Epoch 4] step 13600 loss 0.0580 lr 0.000020
[Epoch 4] step 13700 loss 0.0558 lr 0.000020
[Epoch 4] step 13800 loss 0.1205 lr 0.000020
[Epoch 4] step 13900 loss 0.0595 lr 0.000020
[Epoch 4] step 14000 loss 0.0681 lr 0.000020
[Epoch 4] step 14100 loss 0.0339 lr 0.000020
[Epoch 4] step 14200 loss 0.0286 lr 0.000020
[Epoch 4] step 14300 loss 0.0313 lr 0.000020
[Epoch 4] step 14400 loss 0.0733 lr 0.000020
[Epoch 4] step 14500 loss 0.0891 lr 0.000020
[Epoch 4] step 14600 loss 0.0424 lr 0.000020
[Epoch 4] step 14700 loss 0.0663 lr 0.000020
[Epoch 4] step 14800 loss 0.0914 lr 0.000020
[Epoch 4] step 14900 loss 0.0533 lr 0.000020
[Validation] global_step 60000 loss 0.2717 accuracy 0.4844
Validation accuracy improved from 0.4688 to 0.4844
Epoch 4 avg loss 0.0719
[Epoch 5] step 0 loss 0.1020 lr 0.000020
[Epoch 5] step 100 loss 0.0690 lr 0.000020
[Epoch 5] step 200 loss 0.0793 lr 0.000020
[Epoch 5] step 300 loss 0.0842 lr 0.000020
[Epoch 5] step 400 loss 0.0740 lr 0.000020
[Epoch 5] step 500 loss 0.0488 lr 0.000020
[Epoch 5] step 600 loss 0.1254 lr 0.000020
[Epoch 5] step 700 loss 0.0912 lr 0.000020
[Epoch 5] step 800 loss 0.0765 lr 0.000020
[Epoch 5] step 900 loss 0.1010 lr 0.000020
[Epoch 5] step 1000 loss 0.1791 lr 0.000020
[Epoch 5] step 1100 loss 0.3564 lr 0.000020
[Epoch 5] step 1200 loss 0.0453 lr 0.000020
[Epoch 5] step 1300 loss 0.0592 lr 0.000020
[Epoch 5] step 1400 loss 0.1728 lr 0.000020
[Epoch 5] step 1500 loss 0.0634 lr 0.000020
[Epoch 5] step 1600 loss 0.0707 lr 0.000020
[Epoch 5] step 1700 loss 0.1035 lr 0.000020
[Epoch 5] step 1800 loss 0.0360 lr 0.000020
[Epoch 5] step 1900 loss 0.1734 lr 0.000020
[Epoch 5] step 2000 loss 0.0341 lr 0.000020
[Epoch 5] step 2100 loss 0.0612 lr 0.000020
[Epoch 5] step 2200 loss 0.0964 lr 0.000020
[Epoch 5] step 2300 loss 0.0861 lr 0.000019
[Epoch 5] step 2400 loss 0.0971 lr 0.000019
[Epoch 5] step 2500 loss 0.0870 lr 0.000019
[Epoch 5] step 2600 loss 0.1259 lr 0.000019
[Epoch 5] step 2700 loss 0.0456 lr 0.000019
[Epoch 5] step 2800 loss 0.0327 lr 0.000019
[Epoch 5] step 2900 loss 0.0919 lr 0.000019
[Epoch 5] step 3000 loss 0.0280 lr 0.000019
[Epoch 5] step 3100 loss 0.0644 lr 0.000019
[Epoch 5] step 3200 loss 0.0745 lr 0.000019
[Epoch 5] step 3300 loss 0.0672 lr 0.000019
[Epoch 5] step 3400 loss 0.0726 lr 0.000019
[Epoch 5] step 3500 loss 0.0385 lr 0.000019
[Epoch 5] step 3600 loss 0.0493 lr 0.000019
[Epoch 5] step 3700 loss 0.0484 lr 0.000019
[Epoch 5] step 3800 loss 0.0745 lr 0.000019
[Epoch 5] step 3900 loss 0.0395 lr 0.000019
[Epoch 5] step 4000 loss 0.1210 lr 0.000019
[Epoch 5] step 4100 loss 0.0363 lr 0.000019
[Epoch 5] step 4200 loss 0.0370 lr 0.000019
[Epoch 5] step 4300 loss 0.0386 lr 0.000019
[Epoch 5] step 4400 loss 0.0922 lr 0.000019
[Epoch 5] step 4500 loss 0.0285 lr 0.000019
[Epoch 5] step 4600 loss 0.0118 lr 0.000019
[Epoch 5] step 4700 loss 0.0458 lr 0.000019
[Epoch 5] step 4800 loss 0.0315 lr 0.000019
[Epoch 5] step 4900 loss 0.0856 lr 0.000019
[Validation] global_step 65000 loss 0.2767 accuracy 0.4609
Validation metrics did not improve. Patience: 1/10
[Epoch 5] step 5000 loss 0.0622 lr 0.000019
[Epoch 5] step 5100 loss 0.0470 lr 0.000019
[Epoch 5] step 5200 loss 0.0911 lr 0.000019
[Epoch 5] step 5300 loss 0.0819 lr 0.000019
[Epoch 5] step 5400 loss 0.0631 lr 0.000019
[Epoch 5] step 5500 loss 0.1292 lr 0.000019
[Epoch 5] step 5600 loss 0.0364 lr 0.000019
[Epoch 5] step 5700 loss 0.0407 lr 0.000019
[Epoch 5] step 5800 loss 0.0285 lr 0.000019
[Epoch 5] step 5900 loss 0.0515 lr 0.000019
[Epoch 5] step 6000 loss 0.1900 lr 0.000019
[Epoch 5] step 6100 loss 0.1151 lr 0.000019
[Epoch 5] step 6200 loss 0.0893 lr 0.000019
[Epoch 5] step 6300 loss 0.1238 lr 0.000019
[Epoch 5] step 6400 loss 0.1017 lr 0.000019
[Epoch 5] step 6500 loss 0.0779 lr 0.000019
[Epoch 5] step 6600 loss 0.0523 lr 0.000019
[Epoch 5] step 6700 loss 0.1158 lr 0.000019
[Epoch 5] step 6800 loss 0.0486 lr 0.000018
[Epoch 5] step 6900 loss 0.0300 lr 0.000018
[Epoch 5] step 7000 loss 0.1341 lr 0.000018
[Epoch 5] step 7100 loss 0.1238 lr 0.000018
[Epoch 5] step 7200 loss 0.0208 lr 0.000018
[Epoch 5] step 7300 loss 0.0522 lr 0.000018
[Epoch 5] step 7400 loss 0.1237 lr 0.000018
[Epoch 5] step 7500 loss 0.0614 lr 0.000018
[Epoch 5] step 7600 loss 0.0768 lr 0.000018
[Epoch 5] step 7700 loss 0.0634 lr 0.000018
[Epoch 5] step 7800 loss 0.0832 lr 0.000018
[Epoch 5] step 7900 loss 0.0185 lr 0.000018
[Epoch 5] step 8000 loss 0.0287 lr 0.000018
[Epoch 5] step 8100 loss 0.1089 lr 0.000018
[Epoch 5] step 8200 loss 0.0507 lr 0.000018
[Epoch 5] step 8300 loss 0.0557 lr 0.000018
[Epoch 5] step 8400 loss 0.0515 lr 0.000018
[Epoch 5] step 8500 loss 0.0513 lr 0.000018
[Epoch 5] step 8600 loss 0.0214 lr 0.000018
[Epoch 5] step 8700 loss 0.1371 lr 0.000018
[Epoch 5] step 8800 loss 0.1294 lr 0.000018
[Epoch 5] step 8900 loss 0.0218 lr 0.000018
[Epoch 5] step 9000 loss 0.1234 lr 0.000018
[Epoch 5] step 9100 loss 0.0825 lr 0.000018
[Epoch 5] step 9200 loss 0.0215 lr 0.000018
[Epoch 5] step 9300 loss 0.0331 lr 0.000018
[Epoch 5] step 9400 loss 0.0886 lr 0.000018
[Epoch 5] step 9500 loss 0.0324 lr 0.000018
[Epoch 5] step 9600 loss 0.0480 lr 0.000018
[Epoch 5] step 9700 loss 0.1710 lr 0.000018
[Epoch 5] step 9800 loss 0.1085 lr 0.000018
[Epoch 5] step 9900 loss 0.0772 lr 0.000018
[Validation] global_step 70000 loss 0.2497 accuracy 0.4336
Validation metrics did not improve. Patience: 2/10
[Epoch 5] step 10000 loss 0.0081 lr 0.000018
[Epoch 5] step 10100 loss 0.0474 lr 0.000018
[Epoch 5] step 10200 loss 0.0478 lr 0.000018
[Epoch 5] step 10300 loss 0.0302 lr 0.000018
[Epoch 5] step 10400 loss 0.0246 lr 0.000018
[Epoch 5] step 10500 loss 0.0290 lr 0.000018
[Epoch 5] step 10600 loss 0.1974 lr 0.000018
[Epoch 5] step 10700 loss 0.0206 lr 0.000018
[Epoch 5] step 10800 loss 0.0809 lr 0.000018
[Epoch 5] step 10900 loss 0.0725 lr 0.000018
[Epoch 5] step 11000 loss 0.0227 lr 0.000018
[Epoch 5] step 11100 loss 0.1127 lr 0.000018
[Epoch 5] step 11200 loss 0.0146 lr 0.000018
[Epoch 5] step 11300 loss 0.0464 lr 0.000017
[Epoch 5] step 11400 loss 0.0515 lr 0.000017
[Epoch 5] step 11500 loss 0.0214 lr 0.000017
[Epoch 5] step 11600 loss 0.0781 lr 0.000017
[Epoch 5] step 11700 loss 0.0309 lr 0.000017
[Epoch 5] step 11800 loss 0.0196 lr 0.000017
[Epoch 5] step 11900 loss 0.0692 lr 0.000017
[Epoch 5] step 12000 loss 0.0652 lr 0.000017
[Epoch 5] step 12100 loss 0.0603 lr 0.000017
[Epoch 5] step 12200 loss 0.0533 lr 0.000017
[Epoch 5] step 12300 loss 0.0426 lr 0.000017
[Epoch 5] step 12400 loss 0.0488 lr 0.000017
[Epoch 5] step 12500 loss 0.0672 lr 0.000017
[Epoch 5] step 12600 loss 0.0331 lr 0.000017
[Epoch 5] step 12700 loss 0.0304 lr 0.000017
[Epoch 5] step 12800 loss 0.0687 lr 0.000017
[Epoch 5] step 12900 loss 0.0249 lr 0.000017
[Epoch 5] step 13000 loss 0.0451 lr 0.000017
[Epoch 5] step 13100 loss 0.1038 lr 0.000017
[Epoch 5] step 13200 loss 0.0557 lr 0.000017
[Epoch 5] step 13300 loss 0.0427 lr 0.000017
[Epoch 5] step 13400 loss 0.0147 lr 0.000017
[Epoch 5] step 13500 loss 0.0202 lr 0.000017
[Epoch 5] step 13600 loss 0.1075 lr 0.000017
[Epoch 5] step 13700 loss 0.0688 lr 0.000017
[Epoch 5] step 13800 loss 0.0449 lr 0.000017
[Epoch 5] step 13900 loss 0.0543 lr 0.000017
[Epoch 5] step 14000 loss 0.0550 lr 0.000017
[Epoch 5] step 14100 loss 0.0287 lr 0.000017
[Epoch 5] step 14200 loss 0.0249 lr 0.000017
[Epoch 5] step 14300 loss 0.0748 lr 0.000017
[Epoch 5] step 14400 loss 0.0410 lr 0.000017
[Epoch 5] step 14500 loss 0.0788 lr 0.000017
[Epoch 5] step 14600 loss 0.0507 lr 0.000017
[Epoch 5] step 14700 loss 0.1213 lr 0.000017
[Epoch 5] step 14800 loss 0.0242 lr 0.000017
[Epoch 5] step 14900 loss 0.0441 lr 0.000017
[Validation] global_step 75000 loss 0.2580 accuracy 0.4883
Validation accuracy improved from 0.4844 to 0.4883
Epoch 5 avg loss 0.0710
[Epoch 6] step 0 loss 0.0242 lr 0.000017
[Epoch 6] step 100 loss 0.0810 lr 0.000017
[Epoch 6] step 200 loss 0.0479 lr 0.000017
[Epoch 6] step 300 loss 0.0694 lr 0.000017
[Epoch 6] step 400 loss 0.1425 lr 0.000017
[Epoch 6] step 500 loss 0.0919 lr 0.000017
[Epoch 6] step 600 loss 0.0562 lr 0.000017
[Epoch 6] step 700 loss 0.0559 lr 0.000017
[Epoch 6] step 800 loss 0.1796 lr 0.000016
[Epoch 6] step 900 loss 0.0179 lr 0.000016
[Epoch 6] step 1000 loss 0.0530 lr 0.000016
[Epoch 6] step 1100 loss 0.1049 lr 0.000016
[Epoch 6] step 1200 loss 0.3656 lr 0.000016
[Epoch 6] step 1300 loss 0.0266 lr 0.000016
[Epoch 6] step 1400 loss 0.0763 lr 0.000016
[Epoch 6] step 1500 loss 0.1381 lr 0.000016
[Epoch 6] step 1600 loss 0.0050 lr 0.000016
[Epoch 6] step 1700 loss 0.0328 lr 0.000016
[Epoch 6] step 1800 loss 0.0319 lr 0.000016
[Epoch 6] step 1900 loss 0.0738 lr 0.000016
[Epoch 6] step 2000 loss 0.0713 lr 0.000016
[Epoch 6] step 2100 loss 0.0311 lr 0.000016
[Epoch 6] step 2200 loss 0.0535 lr 0.000016
[Epoch 6] step 2300 loss 0.1707 lr 0.000016
[Epoch 6] step 2400 loss 0.0476 lr 0.000016
[Epoch 6] step 2500 loss 0.0265 lr 0.000016
[Epoch 6] step 2600 loss 0.0448 lr 0.000016
[Epoch 6] step 2700 loss 0.0489 lr 0.000016
[Epoch 6] step 2800 loss 0.0472 lr 0.000016
[Epoch 6] step 2900 loss 0.1052 lr 0.000016
[Epoch 6] step 3000 loss 0.0593 lr 0.000016
[Epoch 6] step 3100 loss 0.0367 lr 0.000016
[Epoch 6] step 3200 loss 0.0350 lr 0.000016
[Epoch 6] step 3300 loss 0.0133 lr 0.000016
[Epoch 6] step 3400 loss 0.0417 lr 0.000016
[Epoch 6] step 3500 loss 0.0391 lr 0.000016
[Epoch 6] step 3600 loss 0.0583 lr 0.000016
[Epoch 6] step 3700 loss 0.2029 lr 0.000016
[Epoch 6] step 3800 loss 0.0634 lr 0.000016
[Epoch 6] step 3900 loss 0.0469 lr 0.000016
[Epoch 6] step 4000 loss 0.0239 lr 0.000016
[Epoch 6] step 4100 loss 0.0357 lr 0.000016
[Epoch 6] step 4200 loss 0.0381 lr 0.000016
[Epoch 6] step 4300 loss 0.1330 lr 0.000016
[Epoch 6] step 4400 loss 0.0352 lr 0.000016
[Epoch 6] step 4500 loss 0.0553 lr 0.000016
[Epoch 6] step 4600 loss 0.0274 lr 0.000016
[Epoch 6] step 4700 loss 0.0509 lr 0.000016
[Epoch 6] step 4800 loss 0.2616 lr 0.000016
[Epoch 6] step 4900 loss 0.0929 lr 0.000016
[Validation] global_step 80000 loss 0.2558 accuracy 0.4688
Validation metrics did not improve. Patience: 1/10
[Epoch 6] step 5000 loss 0.0474 lr 0.000016
[Epoch 6] step 5100 loss 0.0485 lr 0.000016
[Epoch 6] step 5200 loss 0.0240 lr 0.000016
[Epoch 6] step 5300 loss 0.0795 lr 0.000015
[Epoch 6] step 5400 loss 0.0228 lr 0.000015
[Epoch 6] step 5500 loss 0.0528 lr 0.000015
[Epoch 6] step 5600 loss 0.1009 lr 0.000015
[Epoch 6] step 5700 loss 0.0574 lr 0.000015
[Epoch 6] step 5800 loss 0.0335 lr 0.000015
[Epoch 6] step 5900 loss 0.1073 lr 0.000015
[Epoch 6] step 6000 loss 0.0924 lr 0.000015
[Epoch 6] step 6100 loss 0.0708 lr 0.000015
[Epoch 6] step 6200 loss 0.0278 lr 0.000015
[Epoch 6] step 6300 loss 0.0391 lr 0.000015
[Epoch 6] step 6400 loss 0.0738 lr 0.000015
[Epoch 6] step 6500 loss 0.1557 lr 0.000015
[Epoch 6] step 6600 loss 0.0269 lr 0.000015
[Epoch 6] step 6700 loss 0.1304 lr 0.000015
[Epoch 6] step 6800 loss 0.0470 lr 0.000015
[Epoch 6] step 6900 loss 0.0865 lr 0.000015
[Epoch 6] step 7000 loss 0.0445 lr 0.000015
[Epoch 6] step 7100 loss 0.1751 lr 0.000015
[Epoch 6] step 7200 loss 0.0391 lr 0.000015
[Epoch 6] step 7300 loss 0.1338 lr 0.000015
[Epoch 6] step 7400 loss 0.0669 lr 0.000015
[Epoch 6] step 7500 loss 0.0472 lr 0.000015
[Epoch 6] step 7600 loss 0.0634 lr 0.000015
[Epoch 6] step 7700 loss 0.0416 lr 0.000015
[Epoch 6] step 7800 loss 0.1015 lr 0.000015
[Epoch 6] step 7900 loss 0.0656 lr 0.000015
[Epoch 6] step 8000 loss 0.0436 lr 0.000015
[Epoch 6] step 8100 loss 0.0450 lr 0.000015
[Epoch 6] step 8200 loss 0.0625 lr 0.000015
[Epoch 6] step 8300 loss 0.0433 lr 0.000015
[Epoch 6] step 8400 loss 0.1124 lr 0.000015
[Epoch 6] step 8500 loss 0.0484 lr 0.000015
[Epoch 6] step 8600 loss 0.0920 lr 0.000015
[Epoch 6] step 8700 loss 0.0647 lr 0.000015
[Epoch 6] step 8800 loss 0.0811 lr 0.000015
[Epoch 6] step 8900 loss 0.2311 lr 0.000015
[Epoch 6] step 9000 loss 0.0492 lr 0.000015
[Epoch 6] step 9100 loss 0.0606 lr 0.000015
[Epoch 6] step 9200 loss 0.0271 lr 0.000015
[Epoch 6] step 9300 loss 0.0478 lr 0.000015
[Epoch 6] step 9400 loss 0.0372 lr 0.000015
[Epoch 6] step 9500 loss 0.0777 lr 0.000015
[Epoch 6] step 9600 loss 0.1396 lr 0.000015
[Epoch 6] step 9700 loss 0.0512 lr 0.000015
[Epoch 6] step 9800 loss 0.0889 lr 0.000014
[Epoch 6] step 9900 loss 0.2327 lr 0.000014
[Validation] global_step 85000 loss 0.2563 accuracy 0.4414
Validation metrics did not improve. Patience: 2/10
[Epoch 6] step 10000 loss 0.0232 lr 0.000014
[Epoch 6] step 10100 loss 0.0426 lr 0.000014
[Epoch 6] step 10200 loss 0.0990 lr 0.000014
[Epoch 6] step 10300 loss 0.0448 lr 0.000014
[Epoch 6] step 10400 loss 0.0461 lr 0.000014
[Epoch 6] step 10500 loss 0.0893 lr 0.000014
[Epoch 6] step 10600 loss 0.0798 lr 0.000014
[Epoch 6] step 10700 loss 0.0258 lr 0.000014
[Epoch 6] step 10800 loss 0.0297 lr 0.000014
[Epoch 6] step 10900 loss 0.0422 lr 0.000014
[Epoch 6] step 11000 loss 0.0482 lr 0.000014
[Epoch 6] step 11100 loss 0.1004 lr 0.000014
[Epoch 6] step 11200 loss 0.0661 lr 0.000014
[Epoch 6] step 11300 loss 0.0444 lr 0.000014
[Epoch 6] step 11400 loss 0.1931 lr 0.000014
[Epoch 6] step 11500 loss 0.0092 lr 0.000014
[Epoch 6] step 11600 loss 0.0781 lr 0.000014
[Epoch 6] step 11700 loss 0.0629 lr 0.000014
[Epoch 6] step 11800 loss 0.0338 lr 0.000014
[Epoch 6] step 11900 loss 0.1433 lr 0.000014
[Epoch 6] step 12000 loss 0.0755 lr 0.000014
[Epoch 6] step 12100 loss 0.1031 lr 0.000014
[Epoch 6] step 12200 loss 0.0458 lr 0.000014
[Epoch 6] step 12300 loss 0.0160 lr 0.000014
[Epoch 6] step 12400 loss 0.0606 lr 0.000014
[Epoch 6] step 12500 loss 0.0956 lr 0.000014
[Epoch 6] step 12600 loss 0.0440 lr 0.000014
[Epoch 6] step 12700 loss 0.0624 lr 0.000014
[Epoch 6] step 12800 loss 0.0831 lr 0.000014
[Epoch 6] step 12900 loss 0.0518 lr 0.000014
[Epoch 6] step 13000 loss 0.0955 lr 0.000014
[Epoch 6] step 13100 loss 0.0284 lr 0.000014
[Epoch 6] step 13200 loss 0.0636 lr 0.000014
[Epoch 6] step 13300 loss 0.0366 lr 0.000014
[Epoch 6] step 13400 loss 0.0611 lr 0.000014
[Epoch 6] step 13500 loss 0.1286 lr 0.000014
[Epoch 6] step 13600 loss 0.0537 lr 0.000014
[Epoch 6] step 13700 loss 0.0448 lr 0.000014
[Epoch 6] step 13800 loss 0.0155 lr 0.000014
[Epoch 6] step 13900 loss 0.0767 lr 0.000014
[Epoch 6] step 14000 loss 0.1684 lr 0.000014
[Epoch 6] step 14100 loss 0.0610 lr 0.000014
[Epoch 6] step 14200 loss 0.2646 lr 0.000014
[Epoch 6] step 14300 loss 0.0348 lr 0.000013
[Epoch 6] step 14400 loss 0.0633 lr 0.000013
[Epoch 6] step 14500 loss 0.0693 lr 0.000013
[Epoch 6] step 14600 loss 0.0938 lr 0.000013
[Epoch 6] step 14700 loss 0.1491 lr 0.000013
[Epoch 6] step 14800 loss 0.0669 lr 0.000013
[Epoch 6] step 14900 loss 0.2047 lr 0.000013
[Validation] global_step 90000 loss 0.2578 accuracy 0.4492
Validation metrics did not improve. Patience: 3/10
Epoch 6 avg loss 0.0703
[Epoch 7] step 0 loss 0.0842 lr 0.000013
[Epoch 7] step 100 loss 0.0819 lr 0.000013
[Epoch 7] step 200 loss 0.0528 lr 0.000013
[Epoch 7] step 300 loss 0.0170 lr 0.000013
[Epoch 7] step 400 loss 0.0470 lr 0.000013
[Epoch 7] step 500 loss 0.0741 lr 0.000013
[Epoch 7] step 600 loss 0.0383 lr 0.000013
[Epoch 7] step 700 loss 0.2738 lr 0.000013
[Epoch 7] step 800 loss 0.0210 lr 0.000013
[Epoch 7] step 900 loss 0.1474 lr 0.000013
[Epoch 7] step 1000 loss 0.0632 lr 0.000013
[Epoch 7] step 1100 loss 0.0601 lr 0.000013
[Epoch 7] step 1200 loss 0.0494 lr 0.000013
[Epoch 7] step 1300 loss 0.1067 lr 0.000013
[Epoch 7] step 1400 loss 0.0523 lr 0.000013
[Epoch 7] step 1500 loss 0.0738 lr 0.000013
[Epoch 7] step 1600 loss 0.0480 lr 0.000013
[Epoch 7] step 1700 loss 0.2241 lr 0.000013
[Epoch 7] step 1800 loss 0.1688 lr 0.000013
[Epoch 7] step 1900 loss 0.0312 lr 0.000013
[Epoch 7] step 2000 loss 0.0307 lr 0.000013
[Epoch 7] step 2100 loss 0.0742 lr 0.000013
[Epoch 7] step 2200 loss 0.0443 lr 0.000013
[Epoch 7] step 2300 loss 0.0647 lr 0.000013
[Epoch 7] step 2400 loss 0.0376 lr 0.000013
[Epoch 7] step 2500 loss 0.2549 lr 0.000013
[Epoch 7] step 2600 loss 0.0414 lr 0.000013
[Epoch 7] step 2700 loss 0.0527 lr 0.000013
[Epoch 7] step 2800 loss 0.0475 lr 0.000013
[Epoch 7] step 2900 loss 0.1038 lr 0.000013
[Epoch 7] step 3000 loss 0.0483 lr 0.000013
[Epoch 7] step 3100 loss 0.3587 lr 0.000013
[Epoch 7] step 3200 loss 0.0492 lr 0.000013
[Epoch 7] step 3300 loss 0.0418 lr 0.000013
[Epoch 7] step 3400 loss 0.0141 lr 0.000013
[Epoch 7] step 3500 loss 0.0576 lr 0.000013
[Epoch 7] step 3600 loss 0.0432 lr 0.000013
[Epoch 7] step 3700 loss 0.0463 lr 0.000013
[Epoch 7] step 3800 loss 0.0497 lr 0.000012
[Epoch 7] step 3900 loss 0.0159 lr 0.000012
[Epoch 7] step 4000 loss 0.1567 lr 0.000012
[Epoch 7] step 4100 loss 0.0474 lr 0.000012
[Epoch 7] step 4200 loss 0.0883 lr 0.000012
[Epoch 7] step 4300 loss 0.0388 lr 0.000012
[Epoch 7] step 4400 loss 0.0342 lr 0.000012
[Epoch 7] step 4500 loss 0.0257 lr 0.000012
[Epoch 7] step 4600 loss 0.0560 lr 0.000012
[Epoch 7] step 4700 loss 0.1090 lr 0.000012
[Epoch 7] step 4800 loss 0.0668 lr 0.000012
[Epoch 7] step 4900 loss 0.0599 lr 0.000012
[Validation] global_step 95000 loss 0.2606 accuracy 0.4688
Validation metrics did not improve. Patience: 4/10
[Epoch 7] step 5000 loss 0.0366 lr 0.000012
[Epoch 7] step 5100 loss 0.0402 lr 0.000012
[Epoch 7] step 5200 loss 0.0776 lr 0.000012
