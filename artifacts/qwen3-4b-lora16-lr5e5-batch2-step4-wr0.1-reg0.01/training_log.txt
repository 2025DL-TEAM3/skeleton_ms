===== Training started at 0 =====
Batch size: 2, LR: 5e-05, Epochs: 10
Steps per file: 50, Grad. accum: 4, Warmup rate: 0.1
Validation dataset loaded with 128 steps, using seed 42, max files 128, steps/file 1, batch size 8
Total validation batches: 16
Warmup steps: 3750, Total optimizer steps: 37500
[Epoch 1] step 0 loss 0.2552 lr 0.000000
[Epoch 1] step 100 loss 0.1904 lr 0.000000
[Epoch 1] step 200 loss 0.4714 lr 0.000001
[Epoch 1] step 300 loss 0.5190 lr 0.000001
[Epoch 1] step 400 loss 0.2777 lr 0.000001
[Epoch 1] step 500 loss 0.4989 lr 0.000002
[Epoch 1] step 600 loss 0.4558 lr 0.000002
[Epoch 1] step 700 loss 0.1897 lr 0.000002
[Epoch 1] step 800 loss 0.1187 lr 0.000003
[Epoch 1] step 900 loss 0.1422 lr 0.000003
[Epoch 1] step 1000 loss 0.1553 lr 0.000003
[Epoch 1] step 1100 loss 0.2082 lr 0.000004
[Epoch 1] step 1200 loss 0.0572 lr 0.000004
[Epoch 1] step 1300 loss 0.1181 lr 0.000004
[Epoch 1] step 1400 loss 0.1607 lr 0.000005
[Epoch 1] step 1500 loss 0.0443 lr 0.000005
[Epoch 1] step 1600 loss 0.0733 lr 0.000005
[Epoch 1] step 1700 loss 0.1227 lr 0.000006
[Epoch 1] step 1800 loss 0.0561 lr 0.000006
[Epoch 1] step 1900 loss 0.0805 lr 0.000006
[Epoch 1] step 2000 loss 0.0671 lr 0.000007
[Epoch 1] step 2100 loss 0.1138 lr 0.000007
[Epoch 1] step 2200 loss 0.1048 lr 0.000007
[Epoch 1] step 2300 loss 0.1598 lr 0.000008
[Epoch 1] step 2400 loss 0.0254 lr 0.000008
[Epoch 1] step 2500 loss 0.1288 lr 0.000008
[Epoch 1] step 2600 loss 0.0630 lr 0.000009
[Epoch 1] step 2700 loss 0.0299 lr 0.000009
[Epoch 1] step 2800 loss 0.2629 lr 0.000009
[Epoch 1] step 2900 loss 0.1473 lr 0.000010
[Epoch 1] step 3000 loss 0.0689 lr 0.000010
[Epoch 1] step 3100 loss 0.0570 lr 0.000010
[Epoch 1] step 3200 loss 0.0438 lr 0.000011
[Epoch 1] step 3300 loss 0.0653 lr 0.000011
[Epoch 1] step 3400 loss 0.2298 lr 0.000011
[Epoch 1] step 3500 loss 0.0555 lr 0.000012
[Epoch 1] step 3600 loss 0.0472 lr 0.000012
[Epoch 1] step 3700 loss 0.0557 lr 0.000012
[Epoch 1] step 3800 loss 0.0640 lr 0.000013
[Epoch 1] step 3900 loss 0.2745 lr 0.000013
[Epoch 1] step 4000 loss 0.0171 lr 0.000013
[Epoch 1] step 4100 loss 0.0667 lr 0.000014
[Epoch 1] step 4200 loss 0.0486 lr 0.000014
[Epoch 1] step 4300 loss 0.0346 lr 0.000014
[Epoch 1] step 4400 loss 0.0866 lr 0.000015
[Epoch 1] step 4500 loss 0.0391 lr 0.000015
[Epoch 1] step 4600 loss 0.0025 lr 0.000015
[Epoch 1] step 4700 loss 0.0240 lr 0.000016
[Epoch 1] step 4800 loss 0.0791 lr 0.000016
[Epoch 1] step 4900 loss 0.0793 lr 0.000016
[Validation] global_step 5000 loss 0.2196 accuracy 0.4336
Validation accuracy improved from 0.0000 to 0.4336, Validation loss improved from inf to 0.2196
[Epoch 1] step 5000 loss 0.1111 lr 0.000017
[Epoch 1] step 5100 loss 0.0809 lr 0.000017
[Epoch 1] step 5200 loss 0.1152 lr 0.000017
[Epoch 1] step 5300 loss 0.0358 lr 0.000018
[Epoch 1] step 5400 loss 0.0439 lr 0.000018
[Epoch 1] step 5500 loss 0.0461 lr 0.000018
[Epoch 1] step 5600 loss 0.0803 lr 0.000019
[Epoch 1] step 5700 loss 0.0155 lr 0.000019
[Epoch 1] step 5800 loss 0.0596 lr 0.000019
[Epoch 1] step 5900 loss 0.0150 lr 0.000020
[Epoch 1] step 6000 loss 0.0848 lr 0.000020
[Epoch 1] step 6100 loss 0.0680 lr 0.000020
[Epoch 1] step 6200 loss 0.2184 lr 0.000021
[Epoch 1] step 6300 loss 0.0476 lr 0.000021
[Epoch 1] step 6400 loss 0.0633 lr 0.000021
[Epoch 1] step 6500 loss 0.1042 lr 0.000022
[Epoch 1] step 6600 loss 0.0753 lr 0.000022
[Epoch 1] step 6700 loss 0.0630 lr 0.000022
[Epoch 1] step 6800 loss 0.0875 lr 0.000023
[Epoch 1] step 6900 loss 0.0392 lr 0.000023
[Epoch 1] step 7000 loss 0.0706 lr 0.000023
[Epoch 1] step 7100 loss 0.0334 lr 0.000024
[Epoch 1] step 7200 loss 0.0522 lr 0.000024
[Epoch 1] step 7300 loss 0.0447 lr 0.000024
[Epoch 1] step 7400 loss 0.0212 lr 0.000025
[Epoch 1] step 7500 loss 0.1417 lr 0.000025
[Epoch 1] step 7600 loss 0.0740 lr 0.000025
[Epoch 1] step 7700 loss 0.0193 lr 0.000026
[Epoch 1] step 7800 loss 0.1174 lr 0.000026
[Epoch 1] step 7900 loss 0.0483 lr 0.000026
[Epoch 1] step 8000 loss 0.1543 lr 0.000027
[Epoch 1] step 8100 loss 0.0163 lr 0.000027
[Epoch 1] step 8200 loss 0.0478 lr 0.000027
[Epoch 1] step 8300 loss 0.0391 lr 0.000028
[Epoch 1] step 8400 loss 0.1010 lr 0.000028
[Epoch 1] step 8500 loss 0.0514 lr 0.000028
[Epoch 1] step 8600 loss 0.0638 lr 0.000029
[Epoch 1] step 8700 loss 0.1414 lr 0.000029
[Epoch 1] step 8800 loss 0.0452 lr 0.000029
[Epoch 1] step 8900 loss 0.0207 lr 0.000030
[Epoch 1] step 9000 loss 0.0854 lr 0.000030
[Epoch 1] step 9100 loss 0.0451 lr 0.000030
[Epoch 1] step 9200 loss 0.0148 lr 0.000031
[Epoch 1] step 9300 loss 0.0368 lr 0.000031
[Epoch 1] step 9400 loss 0.0512 lr 0.000031
[Epoch 1] step 9500 loss 0.0377 lr 0.000032
[Epoch 1] step 9600 loss 0.0674 lr 0.000032
[Epoch 1] step 9700 loss 0.0242 lr 0.000032
[Epoch 1] step 9800 loss 0.0438 lr 0.000033
[Epoch 1] step 9900 loss 0.0788 lr 0.000033
[Validation] global_step 10000 loss 0.2145 accuracy 0.4375
Validation accuracy improved from 0.4336 to 0.4375, Validation loss improved from 0.2196 to 0.2145
[Epoch 1] step 10000 loss 0.0453 lr 0.000033
[Epoch 1] step 10100 loss 0.0632 lr 0.000034
[Epoch 1] step 10200 loss 0.0170 lr 0.000034
[Epoch 1] step 10300 loss 0.1029 lr 0.000034
[Epoch 1] step 10400 loss 0.0836 lr 0.000035
[Epoch 1] step 10500 loss 0.0285 lr 0.000035
[Epoch 1] step 10600 loss 0.0252 lr 0.000035
[Epoch 1] step 10700 loss 0.0251 lr 0.000036
[Epoch 1] step 10800 loss 0.0315 lr 0.000036
[Epoch 1] step 10900 loss 0.0846 lr 0.000036
[Epoch 1] step 11000 loss 0.0253 lr 0.000037
[Epoch 1] step 11100 loss 0.0452 lr 0.000037
[Epoch 1] step 11200 loss 0.0115 lr 0.000037
[Epoch 1] step 11300 loss 0.0581 lr 0.000038
[Epoch 1] step 11400 loss 0.0336 lr 0.000038
[Epoch 1] step 11500 loss 0.0186 lr 0.000038
[Epoch 1] step 11600 loss 0.0196 lr 0.000039
[Epoch 1] step 11700 loss 0.0208 lr 0.000039
[Epoch 1] step 11800 loss 0.0906 lr 0.000039
[Epoch 1] step 11900 loss 0.0767 lr 0.000040
[Epoch 1] step 12000 loss 0.0239 lr 0.000040
[Epoch 1] step 12100 loss 0.0589 lr 0.000040
[Epoch 1] step 12200 loss 0.0475 lr 0.000041
[Epoch 1] step 12300 loss 0.0450 lr 0.000041
[Epoch 1] step 12400 loss 0.0391 lr 0.000041
[Epoch 1] step 12500 loss 0.0360 lr 0.000042
[Epoch 1] step 12600 loss 0.0713 lr 0.000042
[Epoch 1] step 12700 loss 0.2000 lr 0.000042
[Epoch 1] step 12800 loss 0.0192 lr 0.000043
[Epoch 1] step 12900 loss 0.0601 lr 0.000043
[Epoch 1] step 13000 loss 0.0427 lr 0.000043
[Epoch 1] step 13100 loss 0.0238 lr 0.000044
[Epoch 1] step 13200 loss 0.0699 lr 0.000044
[Epoch 1] step 13300 loss 0.0620 lr 0.000044
[Epoch 1] step 13400 loss 0.0646 lr 0.000045
[Epoch 1] step 13500 loss 0.0562 lr 0.000045
[Epoch 1] step 13600 loss 0.0342 lr 0.000045
[Epoch 1] step 13700 loss 0.0566 lr 0.000046
[Epoch 1] step 13800 loss 0.0554 lr 0.000046
[Epoch 1] step 13900 loss 0.2694 lr 0.000046
[Epoch 1] step 14000 loss 0.0308 lr 0.000047
[Epoch 1] step 14100 loss 0.0952 lr 0.000047
[Epoch 1] step 14200 loss 0.0499 lr 0.000047
[Epoch 1] step 14300 loss 0.0421 lr 0.000048
[Epoch 1] step 14400 loss 0.0447 lr 0.000048
[Epoch 1] step 14500 loss 0.0639 lr 0.000048
[Epoch 1] step 14600 loss 0.0085 lr 0.000049
[Epoch 1] step 14700 loss 0.0815 lr 0.000049
[Epoch 1] step 14800 loss 0.0882 lr 0.000049
[Epoch 1] step 14900 loss 0.0704 lr 0.000050
[Validation] global_step 15000 loss 0.2188 accuracy 0.4648
Validation accuracy improved from 0.4375 to 0.4648
Epoch 1 avg loss 0.0833
[Epoch 2] step 0 loss 0.0987 lr 0.000050
[Epoch 2] step 100 loss 0.0529 lr 0.000050
[Epoch 2] step 200 loss 0.0673 lr 0.000050
[Epoch 2] step 300 loss 0.0706 lr 0.000050
[Epoch 2] step 400 loss 0.0454 lr 0.000050
[Epoch 2] step 500 loss 0.0998 lr 0.000050
[Epoch 2] step 600 loss 0.0623 lr 0.000050
[Epoch 2] step 700 loss 0.0351 lr 0.000050
[Epoch 2] step 800 loss 0.0156 lr 0.000050
[Epoch 2] step 900 loss 0.1200 lr 0.000050
[Epoch 2] step 1000 loss 0.0827 lr 0.000050
[Epoch 2] step 1100 loss 0.0142 lr 0.000050
[Epoch 2] step 1200 loss 0.0377 lr 0.000050
[Epoch 2] step 1300 loss 0.0409 lr 0.000050
[Epoch 2] step 1400 loss 0.0762 lr 0.000049
[Epoch 2] step 1500 loss 0.2042 lr 0.000049
[Epoch 2] step 1600 loss 0.0458 lr 0.000049
[Epoch 2] step 1700 loss 0.0221 lr 0.000049
[Epoch 2] step 1800 loss 0.0650 lr 0.000049
[Epoch 2] step 1900 loss 0.0245 lr 0.000049
[Epoch 2] step 2000 loss 0.0267 lr 0.000049
[Epoch 2] step 2100 loss 0.0241 lr 0.000049
[Epoch 2] step 2200 loss 0.0772 lr 0.000049
[Epoch 2] step 2300 loss 0.0551 lr 0.000049
[Epoch 2] step 2400 loss 0.0372 lr 0.000049
[Epoch 2] step 2500 loss 0.0592 lr 0.000049
[Epoch 2] step 2600 loss 0.0199 lr 0.000049
[Epoch 2] step 2700 loss 0.0132 lr 0.000049
[Epoch 2] step 2800 loss 0.0423 lr 0.000049
[Epoch 2] step 2900 loss 0.0623 lr 0.000049
[Epoch 2] step 3000 loss 0.0365 lr 0.000049
[Epoch 2] step 3100 loss 0.0335 lr 0.000049
[Epoch 2] step 3200 loss 0.0790 lr 0.000049
[Epoch 2] step 3300 loss 0.1271 lr 0.000049
[Epoch 2] step 3400 loss 0.1176 lr 0.000049
[Epoch 2] step 3500 loss 0.0619 lr 0.000049
[Epoch 2] step 3600 loss 0.0849 lr 0.000049
[Epoch 2] step 3700 loss 0.0925 lr 0.000049
[Epoch 2] step 3800 loss 0.0222 lr 0.000049
[Epoch 2] step 3900 loss 0.0258 lr 0.000049
[Epoch 2] step 4000 loss 0.0845 lr 0.000049
[Epoch 2] step 4100 loss 0.0415 lr 0.000048
[Epoch 2] step 4200 loss 0.0450 lr 0.000048
[Epoch 2] step 4300 loss 0.1574 lr 0.000048
[Epoch 2] step 4400 loss 0.0455 lr 0.000048
[Epoch 2] step 4500 loss 0.0547 lr 0.000048
[Epoch 2] step 4600 loss 0.0219 lr 0.000048
[Epoch 2] step 4700 loss 0.0216 lr 0.000048
[Epoch 2] step 4800 loss 0.0514 lr 0.000048
[Epoch 2] step 4900 loss 0.0306 lr 0.000048
[Validation] global_step 20000 loss 0.2296 accuracy 0.4688
Validation accuracy improved from 0.4648 to 0.4688
[Epoch 2] step 5000 loss 0.0881 lr 0.000048
[Epoch 2] step 5100 loss 0.0613 lr 0.000048
[Epoch 2] step 5200 loss 0.0507 lr 0.000048
[Epoch 2] step 5300 loss 0.1022 lr 0.000048
[Epoch 2] step 5400 loss 0.0369 lr 0.000048
[Epoch 2] step 5500 loss 0.2016 lr 0.000048
[Epoch 2] step 5600 loss 0.0637 lr 0.000048
[Epoch 2] step 5700 loss 0.0502 lr 0.000048
[Epoch 2] step 5800 loss 0.1218 lr 0.000048
[Epoch 2] step 5900 loss 0.0634 lr 0.000048
[Epoch 2] step 6000 loss 0.1165 lr 0.000048
[Epoch 2] step 6100 loss 0.0650 lr 0.000048
[Epoch 2] step 6200 loss 0.0403 lr 0.000048
[Epoch 2] step 6300 loss 0.0938 lr 0.000048
[Epoch 2] step 6400 loss 0.0165 lr 0.000048
[Epoch 2] step 6500 loss 0.0376 lr 0.000048
[Epoch 2] step 6600 loss 0.0487 lr 0.000048
[Epoch 2] step 6700 loss 0.0804 lr 0.000048
[Epoch 2] step 6800 loss 0.0555 lr 0.000047
[Epoch 2] step 6900 loss 0.0500 lr 0.000047
[Epoch 2] step 7000 loss 0.0323 lr 0.000047
[Epoch 2] step 7100 loss 0.1135 lr 0.000047
[Epoch 2] step 7200 loss 0.0490 lr 0.000047
[Epoch 2] step 7300 loss 0.0701 lr 0.000047
[Epoch 2] step 7400 loss 0.0487 lr 0.000047
[Epoch 2] step 7500 loss 0.0391 lr 0.000047
[Epoch 2] step 7600 loss 0.0901 lr 0.000047
[Epoch 2] step 7700 loss 0.0322 lr 0.000047
[Epoch 2] step 7800 loss 0.0465 lr 0.000047
[Epoch 2] step 7900 loss 0.1753 lr 0.000047
[Epoch 2] step 8000 loss 0.0423 lr 0.000047
[Epoch 2] step 8100 loss 0.0680 lr 0.000047
[Epoch 2] step 8200 loss 0.0752 lr 0.000047
[Epoch 2] step 8300 loss 0.1151 lr 0.000047
[Epoch 2] step 8400 loss 0.0891 lr 0.000047
[Epoch 2] step 8500 loss 0.1882 lr 0.000047
[Epoch 2] step 8600 loss 0.0536 lr 0.000047
[Epoch 2] step 8700 loss 0.0930 lr 0.000047
[Epoch 2] step 8800 loss 0.0499 lr 0.000047
[Epoch 2] step 8900 loss 0.1110 lr 0.000047
[Epoch 2] step 9000 loss 0.0518 lr 0.000047
[Epoch 2] step 9100 loss 0.1052 lr 0.000047
[Epoch 2] step 9200 loss 0.0350 lr 0.000047
[Epoch 2] step 9300 loss 0.1185 lr 0.000047
[Epoch 2] step 9400 loss 0.0432 lr 0.000047
[Epoch 2] step 9500 loss 0.0540 lr 0.000046
[Epoch 2] step 9600 loss 0.0679 lr 0.000046
[Epoch 2] step 9700 loss 0.0626 lr 0.000046
[Epoch 2] step 9800 loss 0.0759 lr 0.000046
[Epoch 2] step 9900 loss 0.1414 lr 0.000046
[Validation] global_step 25000 loss 0.2396 accuracy 0.4570
Validation metrics did not improve. Patience: 1/10
[Epoch 2] step 10000 loss 0.0503 lr 0.000046
[Epoch 2] step 10100 loss 0.0323 lr 0.000046
[Epoch 2] step 10200 loss 0.0601 lr 0.000046
[Epoch 2] step 10300 loss 0.0837 lr 0.000046
[Epoch 2] step 10400 loss 0.0925 lr 0.000046
[Epoch 2] step 10500 loss 0.0294 lr 0.000046
[Epoch 2] step 10600 loss 0.0237 lr 0.000046
[Epoch 2] step 10700 loss 0.1046 lr 0.000046
[Epoch 2] step 10800 loss 0.0145 lr 0.000046
[Epoch 2] step 10900 loss 0.0262 lr 0.000046
[Epoch 2] step 11000 loss 0.0322 lr 0.000046
[Epoch 2] step 11100 loss 0.0429 lr 0.000046
[Epoch 2] step 11200 loss 0.0442 lr 0.000046
[Epoch 2] step 11300 loss 0.0912 lr 0.000046
[Epoch 2] step 11400 loss 0.2842 lr 0.000046
[Epoch 2] step 11500 loss 0.1179 lr 0.000046
[Epoch 2] step 11600 loss 0.0613 lr 0.000046
[Epoch 2] step 11700 loss 0.0535 lr 0.000046
[Epoch 2] step 11800 loss 0.0450 lr 0.000046
[Epoch 2] step 11900 loss 0.0475 lr 0.000046
[Epoch 2] step 12000 loss 0.0451 lr 0.000046
[Epoch 2] step 12100 loss 0.0899 lr 0.000046
[Epoch 2] step 12200 loss 0.0958 lr 0.000045
[Epoch 2] step 12300 loss 0.0768 lr 0.000045
[Epoch 2] step 12400 loss 0.1398 lr 0.000045
[Epoch 2] step 12500 loss 0.0568 lr 0.000045
[Epoch 2] step 12600 loss 0.0709 lr 0.000045
[Epoch 2] step 12700 loss 0.0762 lr 0.000045
[Epoch 2] step 12800 loss 0.0325 lr 0.000045
[Epoch 2] step 12900 loss 0.0719 lr 0.000045
[Epoch 2] step 13000 loss 0.0598 lr 0.000045
[Epoch 2] step 13100 loss 0.0187 lr 0.000045
[Epoch 2] step 13200 loss 0.0480 lr 0.000045
[Epoch 2] step 13300 loss 0.0776 lr 0.000045
[Epoch 2] step 13400 loss 0.1038 lr 0.000045
[Epoch 2] step 13500 loss 0.0605 lr 0.000045
[Epoch 2] step 13600 loss 0.0675 lr 0.000045
[Epoch 2] step 13700 loss 0.0367 lr 0.000045
[Epoch 2] step 13800 loss 0.0571 lr 0.000045
[Epoch 2] step 13900 loss 0.0292 lr 0.000045
[Epoch 2] step 14000 loss 0.0637 lr 0.000045
[Epoch 2] step 14100 loss 0.0377 lr 0.000045
[Epoch 2] step 14200 loss 0.0464 lr 0.000045
[Epoch 2] step 14300 loss 0.1242 lr 0.000045
[Epoch 2] step 14400 loss 0.0766 lr 0.000045
[Epoch 2] step 14500 loss 0.0336 lr 0.000045
[Epoch 2] step 14600 loss 0.0814 lr 0.000045
[Epoch 2] step 14700 loss 0.0374 lr 0.000045
[Epoch 2] step 14800 loss 0.1030 lr 0.000045
[Epoch 2] step 14900 loss 0.1144 lr 0.000044
[Validation] global_step 30000 loss 0.2478 accuracy 0.4414
Validation metrics did not improve. Patience: 2/10
Epoch 2 avg loss 0.0661
[Epoch 3] step 0 loss 0.1048 lr 0.000044
[Epoch 3] step 100 loss 0.0750 lr 0.000044
[Epoch 3] step 200 loss 0.0452 lr 0.000044
[Epoch 3] step 300 loss 0.0847 lr 0.000044
[Epoch 3] step 400 loss 0.0643 lr 0.000044
[Epoch 3] step 500 loss 0.0670 lr 0.000044
[Epoch 3] step 600 loss 0.1226 lr 0.000044
[Epoch 3] step 700 loss 0.0118 lr 0.000044
[Epoch 3] step 800 loss 0.0473 lr 0.000044
[Epoch 3] step 900 loss 0.0256 lr 0.000044
[Epoch 3] step 1000 loss 0.0660 lr 0.000044
[Epoch 3] step 1100 loss 0.0471 lr 0.000044
[Epoch 3] step 1200 loss 0.0548 lr 0.000044
[Epoch 3] step 1300 loss 0.0354 lr 0.000044
[Epoch 3] step 1400 loss 0.0848 lr 0.000044
[Epoch 3] step 1500 loss 0.0543 lr 0.000044
[Epoch 3] step 1600 loss 0.0476 lr 0.000044
[Epoch 3] step 1700 loss 0.0849 lr 0.000044
[Epoch 3] step 1800 loss 0.0368 lr 0.000044
[Epoch 3] step 1900 loss 0.0480 lr 0.000044
[Epoch 3] step 2000 loss 0.1321 lr 0.000044
[Epoch 3] step 2100 loss 0.0102 lr 0.000044
[Epoch 3] step 2200 loss 0.0651 lr 0.000044
[Epoch 3] step 2300 loss 0.0244 lr 0.000044
[Epoch 3] step 2400 loss 0.1461 lr 0.000044
[Epoch 3] step 2500 loss 0.0625 lr 0.000044
[Epoch 3] step 2600 loss 0.0406 lr 0.000043
[Epoch 3] step 2700 loss 0.0308 lr 0.000043
[Epoch 3] step 2800 loss 0.0541 lr 0.000043
[Epoch 3] step 2900 loss 0.1169 lr 0.000043
[Epoch 3] step 3000 loss 0.0353 lr 0.000043
[Epoch 3] step 3100 loss 0.0440 lr 0.000043
[Epoch 3] step 3200 loss 0.0417 lr 0.000043
[Epoch 3] step 3300 loss 0.0362 lr 0.000043
[Epoch 3] step 3400 loss 0.0663 lr 0.000043
[Epoch 3] step 3500 loss 0.0458 lr 0.000043
[Epoch 3] step 3600 loss 0.0833 lr 0.000043
[Epoch 3] step 3700 loss 0.0694 lr 0.000043
[Epoch 3] step 3800 loss 0.0618 lr 0.000043
[Epoch 3] step 3900 loss 0.0477 lr 0.000043
[Epoch 3] step 4000 loss 0.0954 lr 0.000043
[Epoch 3] step 4100 loss 0.0457 lr 0.000043
[Epoch 3] step 4200 loss 0.0218 lr 0.000043
[Epoch 3] step 4300 loss 0.0820 lr 0.000043
[Epoch 3] step 4400 loss 0.0674 lr 0.000043
[Epoch 3] step 4500 loss 0.0606 lr 0.000043
[Epoch 3] step 4600 loss 0.1024 lr 0.000043
[Epoch 3] step 4700 loss 0.1413 lr 0.000043
[Epoch 3] step 4800 loss 0.0556 lr 0.000043
[Epoch 3] step 4900 loss 0.0088 lr 0.000043
[Validation] global_step 35000 loss 0.2521 accuracy 0.4492
Validation metrics did not improve. Patience: 3/10
[Epoch 3] step 5000 loss 0.0328 lr 0.000043
[Epoch 3] step 5100 loss 0.1029 lr 0.000043
[Epoch 3] step 5200 loss 0.0686 lr 0.000043
[Epoch 3] step 5300 loss 0.0540 lr 0.000042
[Epoch 3] step 5400 loss 0.1020 lr 0.000042
[Epoch 3] step 5500 loss 0.0647 lr 0.000042
[Epoch 3] step 5600 loss 0.0464 lr 0.000042
[Epoch 3] step 5700 loss 0.0206 lr 0.000042
[Epoch 3] step 5800 loss 0.0759 lr 0.000042
[Epoch 3] step 5900 loss 0.0500 lr 0.000042
[Epoch 3] step 6000 loss 0.0250 lr 0.000042
[Epoch 3] step 6100 loss 0.0549 lr 0.000042
[Epoch 3] step 6200 loss 0.0342 lr 0.000042
[Epoch 3] step 6300 loss 0.0065 lr 0.000042
[Epoch 3] step 6400 loss 0.1061 lr 0.000042
[Epoch 3] step 6500 loss 0.1161 lr 0.000042
[Epoch 3] step 6600 loss 0.0244 lr 0.000042
[Epoch 3] step 6700 loss 0.0558 lr 0.000042
[Epoch 3] step 6800 loss 0.0575 lr 0.000042
[Epoch 3] step 6900 loss 0.1264 lr 0.000042
[Epoch 3] step 7000 loss 0.1158 lr 0.000042
[Epoch 3] step 7100 loss 0.0851 lr 0.000042
[Epoch 3] step 7200 loss 0.0658 lr 0.000042
[Epoch 3] step 7300 loss 0.1005 lr 0.000042
[Epoch 3] step 7400 loss 0.0311 lr 0.000042
[Epoch 3] step 7500 loss 0.0487 lr 0.000042
[Epoch 3] step 7600 loss 0.0321 lr 0.000042
[Epoch 3] step 7700 loss 0.0425 lr 0.000042
[Epoch 3] step 7800 loss 0.0817 lr 0.000042
[Epoch 3] step 7900 loss 0.0372 lr 0.000042
[Epoch 3] step 8000 loss 0.0486 lr 0.000041
[Epoch 3] step 8100 loss 0.0612 lr 0.000041
[Epoch 3] step 8200 loss 0.0259 lr 0.000041
[Epoch 3] step 8300 loss 0.1161 lr 0.000041
[Epoch 3] step 8400 loss 0.0224 lr 0.000041
[Epoch 3] step 8500 loss 0.0459 lr 0.000041
[Epoch 3] step 8600 loss 0.0622 lr 0.000041
[Epoch 3] step 8700 loss 0.0414 lr 0.000041
[Epoch 3] step 8800 loss 0.0619 lr 0.000041
[Epoch 3] step 8900 loss 0.0366 lr 0.000041
[Epoch 3] step 9000 loss 0.1882 lr 0.000041
[Epoch 3] step 9100 loss 0.0567 lr 0.000041
[Epoch 3] step 9200 loss 0.0439 lr 0.000041
[Epoch 3] step 9300 loss 0.0475 lr 0.000041
[Epoch 3] step 9400 loss 0.2062 lr 0.000041
[Epoch 3] step 9500 loss 0.0403 lr 0.000041
[Epoch 3] step 9600 loss 0.0964 lr 0.000041
[Epoch 3] step 9700 loss 0.0783 lr 0.000041
[Epoch 3] step 9800 loss 0.0707 lr 0.000041
[Epoch 3] step 9900 loss 0.1357 lr 0.000041
[Validation] global_step 40000 loss 0.2585 accuracy 0.4414
Validation metrics did not improve. Patience: 4/10
[Epoch 3] step 10000 loss 0.0887 lr 0.000041
[Epoch 3] step 10100 loss 0.0365 lr 0.000041
[Epoch 3] step 10200 loss 0.0398 lr 0.000041
[Epoch 3] step 10300 loss 0.1447 lr 0.000041
[Epoch 3] step 10400 loss 0.1207 lr 0.000041
[Epoch 3] step 10500 loss 0.1930 lr 0.000041
[Epoch 3] step 10600 loss 0.0838 lr 0.000041
[Epoch 3] step 10700 loss 0.0315 lr 0.000040
[Epoch 3] step 10800 loss 0.0365 lr 0.000040
[Epoch 3] step 10900 loss 0.1080 lr 0.000040
[Epoch 3] step 11000 loss 0.0481 lr 0.000040
[Epoch 3] step 11100 loss 0.0271 lr 0.000040
[Epoch 3] step 11200 loss 0.0917 lr 0.000040
[Epoch 3] step 11300 loss 0.0508 lr 0.000040
[Epoch 3] step 11400 loss 0.0716 lr 0.000040
[Epoch 3] step 11500 loss 0.0205 lr 0.000040
[Epoch 3] step 11600 loss 0.0173 lr 0.000040
[Epoch 3] step 11700 loss 0.0485 lr 0.000040
[Epoch 3] step 11800 loss 0.0408 lr 0.000040
[Epoch 3] step 11900 loss 0.0349 lr 0.000040
[Epoch 3] step 12000 loss 0.1461 lr 0.000040
[Epoch 3] step 12100 loss 0.0669 lr 0.000040
[Epoch 3] step 12200 loss 0.0931 lr 0.000040
[Epoch 3] step 12300 loss 0.0856 lr 0.000040
[Epoch 3] step 12400 loss 0.0315 lr 0.000040
[Epoch 3] step 12500 loss 0.0461 lr 0.000040
[Epoch 3] step 12600 loss 0.1838 lr 0.000040
[Epoch 3] step 12700 loss 0.0592 lr 0.000040
[Epoch 3] step 12800 loss 0.0644 lr 0.000040
[Epoch 3] step 12900 loss 0.1235 lr 0.000040
[Epoch 3] step 13000 loss 0.1990 lr 0.000040
[Epoch 3] step 13100 loss 0.0514 lr 0.000040
[Epoch 3] step 13200 loss 0.0347 lr 0.000040
[Epoch 3] step 13300 loss 0.0262 lr 0.000040
[Epoch 3] step 13400 loss 0.0135 lr 0.000039
[Epoch 3] step 13500 loss 0.1377 lr 0.000039
[Epoch 3] step 13600 loss 0.1629 lr 0.000039
[Epoch 3] step 13700 loss 0.0676 lr 0.000039
[Epoch 3] step 13800 loss 0.0769 lr 0.000039
[Epoch 3] step 13900 loss 0.0443 lr 0.000039
[Epoch 3] step 14000 loss 0.0530 lr 0.000039
[Epoch 3] step 14100 loss 0.1192 lr 0.000039
[Epoch 3] step 14200 loss 0.0304 lr 0.000039
[Epoch 3] step 14300 loss 0.2455 lr 0.000039
[Epoch 3] step 14400 loss 0.0579 lr 0.000039
[Epoch 3] step 14500 loss 0.0812 lr 0.000039
[Epoch 3] step 14600 loss 0.0663 lr 0.000039
[Epoch 3] step 14700 loss 0.1131 lr 0.000039
[Epoch 3] step 14800 loss 0.0402 lr 0.000039
[Epoch 3] step 14900 loss 0.0567 lr 0.000039
[Validation] global_step 45000 loss 0.2327 accuracy 0.4688
Validation metrics did not improve. Patience: 5/10
Epoch 3 avg loss 0.0699
[Epoch 4] step 0 loss 0.0884 lr 0.000039
[Epoch 4] step 100 loss 0.0831 lr 0.000039
[Epoch 4] step 200 loss 0.0481 lr 0.000039
[Epoch 4] step 300 loss 0.2272 lr 0.000039
[Epoch 4] step 400 loss 0.1315 lr 0.000039
[Epoch 4] step 500 loss 0.0693 lr 0.000039
[Epoch 4] step 600 loss 0.0638 lr 0.000039
[Epoch 4] step 700 loss 0.1137 lr 0.000039
[Epoch 4] step 800 loss 0.1591 lr 0.000039
[Epoch 4] step 900 loss 0.1153 lr 0.000039
[Epoch 4] step 1000 loss 0.0224 lr 0.000039
[Epoch 4] step 1100 loss 0.0662 lr 0.000038
[Epoch 4] step 1200 loss 0.0573 lr 0.000038
[Epoch 4] step 1300 loss 0.0696 lr 0.000038
[Epoch 4] step 1400 loss 0.0522 lr 0.000038
[Epoch 4] step 1500 loss 0.0669 lr 0.000038
[Epoch 4] step 1600 loss 0.0401 lr 0.000038
[Epoch 4] step 1700 loss 0.0095 lr 0.000038
[Epoch 4] step 1800 loss 0.0588 lr 0.000038
[Epoch 4] step 1900 loss 0.0405 lr 0.000038
[Epoch 4] step 2000 loss 0.1093 lr 0.000038
[Epoch 4] step 2100 loss 0.1253 lr 0.000038
[Epoch 4] step 2200 loss 0.0298 lr 0.000038
[Epoch 4] step 2300 loss 0.0483 lr 0.000038
[Epoch 4] step 2400 loss 0.0707 lr 0.000038
[Epoch 4] step 2500 loss 0.0846 lr 0.000038
[Epoch 4] step 2600 loss 0.0682 lr 0.000038
[Epoch 4] step 2700 loss 0.0136 lr 0.000038
[Epoch 4] step 2800 loss 0.1045 lr 0.000038
[Epoch 4] step 2900 loss 0.0143 lr 0.000038
[Epoch 4] step 3000 loss 0.0602 lr 0.000038
[Epoch 4] step 3100 loss 0.0539 lr 0.000038
[Epoch 4] step 3200 loss 0.0418 lr 0.000038
[Epoch 4] step 3300 loss 0.0581 lr 0.000038
[Epoch 4] step 3400 loss 0.0706 lr 0.000038
[Epoch 4] step 3500 loss 0.0421 lr 0.000038
[Epoch 4] step 3600 loss 0.0252 lr 0.000038
[Epoch 4] step 3700 loss 0.1516 lr 0.000038
[Epoch 4] step 3800 loss 0.0444 lr 0.000037
[Epoch 4] step 3900 loss 0.1792 lr 0.000037
[Epoch 4] step 4000 loss 0.0672 lr 0.000037
[Epoch 4] step 4100 loss 0.1033 lr 0.000037
[Epoch 4] step 4200 loss 0.1133 lr 0.000037
[Epoch 4] step 4300 loss 0.0472 lr 0.000037
[Epoch 4] step 4400 loss 0.0507 lr 0.000037
[Epoch 4] step 4500 loss 0.1120 lr 0.000037
[Epoch 4] step 4600 loss 0.0826 lr 0.000037
[Epoch 4] step 4700 loss 0.1141 lr 0.000037
[Epoch 4] step 4800 loss 0.0570 lr 0.000037
[Epoch 4] step 4900 loss 0.0600 lr 0.000037
[Validation] global_step 50000 loss 0.2486 accuracy 0.4570
Validation metrics did not improve. Patience: 6/10
[Epoch 4] step 5000 loss 0.0304 lr 0.000037
[Epoch 4] step 5100 loss 0.1136 lr 0.000037
[Epoch 4] step 5200 loss 0.0267 lr 0.000037
[Epoch 4] step 5300 loss 0.0272 lr 0.000037
[Epoch 4] step 5400 loss 0.0454 lr 0.000037
[Epoch 4] step 5500 loss 0.0797 lr 0.000037
[Epoch 4] step 5600 loss 0.0302 lr 0.000037
[Epoch 4] step 5700 loss 0.0843 lr 0.000037
[Epoch 4] step 5800 loss 0.0396 lr 0.000037
[Epoch 4] step 5900 loss 0.0778 lr 0.000037
[Epoch 4] step 6000 loss 0.1196 lr 0.000037
[Epoch 4] step 6100 loss 0.0532 lr 0.000037
[Epoch 4] step 6200 loss 0.0126 lr 0.000037
[Epoch 4] step 6300 loss 0.0716 lr 0.000037
[Epoch 4] step 6400 loss 0.0496 lr 0.000037
[Epoch 4] step 6500 loss 0.2652 lr 0.000036
[Epoch 4] step 6600 loss 0.0488 lr 0.000036
[Epoch 4] step 6700 loss 0.1216 lr 0.000036
[Epoch 4] step 6800 loss 0.1802 lr 0.000036
[Epoch 4] step 6900 loss 0.0518 lr 0.000036
[Epoch 4] step 7000 loss 0.0711 lr 0.000036
[Epoch 4] step 7100 loss 0.0593 lr 0.000036
[Epoch 4] step 7200 loss 0.0252 lr 0.000036
[Epoch 4] step 7300 loss 0.0442 lr 0.000036
[Epoch 4] step 7400 loss 0.1482 lr 0.000036
[Epoch 4] step 7500 loss 0.0454 lr 0.000036
[Epoch 4] step 7600 loss 0.0485 lr 0.000036
[Epoch 4] step 7700 loss 0.0413 lr 0.000036
[Epoch 4] step 7800 loss 0.0612 lr 0.000036
[Epoch 4] step 7900 loss 0.0172 lr 0.000036
[Epoch 4] step 8000 loss 0.0246 lr 0.000036
[Epoch 4] step 8100 loss 0.2547 lr 0.000036
[Epoch 4] step 8200 loss 0.0769 lr 0.000036
[Epoch 4] step 8300 loss 0.0892 lr 0.000036
[Epoch 4] step 8400 loss 0.0790 lr 0.000036
[Epoch 4] step 8500 loss 0.0839 lr 0.000036
[Epoch 4] step 8600 loss 0.0211 lr 0.000036
[Epoch 4] step 8700 loss 0.1050 lr 0.000036
[Epoch 4] step 8800 loss 0.0299 lr 0.000036
[Epoch 4] step 8900 loss 0.0568 lr 0.000036
[Epoch 4] step 9000 loss 0.0803 lr 0.000036
[Epoch 4] step 9100 loss 0.0437 lr 0.000036
[Epoch 4] step 9200 loss 0.0188 lr 0.000035
[Epoch 4] step 9300 loss 0.0378 lr 0.000035
[Epoch 4] step 9400 loss 0.0400 lr 0.000035
[Epoch 4] step 9500 loss 0.0398 lr 0.000035
[Epoch 4] step 9600 loss 0.0664 lr 0.000035
[Epoch 4] step 9700 loss 0.1241 lr 0.000035
[Epoch 4] step 9800 loss 0.0229 lr 0.000035
[Epoch 4] step 9900 loss 0.0702 lr 0.000035
[Validation] global_step 55000 loss 0.2597 accuracy 0.4688
Validation metrics did not improve. Patience: 7/10
[Epoch 4] step 10000 loss 0.0641 lr 0.000035
[Epoch 4] step 10100 loss 0.0829 lr 0.000035
[Epoch 4] step 10200 loss 0.0436 lr 0.000035
[Epoch 4] step 10300 loss 0.0791 lr 0.000035
[Epoch 4] step 10400 loss 0.0411 lr 0.000035
[Epoch 4] step 10500 loss 0.0204 lr 0.000035
[Epoch 4] step 10600 loss 0.0240 lr 0.000035
[Epoch 4] step 10700 loss 0.0307 lr 0.000035
[Epoch 4] step 10800 loss 0.0236 lr 0.000035
[Epoch 4] step 10900 loss 0.0247 lr 0.000035
[Epoch 4] step 11000 loss 0.0563 lr 0.000035
[Epoch 4] step 11100 loss 0.1077 lr 0.000035
[Epoch 4] step 11200 loss 0.0847 lr 0.000035
[Epoch 4] step 11300 loss 0.0759 lr 0.000035
[Epoch 4] step 11400 loss 0.0288 lr 0.000035
[Epoch 4] step 11500 loss 0.0507 lr 0.000035
[Epoch 4] step 11600 loss 0.0499 lr 0.000035
[Epoch 4] step 11700 loss 0.0491 lr 0.000035
[Epoch 4] step 11800 loss 0.0787 lr 0.000035
[Epoch 4] step 11900 loss 0.0950 lr 0.000034
[Epoch 4] step 12000 loss 0.1000 lr 0.000034
[Epoch 4] step 12100 loss 0.0606 lr 0.000034
[Epoch 4] step 12200 loss 0.0891 lr 0.000034
[Epoch 4] step 12300 loss 0.0184 lr 0.000034
[Epoch 4] step 12400 loss 0.0249 lr 0.000034
[Epoch 4] step 12500 loss 0.0380 lr 0.000034
[Epoch 4] step 12600 loss 0.0621 lr 0.000034
[Epoch 4] step 12700 loss 0.1148 lr 0.000034
[Epoch 4] step 12800 loss 0.0337 lr 0.000034
[Epoch 4] step 12900 loss 0.0534 lr 0.000034
[Epoch 4] step 13000 loss 0.0646 lr 0.000034
[Epoch 4] step 13100 loss 0.0537 lr 0.000034
[Epoch 4] step 13200 loss 0.0425 lr 0.000034
[Epoch 4] step 13300 loss 0.0759 lr 0.000034
[Epoch 4] step 13400 loss 0.0494 lr 0.000034
[Epoch 4] step 13500 loss 0.0337 lr 0.000034
[Epoch 4] step 13600 loss 0.1520 lr 0.000034
[Epoch 4] step 13700 loss 0.0905 lr 0.000034
[Epoch 4] step 13800 loss 0.0237 lr 0.000034
[Epoch 4] step 13900 loss 0.0608 lr 0.000034
[Epoch 4] step 14000 loss 0.1401 lr 0.000034
[Epoch 4] step 14100 loss 0.0548 lr 0.000034
[Epoch 4] step 14200 loss 0.0630 lr 0.000034
[Epoch 4] step 14300 loss 0.1634 lr 0.000034
[Epoch 4] step 14400 loss 0.1239 lr 0.000034
[Epoch 4] step 14500 loss 0.0725 lr 0.000034
[Epoch 4] step 14600 loss 0.0503 lr 0.000033
[Epoch 4] step 14700 loss 0.1428 lr 0.000033
[Epoch 4] step 14800 loss 0.0350 lr 0.000033
[Epoch 4] step 14900 loss 0.1355 lr 0.000033
[Validation] global_step 60000 loss 0.2524 accuracy 0.4727
Validation accuracy improved from 0.4688 to 0.4727
Epoch 4 avg loss 0.0708
[Epoch 5] step 0 loss 0.0572 lr 0.000033
[Epoch 5] step 100 loss 0.0571 lr 0.000033
[Epoch 5] step 200 loss 0.0378 lr 0.000033
[Epoch 5] step 300 loss 0.0297 lr 0.000033
[Epoch 5] step 400 loss 0.0302 lr 0.000033
[Epoch 5] step 500 loss 0.0143 lr 0.000033
[Epoch 5] step 600 loss 0.0940 lr 0.000033
[Epoch 5] step 700 loss 0.2141 lr 0.000033
[Epoch 5] step 800 loss 0.0634 lr 0.000033
[Epoch 5] step 900 loss 0.0380 lr 0.000033
[Epoch 5] step 1000 loss 0.0701 lr 0.000033
[Epoch 5] step 1100 loss 0.0646 lr 0.000033
[Epoch 5] step 1200 loss 0.0823 lr 0.000033
[Epoch 5] step 1300 loss 0.0646 lr 0.000033
[Epoch 5] step 1400 loss 0.1053 lr 0.000033
[Epoch 5] step 1500 loss 0.0459 lr 0.000033
[Epoch 5] step 1600 loss 0.0604 lr 0.000033
[Epoch 5] step 1700 loss 0.1313 lr 0.000033
[Epoch 5] step 1800 loss 0.0787 lr 0.000033
[Epoch 5] step 1900 loss 0.0429 lr 0.000033
[Epoch 5] step 2000 loss 0.0622 lr 0.000033
[Epoch 5] step 2100 loss 0.0239 lr 0.000033
[Epoch 5] step 2200 loss 0.0242 lr 0.000033
[Epoch 5] step 2300 loss 0.0337 lr 0.000032
[Epoch 5] step 2400 loss 0.0430 lr 0.000032
[Epoch 5] step 2500 loss 0.0570 lr 0.000032
[Epoch 5] step 2600 loss 0.1347 lr 0.000032
[Epoch 5] step 2700 loss 0.0675 lr 0.000032
[Epoch 5] step 2800 loss 0.0889 lr 0.000032
[Epoch 5] step 2900 loss 0.0655 lr 0.000032
[Epoch 5] step 3000 loss 0.0365 lr 0.000032
[Epoch 5] step 3100 loss 0.0636 lr 0.000032
[Epoch 5] step 3200 loss 0.1343 lr 0.000032
[Epoch 5] step 3300 loss 0.0546 lr 0.000032
[Epoch 5] step 3400 loss 0.0243 lr 0.000032
[Epoch 5] step 3500 loss 0.0217 lr 0.000032
[Epoch 5] step 3600 loss 0.0453 lr 0.000032
[Epoch 5] step 3700 loss 0.0317 lr 0.000032
[Epoch 5] step 3800 loss 0.1256 lr 0.000032
[Epoch 5] step 3900 loss 0.0062 lr 0.000032
[Epoch 5] step 4000 loss 0.0799 lr 0.000032
[Epoch 5] step 4100 loss 0.1237 lr 0.000032
[Epoch 5] step 4200 loss 0.0731 lr 0.000032
[Epoch 5] step 4300 loss 0.0521 lr 0.000032
[Epoch 5] step 4400 loss 0.0412 lr 0.000032
[Epoch 5] step 4500 loss 0.0287 lr 0.000032
[Epoch 5] step 4600 loss 0.1122 lr 0.000032
[Epoch 5] step 4700 loss 0.0577 lr 0.000032
[Epoch 5] step 4800 loss 0.1674 lr 0.000032
[Epoch 5] step 4900 loss 0.0538 lr 0.000032
[Validation] global_step 65000 loss 0.2676 accuracy 0.4805
Validation accuracy improved from 0.4727 to 0.4805
[Epoch 5] step 5000 loss 0.0415 lr 0.000031
[Epoch 5] step 5100 loss 0.0125 lr 0.000031
[Epoch 5] step 5200 loss 0.0476 lr 0.000031
[Epoch 5] step 5300 loss 0.0903 lr 0.000031
[Epoch 5] step 5400 loss 0.0396 lr 0.000031
[Epoch 5] step 5500 loss 0.0312 lr 0.000031
[Epoch 5] step 5600 loss 0.0656 lr 0.000031
[Epoch 5] step 5700 loss 0.0657 lr 0.000031
[Epoch 5] step 5800 loss 0.1694 lr 0.000031
[Epoch 5] step 5900 loss 0.0435 lr 0.000031
[Epoch 5] step 6000 loss 0.1483 lr 0.000031
[Epoch 5] step 6100 loss 0.0460 lr 0.000031
[Epoch 5] step 6200 loss 0.0313 lr 0.000031
[Epoch 5] step 6300 loss 0.1096 lr 0.000031
[Epoch 5] step 6400 loss 0.0715 lr 0.000031
[Epoch 5] step 6500 loss 0.1118 lr 0.000031
[Epoch 5] step 6600 loss 0.0654 lr 0.000031
[Epoch 5] step 6700 loss 0.0754 lr 0.000031
[Epoch 5] step 6800 loss 0.0623 lr 0.000031
[Epoch 5] step 6900 loss 0.1077 lr 0.000031
[Epoch 5] step 7000 loss 0.0255 lr 0.000031
[Epoch 5] step 7100 loss 0.0365 lr 0.000031
[Epoch 5] step 7200 loss 0.0141 lr 0.000031
[Epoch 5] step 7300 loss 0.0573 lr 0.000031
[Epoch 5] step 7400 loss 0.0420 lr 0.000031
[Epoch 5] step 7500 loss 0.0465 lr 0.000031
[Epoch 5] step 7600 loss 0.0498 lr 0.000031
[Epoch 5] step 7700 loss 0.0223 lr 0.000030
[Epoch 5] step 7800 loss 0.1998 lr 0.000030
[Epoch 5] step 7900 loss 0.0511 lr 0.000030
[Epoch 5] step 8000 loss 0.0957 lr 0.000030
[Epoch 5] step 8100 loss 0.0622 lr 0.000030
[Epoch 5] step 8200 loss 0.0631 lr 0.000030
[Epoch 5] step 8300 loss 0.1296 lr 0.000030
[Epoch 5] step 8400 loss 0.0907 lr 0.000030
[Epoch 5] step 8500 loss 0.0592 lr 0.000030
[Epoch 5] step 8600 loss 0.1361 lr 0.000030
[Epoch 5] step 8700 loss 0.0416 lr 0.000030
[Epoch 5] step 8800 loss 0.0499 lr 0.000030
[Epoch 5] step 8900 loss 0.0131 lr 0.000030
[Epoch 5] step 9000 loss 0.0787 lr 0.000030
[Epoch 5] step 9100 loss 0.0685 lr 0.000030
[Epoch 5] step 9200 loss 0.0383 lr 0.000030
[Epoch 5] step 9300 loss 0.0438 lr 0.000030
[Epoch 5] step 9400 loss 0.0779 lr 0.000030
[Epoch 5] step 9500 loss 0.0609 lr 0.000030
[Epoch 5] step 9600 loss 0.0644 lr 0.000030
[Epoch 5] step 9700 loss 0.0818 lr 0.000030
[Epoch 5] step 9800 loss 0.0816 lr 0.000030
[Epoch 5] step 9900 loss 0.0571 lr 0.000030
[Validation] global_step 70000 loss 0.2571 accuracy 0.4766
Validation metrics did not improve. Patience: 1/10
[Epoch 5] step 10000 loss 0.0450 lr 0.000030
[Epoch 5] step 10100 loss 0.1199 lr 0.000030
[Epoch 5] step 10200 loss 0.0753 lr 0.000030
[Epoch 5] step 10300 loss 0.0247 lr 0.000030
[Epoch 5] step 10400 loss 0.0925 lr 0.000029
[Epoch 5] step 10500 loss 0.0525 lr 0.000029
[Epoch 5] step 10600 loss 0.0704 lr 0.000029
[Epoch 5] step 10700 loss 0.0719 lr 0.000029
[Epoch 5] step 10800 loss 0.0685 lr 0.000029
[Epoch 5] step 10900 loss 0.1059 lr 0.000029
[Epoch 5] step 11000 loss 0.0624 lr 0.000029
[Epoch 5] step 11100 loss 0.0807 lr 0.000029
[Epoch 5] step 11200 loss 0.2655 lr 0.000029
[Epoch 5] step 11300 loss 0.0454 lr 0.000029
[Epoch 5] step 11400 loss 0.0253 lr 0.000029
[Epoch 5] step 11500 loss 0.0389 lr 0.000029
[Epoch 5] step 11600 loss 0.0805 lr 0.000029
[Epoch 5] step 11700 loss 0.0504 lr 0.000029
[Epoch 5] step 11800 loss 0.0486 lr 0.000029
[Epoch 5] step 11900 loss 0.1343 lr 0.000029
[Epoch 5] step 12000 loss 0.0301 lr 0.000029
[Epoch 5] step 12100 loss 0.0638 lr 0.000029
[Epoch 5] step 12200 loss 0.0260 lr 0.000029
[Epoch 5] step 12300 loss 0.1979 lr 0.000029
[Epoch 5] step 12400 loss 0.0231 lr 0.000029
[Epoch 5] step 12500 loss 0.0154 lr 0.000029
[Epoch 5] step 12600 loss 0.0806 lr 0.000029
[Epoch 5] step 12700 loss 0.0582 lr 0.000029
[Epoch 5] step 12800 loss 0.0349 lr 0.000029
[Epoch 5] step 12900 loss 0.1080 lr 0.000029
[Epoch 5] step 13000 loss 0.0420 lr 0.000029
[Epoch 5] step 13100 loss 0.0682 lr 0.000028
[Epoch 5] step 13200 loss 0.0888 lr 0.000028
[Epoch 5] step 13300 loss 0.0984 lr 0.000028
[Epoch 5] step 13400 loss 0.0784 lr 0.000028
[Epoch 5] step 13500 loss 0.1408 lr 0.000028
[Epoch 5] step 13600 loss 0.1589 lr 0.000028
[Epoch 5] step 13700 loss 0.2319 lr 0.000028
[Epoch 5] step 13800 loss 0.1392 lr 0.000028
[Epoch 5] step 13900 loss 0.0164 lr 0.000028
[Epoch 5] step 14000 loss 0.0226 lr 0.000028
[Epoch 5] step 14100 loss 0.0492 lr 0.000028
[Epoch 5] step 14200 loss 0.0512 lr 0.000028
[Epoch 5] step 14300 loss 0.0250 lr 0.000028
[Epoch 5] step 14400 loss 0.0583 lr 0.000028
[Epoch 5] step 14500 loss 0.1496 lr 0.000028
[Epoch 5] step 14600 loss 0.0963 lr 0.000028
[Epoch 5] step 14700 loss 0.0710 lr 0.000028
[Epoch 5] step 14800 loss 0.0317 lr 0.000028
[Epoch 5] step 14900 loss 0.1538 lr 0.000028
[Validation] global_step 75000 loss 0.2544 accuracy 0.5234
Validation accuracy improved from 0.4805 to 0.5234
Epoch 5 avg loss 0.0692
[Epoch 6] step 0 loss 0.1108 lr 0.000028
[Epoch 6] step 100 loss 0.0550 lr 0.000028
[Epoch 6] step 200 loss 0.0622 lr 0.000028
[Epoch 6] step 300 loss 0.1103 lr 0.000028
[Epoch 6] step 400 loss 0.1106 lr 0.000028
[Epoch 6] step 500 loss 0.0765 lr 0.000028
[Epoch 6] step 600 loss 0.0269 lr 0.000028
[Epoch 6] step 700 loss 0.1799 lr 0.000028
[Epoch 6] step 800 loss 0.0736 lr 0.000027
[Epoch 6] step 900 loss 0.0676 lr 0.000027
[Epoch 6] step 1000 loss 0.1568 lr 0.000027
[Epoch 6] step 1100 loss 0.0536 lr 0.000027
[Epoch 6] step 1200 loss 0.0799 lr 0.000027
[Epoch 6] step 1300 loss 0.1099 lr 0.000027
[Epoch 6] step 1400 loss 0.1090 lr 0.000027
[Epoch 6] step 1500 loss 0.1148 lr 0.000027
[Epoch 6] step 1600 loss 0.0809 lr 0.000027
[Epoch 6] step 1700 loss 0.0831 lr 0.000027
[Epoch 6] step 1800 loss 0.1920 lr 0.000027
[Epoch 6] step 1900 loss 0.1222 lr 0.000027
[Epoch 6] step 2000 loss 0.1421 lr 0.000027
[Epoch 6] step 2100 loss 0.1608 lr 0.000027
[Epoch 6] step 2200 loss 0.2046 lr 0.000027
[Epoch 6] step 2300 loss 0.2352 lr 0.000027
[Epoch 6] step 2400 loss 0.3491 lr 0.000027
[Epoch 6] step 2500 loss 0.4486 lr 0.000027
[Epoch 6] step 2600 loss 0.5644 lr 0.000027
[Epoch 6] step 2700 loss nan lr 0.000027
[Epoch 6] step 2800 loss nan lr 0.000027
[Epoch 6] step 2900 loss nan lr 0.000027
[Epoch 6] step 3000 loss nan lr 0.000027
[Epoch 6] step 3100 loss nan lr 0.000027
[Epoch 6] step 3200 loss nan lr 0.000027
[Epoch 6] step 3300 loss nan lr 0.000027
[Epoch 6] step 3400 loss nan lr 0.000027
[Epoch 6] step 3500 loss nan lr 0.000026
[Epoch 6] step 3600 loss nan lr 0.000026
[Epoch 6] step 3700 loss nan lr 0.000026
[Epoch 6] step 3800 loss nan lr 0.000026
[Epoch 6] step 3900 loss nan lr 0.000026
[Epoch 6] step 4000 loss nan lr 0.000026
[Epoch 6] step 4100 loss nan lr 0.000026
[Epoch 6] step 4200 loss nan lr 0.000026
[Epoch 6] step 4300 loss nan lr 0.000026
[Epoch 6] step 4400 loss nan lr 0.000026
[Epoch 6] step 4500 loss nan lr 0.000026
[Epoch 6] step 4600 loss nan lr 0.000026
[Epoch 6] step 4700 loss nan lr 0.000026
[Epoch 6] step 4800 loss nan lr 0.000026
[Epoch 6] step 4900 loss nan lr 0.000026
