===== Training started at 0 =====
Batch size: 2, LR: 5e-05, Epochs: 10
Steps per file: 50, Grad. accum: 4, Warmup rate: 0.1
Validation dataset loaded with 128 steps, using seed 42, max files 128, steps/file 1, batch size 8
Total validation batches: 16
Warmup steps: 3750, Total optimizer steps: 37500
[Epoch 1] step 0 loss 0.2633 lr 0.000000
[Epoch 1] step 100 loss 0.3571 lr 0.000000
[Epoch 1] step 200 loss 0.5917 lr 0.000001
[Epoch 1] step 300 loss 0.2819 lr 0.000001
[Epoch 1] step 400 loss 0.4280 lr 0.000001
[Epoch 1] step 500 loss 0.5550 lr 0.000002
[Epoch 1] step 600 loss 0.2343 lr 0.000002
[Epoch 1] step 700 loss 0.2336 lr 0.000002
[Epoch 1] step 800 loss 0.1533 lr 0.000003
[Epoch 1] step 900 loss 0.1381 lr 0.000003
[Epoch 1] step 1000 loss 0.2179 lr 0.000003
[Epoch 1] step 1100 loss 0.0902 lr 0.000004
[Epoch 1] step 1200 loss 0.2672 lr 0.000004
[Epoch 1] step 1300 loss 0.1142 lr 0.000004
[Epoch 1] step 1400 loss 0.1245 lr 0.000005
[Epoch 1] step 1500 loss 0.0782 lr 0.000005
[Epoch 1] step 1600 loss 0.1268 lr 0.000005
[Epoch 1] step 1700 loss 0.0609 lr 0.000006
[Epoch 1] step 1800 loss 0.0922 lr 0.000006
[Epoch 1] step 1900 loss 0.1568 lr 0.000006
[Epoch 1] step 2000 loss 0.0466 lr 0.000007
[Epoch 1] step 2100 loss 0.1165 lr 0.000007
[Epoch 1] step 2200 loss 0.0546 lr 0.000007
[Epoch 1] step 2300 loss 0.0642 lr 0.000008
[Epoch 1] step 2400 loss 0.0496 lr 0.000008
[Epoch 1] step 2500 loss 0.1340 lr 0.000008
[Epoch 1] step 2600 loss 0.0821 lr 0.000009
[Epoch 1] step 2700 loss 0.1526 lr 0.000009
[Epoch 1] step 2800 loss 0.0688 lr 0.000009
[Epoch 1] step 2900 loss 0.1451 lr 0.000010
[Epoch 1] step 3000 loss 0.0424 lr 0.000010
[Epoch 1] step 3100 loss 0.0395 lr 0.000010
[Epoch 1] step 3200 loss 0.0669 lr 0.000011
[Epoch 1] step 3300 loss 0.0474 lr 0.000011
[Epoch 1] step 3400 loss 0.0668 lr 0.000011
[Epoch 1] step 3500 loss 0.0910 lr 0.000012
[Epoch 1] step 3600 loss 0.0458 lr 0.000012
[Epoch 1] step 3700 loss 0.0558 lr 0.000012
[Epoch 1] step 3800 loss 0.0247 lr 0.000013
[Epoch 1] step 3900 loss 0.0228 lr 0.000013
[Epoch 1] step 4000 loss 0.1342 lr 0.000013
[Epoch 1] step 4100 loss 0.1100 lr 0.000014
[Epoch 1] step 4200 loss 0.0284 lr 0.000014
[Epoch 1] step 4300 loss 0.0341 lr 0.000014
[Epoch 1] step 4400 loss 0.1441 lr 0.000015
[Epoch 1] step 4500 loss 0.0772 lr 0.000015
[Epoch 1] step 4600 loss 0.0161 lr 0.000015
[Epoch 1] step 4700 loss 0.0231 lr 0.000016
[Epoch 1] step 4800 loss 0.0300 lr 0.000016
[Epoch 1] step 4900 loss 0.1042 lr 0.000016
[Epoch 1] step 5000 loss 0.1192 lr 0.000017
[Epoch 1] step 5100 loss 0.1620 lr 0.000017
[Epoch 1] step 5200 loss 0.0637 lr 0.000017
[Epoch 1] step 5300 loss 0.1260 lr 0.000018
[Epoch 1] step 5400 loss 0.0937 lr 0.000018
[Epoch 1] step 5500 loss 0.1257 lr 0.000018
[Epoch 1] step 5600 loss 0.0352 lr 0.000019
[Epoch 1] step 5700 loss 0.0264 lr 0.000019
[Epoch 1] step 5800 loss 0.0198 lr 0.000019
[Epoch 1] step 5900 loss 0.0432 lr 0.000020
[Epoch 1] step 6000 loss 0.0511 lr 0.000020
[Epoch 1] step 6100 loss 0.1133 lr 0.000020
[Epoch 1] step 6200 loss 0.1016 lr 0.000021
[Epoch 1] step 6300 loss 0.0974 lr 0.000021
[Epoch 1] step 6400 loss 0.0350 lr 0.000021
[Epoch 1] step 6500 loss 0.0288 lr 0.000022
[Epoch 1] step 6600 loss 0.1621 lr 0.000022
[Epoch 1] step 6700 loss 0.2828 lr 0.000022
[Epoch 1] step 6800 loss 0.0327 lr 0.000023
[Epoch 1] step 6900 loss 0.0551 lr 0.000023
[Epoch 1] step 7000 loss 0.0194 lr 0.000023
[Epoch 1] step 7100 loss 0.0670 lr 0.000024
[Epoch 1] step 7200 loss 0.0458 lr 0.000024
[Epoch 1] step 7300 loss 0.0802 lr 0.000024
[Epoch 1] step 7400 loss 0.0748 lr 0.000025
[Epoch 1] step 7500 loss 0.0206 lr 0.000025
[Epoch 1] step 7600 loss 0.0573 lr 0.000025
[Epoch 1] step 7700 loss 0.0499 lr 0.000026
[Epoch 1] step 7800 loss 0.1766 lr 0.000026
[Epoch 1] step 7900 loss 0.0220 lr 0.000026
[Epoch 1] step 8000 loss 0.0214 lr 0.000027
[Epoch 1] step 8100 loss 0.1028 lr 0.000027
[Epoch 1] step 8200 loss 0.0528 lr 0.000027
[Epoch 1] step 8300 loss 0.0366 lr 0.000028
[Epoch 1] step 8400 loss 0.0330 lr 0.000028
[Epoch 1] step 8500 loss 0.0139 lr 0.000028
[Epoch 1] step 8600 loss 0.1190 lr 0.000029
[Epoch 1] step 8700 loss 0.0778 lr 0.000029
[Epoch 1] step 8800 loss 0.0376 lr 0.000029
[Epoch 1] step 8900 loss 0.0884 lr 0.000030
[Epoch 1] step 9000 loss 0.1153 lr 0.000030
[Epoch 1] step 9100 loss 0.0407 lr 0.000030
[Epoch 1] step 9200 loss 0.0503 lr 0.000031
[Epoch 1] step 9300 loss 0.0442 lr 0.000031
[Epoch 1] step 9400 loss 0.0308 lr 0.000031
[Epoch 1] step 9500 loss 0.0583 lr 0.000032
[Epoch 1] step 9600 loss 0.0668 lr 0.000032
[Epoch 1] step 9700 loss 0.1279 lr 0.000032
[Epoch 1] step 9800 loss 0.0218 lr 0.000033
[Epoch 1] step 9900 loss 0.1228 lr 0.000033
[Epoch 1] step 10000 loss 0.0525 lr 0.000033
[Epoch 1] step 10100 loss 0.0501 lr 0.000034
[Epoch 1] step 10200 loss 0.1327 lr 0.000034
[Epoch 1] step 10300 loss 0.0336 lr 0.000034
[Epoch 1] step 10400 loss 0.0676 lr 0.000035
[Epoch 1] step 10500 loss 0.1287 lr 0.000035
[Epoch 1] step 10600 loss 0.0669 lr 0.000035
[Epoch 1] step 10700 loss 0.0469 lr 0.000036
[Epoch 1] step 10800 loss 0.1639 lr 0.000036
[Epoch 1] step 10900 loss 0.0694 lr 0.000036
[Epoch 1] step 11000 loss 0.0455 lr 0.000037
[Epoch 1] step 11100 loss 0.0468 lr 0.000037
[Epoch 1] step 11200 loss 0.0188 lr 0.000037
[Epoch 1] step 11300 loss 0.0778 lr 0.000038
[Epoch 1] step 11400 loss 0.0634 lr 0.000038
[Epoch 1] step 11500 loss 0.0350 lr 0.000038
[Epoch 1] step 11600 loss 0.1135 lr 0.000039
[Epoch 1] step 11700 loss 0.0658 lr 0.000039
[Epoch 1] step 11800 loss 0.0104 lr 0.000039
[Epoch 1] step 11900 loss 0.0347 lr 0.000040
[Epoch 1] step 12000 loss 0.0388 lr 0.000040
[Epoch 1] step 12100 loss 0.0530 lr 0.000040
[Epoch 1] step 12200 loss 0.0433 lr 0.000041
[Epoch 1] step 12300 loss 0.0461 lr 0.000041
[Epoch 1] step 12400 loss 0.0992 lr 0.000041
[Epoch 1] step 12500 loss 0.0300 lr 0.000042
[Epoch 1] step 12600 loss 0.0730 lr 0.000042
[Epoch 1] step 12700 loss 0.0509 lr 0.000042
[Epoch 1] step 12800 loss 0.0301 lr 0.000043
[Epoch 1] step 12900 loss 0.0931 lr 0.000043
[Epoch 1] step 13000 loss 0.0387 lr 0.000043
[Epoch 1] step 13100 loss 0.0507 lr 0.000044
[Epoch 1] step 13200 loss 0.1597 lr 0.000044
[Epoch 1] step 13300 loss 0.0420 lr 0.000044
[Epoch 1] step 13400 loss 0.0154 lr 0.000045
[Epoch 1] step 13500 loss 0.0695 lr 0.000045
[Epoch 1] step 13600 loss 0.1698 lr 0.000045
[Epoch 1] step 13700 loss 0.2280 lr 0.000046
[Epoch 1] step 13800 loss 0.0446 lr 0.000046
[Epoch 1] step 13900 loss 0.0479 lr 0.000046
[Epoch 1] step 14000 loss 0.0526 lr 0.000047
[Epoch 1] step 14100 loss 0.1119 lr 0.000047
[Epoch 1] step 14200 loss 0.0248 lr 0.000047
[Epoch 1] step 14300 loss 0.0233 lr 0.000048
[Epoch 1] step 14400 loss 0.0782 lr 0.000048
[Epoch 1] step 14500 loss 0.1131 lr 0.000048
[Epoch 1] step 14600 loss 0.0264 lr 0.000049
[Epoch 1] step 14700 loss 0.1035 lr 0.000049
[Epoch 1] step 14800 loss 0.0764 lr 0.000049
[Epoch 1] step 14900 loss 0.0361 lr 0.000050
Epoch 1 avg loss 0.0850
[Epoch 2] step 0 loss 0.0884 lr 0.000050
[Epoch 2] step 100 loss 0.0722 lr 0.000050
[Epoch 2] step 200 loss 0.0414 lr 0.000050
[Epoch 2] step 300 loss 0.0529 lr 0.000050
[Epoch 2] step 400 loss 0.0182 lr 0.000050
[Epoch 2] step 500 loss 0.0347 lr 0.000050
[Epoch 2] step 600 loss 0.0884 lr 0.000050
[Epoch 2] step 700 loss 0.0710 lr 0.000050
[Epoch 2] step 800 loss 0.0476 lr 0.000050
[Epoch 2] step 900 loss 0.0601 lr 0.000050
[Epoch 2] step 1000 loss 0.0449 lr 0.000050
[Epoch 2] step 1100 loss 0.0125 lr 0.000050
[Epoch 2] step 1200 loss 0.2414 lr 0.000050
[Epoch 2] step 1300 loss 0.0583 lr 0.000050
[Epoch 2] step 1400 loss 0.1097 lr 0.000049
[Epoch 2] step 1500 loss 0.0418 lr 0.000049
[Epoch 2] step 1600 loss 0.0519 lr 0.000049
[Epoch 2] step 1700 loss 0.1095 lr 0.000049
[Epoch 2] step 1800 loss 0.0275 lr 0.000049
[Epoch 2] step 1900 loss 0.0618 lr 0.000049
[Epoch 2] step 2000 loss 0.0739 lr 0.000049
[Epoch 2] step 2100 loss 0.2166 lr 0.000049
[Epoch 2] step 2200 loss 0.0753 lr 0.000049
[Epoch 2] step 2300 loss 0.0039 lr 0.000049
[Epoch 2] step 2400 loss 0.0892 lr 0.000049
[Epoch 2] step 2500 loss 0.0571 lr 0.000049
[Epoch 2] step 2600 loss 0.0265 lr 0.000049
[Epoch 2] step 2700 loss 0.0597 lr 0.000049
[Epoch 2] step 2800 loss 0.1720 lr 0.000049
[Epoch 2] step 2900 loss 0.0621 lr 0.000049
[Validation] global_step 18000 loss 0.2138 accuracy 0.4531
Validation accuracy improved from 0.0000 to 0.4531, Validation loss improved from inf to 0.2138
[Epoch 2] step 3000 loss 0.0348 lr 0.000049
[Epoch 2] step 3100 loss 0.0351 lr 0.000049
[Epoch 2] step 3200 loss 0.1058 lr 0.000049
[Epoch 2] step 3300 loss 0.0186 lr 0.000049
[Epoch 2] step 3400 loss 0.0684 lr 0.000049
[Epoch 2] step 3500 loss 0.0525 lr 0.000049
[Epoch 2] step 3600 loss 0.0353 lr 0.000049
[Epoch 2] step 3700 loss 0.0767 lr 0.000049
[Epoch 2] step 3800 loss 0.1114 lr 0.000049
[Epoch 2] step 3900 loss 0.1446 lr 0.000049
[Epoch 2] step 4000 loss 0.0208 lr 0.000049
[Epoch 2] step 4100 loss 0.2452 lr 0.000048
[Epoch 2] step 4200 loss 0.0372 lr 0.000048
[Epoch 2] step 4300 loss 0.0912 lr 0.000048
[Epoch 2] step 4400 loss 0.0659 lr 0.000048
[Epoch 2] step 4500 loss 0.0667 lr 0.000048
[Epoch 2] step 4600 loss 0.0157 lr 0.000048
[Epoch 2] step 4700 loss 0.1197 lr 0.000048
[Epoch 2] step 4800 loss 0.0638 lr 0.000048
[Epoch 2] step 4900 loss 0.1061 lr 0.000048
[Epoch 2] step 5000 loss 0.0260 lr 0.000048
[Epoch 2] step 5100 loss 0.0491 lr 0.000048
[Epoch 2] step 5200 loss 0.0558 lr 0.000048
[Epoch 2] step 5300 loss 0.0657 lr 0.000048
[Epoch 2] step 5400 loss 0.0249 lr 0.000048
[Epoch 2] step 5500 loss 0.0759 lr 0.000048
[Epoch 2] step 5600 loss 0.0889 lr 0.000048
[Epoch 2] step 5700 loss 0.0766 lr 0.000048
[Epoch 2] step 5800 loss 0.1620 lr 0.000048
[Epoch 2] step 5900 loss 0.0661 lr 0.000048
[Validation] global_step 21000 loss 0.2306 accuracy 0.4453
Validation metrics did not improve. Patience: 1/10
[Epoch 2] step 6000 loss 0.0585 lr 0.000048
[Epoch 2] step 6100 loss 0.0426 lr 0.000048
[Epoch 2] step 6200 loss 0.0746 lr 0.000048
[Epoch 2] step 6300 loss 0.0614 lr 0.000048
[Epoch 2] step 6400 loss 0.0785 lr 0.000048
[Epoch 2] step 6500 loss 0.0841 lr 0.000048
[Epoch 2] step 6600 loss 0.0719 lr 0.000048
[Epoch 2] step 6700 loss 0.0264 lr 0.000048
[Epoch 2] step 6800 loss 0.1112 lr 0.000047
[Epoch 2] step 6900 loss 0.0898 lr 0.000047
[Epoch 2] step 7000 loss 0.0257 lr 0.000047
[Epoch 2] step 7100 loss 0.0954 lr 0.000047
[Epoch 2] step 7200 loss 0.0874 lr 0.000047
[Epoch 2] step 7300 loss 0.0404 lr 0.000047
[Epoch 2] step 7400 loss 0.1185 lr 0.000047
[Epoch 2] step 7500 loss 0.1820 lr 0.000047
[Epoch 2] step 7600 loss 0.0181 lr 0.000047
[Epoch 2] step 7700 loss 0.0624 lr 0.000047
[Epoch 2] step 7800 loss 0.0686 lr 0.000047
[Epoch 2] step 7900 loss 0.0617 lr 0.000047
[Epoch 2] step 8000 loss 0.0715 lr 0.000047
[Epoch 2] step 8100 loss 0.1102 lr 0.000047
[Epoch 2] step 8200 loss 0.1285 lr 0.000047
[Epoch 2] step 8300 loss 0.0642 lr 0.000047
[Epoch 2] step 8400 loss 0.1680 lr 0.000047
[Epoch 2] step 8500 loss 0.0816 lr 0.000047
[Epoch 2] step 8600 loss 0.0576 lr 0.000047
[Epoch 2] step 8700 loss 0.0808 lr 0.000047
[Epoch 2] step 8800 loss 0.1125 lr 0.000047
[Epoch 2] step 8900 loss 0.0406 lr 0.000047
[Validation] global_step 24000 loss 0.2590 accuracy 0.4453
Validation metrics did not improve. Patience: 2/10
[Epoch 2] step 9000 loss 0.0280 lr 0.000047
[Epoch 2] step 9100 loss 0.0612 lr 0.000047
[Epoch 2] step 9200 loss 0.0963 lr 0.000047
[Epoch 2] step 9300 loss 0.0764 lr 0.000047
[Epoch 2] step 9400 loss 0.0793 lr 0.000047
[Epoch 2] step 9500 loss 0.1055 lr 0.000046
[Epoch 2] step 9600 loss 0.0415 lr 0.000046
[Epoch 2] step 9700 loss 0.0378 lr 0.000046
[Epoch 2] step 9800 loss 0.1315 lr 0.000046
[Epoch 2] step 9900 loss 0.2125 lr 0.000046
[Epoch 2] step 10000 loss 0.0309 lr 0.000046
[Epoch 2] step 10100 loss 0.0533 lr 0.000046
[Epoch 2] step 10200 loss 0.0319 lr 0.000046
[Epoch 2] step 10300 loss 0.0332 lr 0.000046
[Epoch 2] step 10400 loss 0.2361 lr 0.000046
[Epoch 2] step 10500 loss 0.0728 lr 0.000046
[Epoch 2] step 10600 loss 0.0593 lr 0.000046
[Epoch 2] step 10700 loss 0.0557 lr 0.000046
[Epoch 2] step 10800 loss 0.0321 lr 0.000046
[Epoch 2] step 10900 loss 0.2086 lr 0.000046
[Epoch 2] step 11000 loss 0.0452 lr 0.000046
[Epoch 2] step 11100 loss 0.0551 lr 0.000046
[Epoch 2] step 11200 loss 0.0362 lr 0.000046
[Epoch 2] step 11300 loss 0.2418 lr 0.000046
[Epoch 2] step 11400 loss 0.0246 lr 0.000046
[Epoch 2] step 11500 loss 0.0318 lr 0.000046
[Epoch 2] step 11600 loss 0.0410 lr 0.000046
[Epoch 2] step 11700 loss 0.0851 lr 0.000046
[Epoch 2] step 11800 loss 0.1131 lr 0.000046
[Epoch 2] step 11900 loss 0.0819 lr 0.000046
[Validation] global_step 27000 loss 0.2534 accuracy 0.4688
Validation accuracy improved from 0.4531 to 0.4688
[Epoch 2] step 12000 loss 0.0298 lr 0.000046
[Epoch 2] step 12100 loss 0.0404 lr 0.000046
[Epoch 2] step 12200 loss 0.0474 lr 0.000045
[Epoch 2] step 12300 loss 0.0770 lr 0.000045
[Epoch 2] step 12400 loss 0.0444 lr 0.000045
[Epoch 2] step 12500 loss 0.0491 lr 0.000045
[Epoch 2] step 12600 loss 0.1622 lr 0.000045
[Epoch 2] step 12700 loss 0.1005 lr 0.000045
[Epoch 2] step 12800 loss 0.0374 lr 0.000045
[Epoch 2] step 12900 loss 0.1095 lr 0.000045
[Epoch 2] step 13000 loss 0.0971 lr 0.000045
[Epoch 2] step 13100 loss 0.0694 lr 0.000045
[Epoch 2] step 13200 loss 0.1507 lr 0.000045
[Epoch 2] step 13300 loss 0.0544 lr 0.000045
[Epoch 2] step 13400 loss 0.0529 lr 0.000045
[Epoch 2] step 13500 loss 0.0980 lr 0.000045
[Epoch 2] step 13600 loss 0.0571 lr 0.000045
[Epoch 2] step 13700 loss 0.0742 lr 0.000045
[Epoch 2] step 13800 loss 0.0490 lr 0.000045
[Epoch 2] step 13900 loss 0.0384 lr 0.000045
[Epoch 2] step 14000 loss 0.0443 lr 0.000045
[Epoch 2] step 14100 loss 0.1447 lr 0.000045
[Epoch 2] step 14200 loss 0.1596 lr 0.000045
[Epoch 2] step 14300 loss 0.0493 lr 0.000045
[Epoch 2] step 14400 loss 0.1139 lr 0.000045
[Epoch 2] step 14500 loss 0.0183 lr 0.000045
[Epoch 2] step 14600 loss 0.0580 lr 0.000045
[Epoch 2] step 14700 loss 0.0389 lr 0.000045
[Epoch 2] step 14800 loss 0.0446 lr 0.000045
[Epoch 2] step 14900 loss 0.0524 lr 0.000044
[Validation] global_step 30000 loss 0.2500 accuracy 0.4609
Validation metrics did not improve. Patience: 1/10
Epoch 2 avg loss 0.0682
[Epoch 3] step 0 loss 0.0143 lr 0.000044
[Epoch 3] step 100 loss 0.0238 lr 0.000044
[Epoch 3] step 200 loss 0.1271 lr 0.000044
[Epoch 3] step 300 loss 0.0515 lr 0.000044
[Epoch 3] step 400 loss 0.0438 lr 0.000044
[Epoch 3] step 500 loss 0.0216 lr 0.000044
[Epoch 3] step 600 loss 0.0802 lr 0.000044
[Epoch 3] step 700 loss 0.0814 lr 0.000044
[Epoch 3] step 800 loss 0.0876 lr 0.000044
[Epoch 3] step 900 loss 0.0953 lr 0.000044
[Epoch 3] step 1000 loss 0.0687 lr 0.000044
[Epoch 3] step 1100 loss 0.0913 lr 0.000044
[Epoch 3] step 1200 loss 0.0779 lr 0.000044
[Epoch 3] step 1300 loss 0.0635 lr 0.000044
[Epoch 3] step 1400 loss 0.0197 lr 0.000044
[Epoch 3] step 1500 loss 0.0466 lr 0.000044
[Epoch 3] step 1600 loss 0.0111 lr 0.000044
[Epoch 3] step 1700 loss 0.0574 lr 0.000044
[Epoch 3] step 1800 loss 0.1580 lr 0.000044
[Epoch 3] step 1900 loss 0.2099 lr 0.000044
[Epoch 3] step 2000 loss 0.0479 lr 0.000044
[Epoch 3] step 2100 loss 0.0644 lr 0.000044
[Epoch 3] step 2200 loss 0.0464 lr 0.000044
[Epoch 3] step 2300 loss 0.0310 lr 0.000044
[Epoch 3] step 2400 loss 0.0535 lr 0.000044
[Epoch 3] step 2500 loss 0.0450 lr 0.000044
[Epoch 3] step 2600 loss 0.0480 lr 0.000043
[Epoch 3] step 2700 loss 0.0341 lr 0.000043
[Epoch 3] step 2800 loss 0.0469 lr 0.000043
[Epoch 3] step 2900 loss 0.0413 lr 0.000043
[Validation] global_step 33000 loss 0.2423 accuracy 0.4453
Validation metrics did not improve. Patience: 2/10
[Epoch 3] step 3000 loss 0.0618 lr 0.000043
[Epoch 3] step 3100 loss 0.0658 lr 0.000043
[Epoch 3] step 3200 loss 0.0998 lr 0.000043
[Epoch 3] step 3300 loss 0.0297 lr 0.000043
[Epoch 3] step 3400 loss 0.0376 lr 0.000043
[Epoch 3] step 3500 loss 0.1066 lr 0.000043
[Epoch 3] step 3600 loss 0.0853 lr 0.000043
[Epoch 3] step 3700 loss 0.0618 lr 0.000043
[Epoch 3] step 3800 loss 0.0582 lr 0.000043
[Epoch 3] step 3900 loss 0.0726 lr 0.000043
[Epoch 3] step 4000 loss 0.0309 lr 0.000043
[Epoch 3] step 4100 loss 0.1138 lr 0.000043
[Epoch 3] step 4200 loss 0.0412 lr 0.000043
[Epoch 3] step 4300 loss 0.0275 lr 0.000043
[Epoch 3] step 4400 loss 0.1449 lr 0.000043
[Epoch 3] step 4500 loss 0.0894 lr 0.000043
[Epoch 3] step 4600 loss 0.0666 lr 0.000043
[Epoch 3] step 4700 loss 0.0807 lr 0.000043
[Epoch 3] step 4800 loss 0.0563 lr 0.000043
[Epoch 3] step 4900 loss 0.0734 lr 0.000043
[Epoch 3] step 5000 loss 0.0516 lr 0.000043
[Epoch 3] step 5100 loss 0.0441 lr 0.000043
[Epoch 3] step 5200 loss 0.1963 lr 0.000043
[Epoch 3] step 5300 loss 0.1248 lr 0.000042
[Epoch 3] step 5400 loss 0.0550 lr 0.000042
[Epoch 3] step 5500 loss 0.1795 lr 0.000042
[Epoch 3] step 5600 loss 0.0270 lr 0.000042
[Epoch 3] step 5700 loss 0.0476 lr 0.000042
[Epoch 3] step 5800 loss 0.0376 lr 0.000042
[Epoch 3] step 5900 loss 0.0228 lr 0.000042
[Validation] global_step 36000 loss 0.2373 accuracy 0.4961
Validation accuracy improved from 0.4688 to 0.4961
[Epoch 3] step 6000 loss 0.0618 lr 0.000042
[Epoch 3] step 6100 loss 0.0627 lr 0.000042
[Epoch 3] step 6200 loss 0.0336 lr 0.000042
[Epoch 3] step 6300 loss 0.0346 lr 0.000042
[Epoch 3] step 6400 loss 0.0438 lr 0.000042
[Epoch 3] step 6500 loss 0.0417 lr 0.000042
[Epoch 3] step 6600 loss 0.1148 lr 0.000042
[Epoch 3] step 6700 loss 0.0161 lr 0.000042
[Epoch 3] step 6800 loss 0.0586 lr 0.000042
[Epoch 3] step 6900 loss 0.0648 lr 0.000042
[Epoch 3] step 7000 loss 0.0490 lr 0.000042
[Epoch 3] step 7100 loss 0.0466 lr 0.000042
[Epoch 3] step 7200 loss 0.0522 lr 0.000042
[Epoch 3] step 7300 loss 0.0673 lr 0.000042
[Epoch 3] step 7400 loss 0.0297 lr 0.000042
[Epoch 3] step 7500 loss 0.1061 lr 0.000042
[Epoch 3] step 7600 loss 0.1095 lr 0.000042
[Epoch 3] step 7700 loss 0.0111 lr 0.000042
[Epoch 3] step 7800 loss 0.0740 lr 0.000042
[Epoch 3] step 7900 loss 0.0582 lr 0.000042
[Epoch 3] step 8000 loss 0.0681 lr 0.000041
[Epoch 3] step 8100 loss 0.0172 lr 0.000041
[Epoch 3] step 8200 loss 0.0776 lr 0.000041
[Epoch 3] step 8300 loss 0.1331 lr 0.000041
[Epoch 3] step 8400 loss 0.0546 lr 0.000041
[Epoch 3] step 8500 loss 0.0184 lr 0.000041
[Epoch 3] step 8600 loss 0.0270 lr 0.000041
[Epoch 3] step 8700 loss 0.0341 lr 0.000041
[Epoch 3] step 8800 loss 0.0739 lr 0.000041
[Epoch 3] step 8900 loss 0.0659 lr 0.000041
[Validation] global_step 39000 loss 0.2387 accuracy 0.4844
Validation metrics did not improve. Patience: 1/10
[Epoch 3] step 9000 loss 0.0057 lr 0.000041
[Epoch 3] step 9100 loss 0.0443 lr 0.000041
[Epoch 3] step 9200 loss 0.0328 lr 0.000041
[Epoch 3] step 9300 loss 0.0301 lr 0.000041
[Epoch 3] step 9400 loss 0.0358 lr 0.000041
[Epoch 3] step 9500 loss 0.0858 lr 0.000041
[Epoch 3] step 9600 loss 0.0422 lr 0.000041
[Epoch 3] step 9700 loss 0.0435 lr 0.000041
[Epoch 3] step 9800 loss 0.0254 lr 0.000041
[Epoch 3] step 9900 loss 0.0728 lr 0.000041
[Epoch 3] step 10000 loss 0.1031 lr 0.000041
[Epoch 3] step 10100 loss 0.0406 lr 0.000041
[Epoch 3] step 10200 loss 0.0992 lr 0.000041
[Epoch 3] step 10300 loss 0.0296 lr 0.000041
[Epoch 3] step 10400 loss 0.0158 lr 0.000041
[Epoch 3] step 10500 loss 0.0357 lr 0.000041
[Epoch 3] step 10600 loss 0.0258 lr 0.000041
[Epoch 3] step 10700 loss 0.0376 lr 0.000040
[Epoch 3] step 10800 loss 0.0187 lr 0.000040
[Epoch 3] step 10900 loss 0.0655 lr 0.000040
[Epoch 3] step 11000 loss 0.0284 lr 0.000040
[Epoch 3] step 11100 loss 0.0550 lr 0.000040
[Epoch 3] step 11200 loss 0.0133 lr 0.000040
[Epoch 3] step 11300 loss 0.0302 lr 0.000040
[Epoch 3] step 11400 loss 0.0489 lr 0.000040
[Epoch 3] step 11500 loss 0.0345 lr 0.000040
[Epoch 3] step 11600 loss 0.0507 lr 0.000040
[Epoch 3] step 11700 loss 0.0393 lr 0.000040
[Epoch 3] step 11800 loss 0.0596 lr 0.000040
[Epoch 3] step 11900 loss 0.0465 lr 0.000040
[Validation] global_step 42000 loss 0.2304 accuracy 0.4766
Validation metrics did not improve. Patience: 2/10
[Epoch 3] step 12000 loss 0.0571 lr 0.000040
[Epoch 3] step 12100 loss 0.1108 lr 0.000040
[Epoch 3] step 12200 loss 0.0611 lr 0.000040
[Epoch 3] step 12300 loss 0.0181 lr 0.000040
[Epoch 3] step 12400 loss 0.0401 lr 0.000040
[Epoch 3] step 12500 loss 0.1461 lr 0.000040
[Epoch 3] step 12600 loss 0.0403 lr 0.000040
[Epoch 3] step 12700 loss 0.0648 lr 0.000040
[Epoch 3] step 12800 loss 0.0876 lr 0.000040
[Epoch 3] step 12900 loss 0.0941 lr 0.000040
[Epoch 3] step 13000 loss 0.0320 lr 0.000040
[Epoch 3] step 13100 loss 0.0609 lr 0.000040
[Epoch 3] step 13200 loss 0.0195 lr 0.000040
[Epoch 3] step 13300 loss 0.0778 lr 0.000040
[Epoch 3] step 13400 loss 0.0535 lr 0.000039
[Epoch 3] step 13500 loss 0.0775 lr 0.000039
[Epoch 3] step 13600 loss 0.0244 lr 0.000039
[Epoch 3] step 13700 loss 0.0092 lr 0.000039
[Epoch 3] step 13800 loss 0.0531 lr 0.000039
[Epoch 3] step 13900 loss 0.0321 lr 0.000039
[Epoch 3] step 14000 loss 0.0997 lr 0.000039
[Epoch 3] step 14100 loss 0.0700 lr 0.000039
[Epoch 3] step 14200 loss 0.0901 lr 0.000039
[Epoch 3] step 14300 loss 0.0208 lr 0.000039
[Epoch 3] step 14400 loss 0.0465 lr 0.000039
[Epoch 3] step 14500 loss 0.0747 lr 0.000039
[Epoch 3] step 14600 loss 0.0988 lr 0.000039
[Epoch 3] step 14700 loss 0.0324 lr 0.000039
[Epoch 3] step 14800 loss 0.0922 lr 0.000039
[Epoch 3] step 14900 loss 0.0676 lr 0.000039
[Validation] global_step 45000 loss 0.2158 accuracy 0.5117
Validation accuracy improved from 0.4961 to 0.5117
Epoch 3 avg loss 0.0689
[Epoch 4] step 0 loss 0.0412 lr 0.000039
[Epoch 4] step 100 loss 0.0833 lr 0.000039
[Epoch 4] step 200 loss 0.0714 lr 0.000039
[Epoch 4] step 300 loss 0.1115 lr 0.000039
[Epoch 4] step 400 loss 0.0957 lr 0.000039
[Epoch 4] step 500 loss 0.0323 lr 0.000039
[Epoch 4] step 600 loss 0.0848 lr 0.000039
[Epoch 4] step 700 loss 0.1730 lr 0.000039
[Epoch 4] step 800 loss 0.1102 lr 0.000039
[Epoch 4] step 900 loss 0.0589 lr 0.000039
[Epoch 4] step 1000 loss 0.0568 lr 0.000039
[Epoch 4] step 1100 loss 0.0945 lr 0.000038
[Epoch 4] step 1200 loss 0.0376 lr 0.000038
[Epoch 4] step 1300 loss 0.0560 lr 0.000038
[Epoch 4] step 1400 loss 0.0490 lr 0.000038
[Epoch 4] step 1500 loss 0.0651 lr 0.000038
[Epoch 4] step 1600 loss 0.0180 lr 0.000038
[Epoch 4] step 1700 loss 0.0523 lr 0.000038
[Epoch 4] step 1800 loss 0.0443 lr 0.000038
[Epoch 4] step 1900 loss 0.0498 lr 0.000038
[Epoch 4] step 2000 loss 0.0690 lr 0.000038
[Epoch 4] step 2100 loss 0.0558 lr 0.000038
[Epoch 4] step 2200 loss 0.0838 lr 0.000038
[Epoch 4] step 2300 loss 0.0504 lr 0.000038
[Epoch 4] step 2400 loss 0.1998 lr 0.000038
[Epoch 4] step 2500 loss 0.0778 lr 0.000038
[Epoch 4] step 2600 loss 0.0422 lr 0.000038
[Epoch 4] step 2700 loss 0.0345 lr 0.000038
[Epoch 4] step 2800 loss 0.0806 lr 0.000038
[Epoch 4] step 2900 loss 0.0904 lr 0.000038
[Validation] global_step 48000 loss 0.2383 accuracy 0.4609
Validation metrics did not improve. Patience: 1/10
[Epoch 4] step 3000 loss 0.0533 lr 0.000038
[Epoch 4] step 3100 loss 0.0413 lr 0.000038
[Epoch 4] step 3200 loss 0.0082 lr 0.000038
[Epoch 4] step 3300 loss 0.0278 lr 0.000038
[Epoch 4] step 3400 loss 0.0585 lr 0.000038
[Epoch 4] step 3500 loss 0.0612 lr 0.000038
[Epoch 4] step 3600 loss 0.0901 lr 0.000038
[Epoch 4] step 3700 loss 0.0551 lr 0.000038
[Epoch 4] step 3800 loss 0.0863 lr 0.000037
[Epoch 4] step 3900 loss 0.1031 lr 0.000037
[Epoch 4] step 4000 loss 0.0733 lr 0.000037
[Epoch 4] step 4100 loss 0.2207 lr 0.000037
[Epoch 4] step 4200 loss 0.0559 lr 0.000037
[Epoch 4] step 4300 loss 0.0181 lr 0.000037
[Epoch 4] step 4400 loss 0.0539 lr 0.000037
[Epoch 4] step 4500 loss 0.0379 lr 0.000037
[Epoch 4] step 4600 loss 0.0668 lr 0.000037
[Epoch 4] step 4700 loss 0.0223 lr 0.000037
[Epoch 4] step 4800 loss 0.0705 lr 0.000037
[Epoch 4] step 4900 loss 0.0948 lr 0.000037
[Epoch 4] step 5000 loss 0.0138 lr 0.000037
[Epoch 4] step 5100 loss 0.0262 lr 0.000037
[Epoch 4] step 5200 loss 0.0428 lr 0.000037
[Epoch 4] step 5300 loss 0.0451 lr 0.000037
[Epoch 4] step 5400 loss 0.0175 lr 0.000037
[Epoch 4] step 5500 loss 0.0325 lr 0.000037
[Epoch 4] step 5600 loss 0.0859 lr 0.000037
[Epoch 4] step 5700 loss 0.0395 lr 0.000037
[Epoch 4] step 5800 loss 0.0767 lr 0.000037
[Epoch 4] step 5900 loss 0.0417 lr 0.000037
[Validation] global_step 51000 loss 0.2315 accuracy 0.4844
Validation metrics did not improve. Patience: 2/10
[Epoch 4] step 6000 loss 0.0869 lr 0.000037
[Epoch 4] step 6100 loss 0.0745 lr 0.000037
[Epoch 4] step 6200 loss 0.0119 lr 0.000037
[Epoch 4] step 6300 loss 0.0780 lr 0.000037
[Epoch 4] step 6400 loss 0.0357 lr 0.000037
[Epoch 4] step 6500 loss 0.1371 lr 0.000036
[Epoch 4] step 6600 loss 0.1133 lr 0.000036
[Epoch 4] step 6700 loss 0.0524 lr 0.000036
[Epoch 4] step 6800 loss 0.1078 lr 0.000036
[Epoch 4] step 6900 loss 0.0557 lr 0.000036
[Epoch 4] step 7000 loss 0.0363 lr 0.000036
[Epoch 4] step 7100 loss 0.0923 lr 0.000036
[Epoch 4] step 7200 loss 0.0715 lr 0.000036
[Epoch 4] step 7300 loss 0.0329 lr 0.000036
[Epoch 4] step 7400 loss 0.0843 lr 0.000036
[Epoch 4] step 7500 loss 0.0518 lr 0.000036
[Epoch 4] step 7600 loss 0.0341 lr 0.000036
[Epoch 4] step 7700 loss 0.0269 lr 0.000036
[Epoch 4] step 7800 loss 0.0371 lr 0.000036
[Epoch 4] step 7900 loss 0.0558 lr 0.000036
[Epoch 4] step 8000 loss 0.0215 lr 0.000036
[Epoch 4] step 8100 loss 0.0525 lr 0.000036
[Epoch 4] step 8200 loss 0.1011 lr 0.000036
[Epoch 4] step 8300 loss 0.0922 lr 0.000036
[Epoch 4] step 8400 loss 0.0399 lr 0.000036
[Epoch 4] step 8500 loss 0.0270 lr 0.000036
[Epoch 4] step 8600 loss 0.0321 lr 0.000036
[Epoch 4] step 8700 loss 0.0612 lr 0.000036
[Epoch 4] step 8800 loss 0.1170 lr 0.000036
[Epoch 4] step 8900 loss 0.0633 lr 0.000036
[Validation] global_step 54000 loss 0.2381 accuracy 0.4844
Validation metrics did not improve. Patience: 3/10
[Epoch 4] step 9000 loss 0.0652 lr 0.000036
[Epoch 4] step 9100 loss 0.0581 lr 0.000036
[Epoch 4] step 9200 loss 0.0827 lr 0.000035
[Epoch 4] step 9300 loss 0.1737 lr 0.000035
[Epoch 4] step 9400 loss 0.0383 lr 0.000035
[Epoch 4] step 9500 loss 0.0825 lr 0.000035
[Epoch 4] step 9600 loss 0.0431 lr 0.000035
[Epoch 4] step 9700 loss 0.0803 lr 0.000035
[Epoch 4] step 9800 loss 0.1783 lr 0.000035
[Epoch 4] step 9900 loss 0.0219 lr 0.000035
[Epoch 4] step 10000 loss 0.1550 lr 0.000035
[Epoch 4] step 10100 loss 0.0220 lr 0.000035
[Epoch 4] step 10200 loss 0.0444 lr 0.000035
[Epoch 4] step 10300 loss 0.0863 lr 0.000035
[Epoch 4] step 10400 loss 0.0230 lr 0.000035
[Epoch 4] step 10500 loss 0.0378 lr 0.000035
[Epoch 4] step 10600 loss 0.0826 lr 0.000035
[Epoch 4] step 10700 loss 0.0241 lr 0.000035
[Epoch 4] step 10800 loss 0.1012 lr 0.000035
[Epoch 4] step 10900 loss 0.0538 lr 0.000035
[Epoch 4] step 11000 loss 0.0704 lr 0.000035
[Epoch 4] step 11100 loss 0.0899 lr 0.000035
[Epoch 4] step 11200 loss 0.0366 lr 0.000035
[Epoch 4] step 11300 loss 0.0320 lr 0.000035
[Epoch 4] step 11400 loss 0.0425 lr 0.000035
[Epoch 4] step 11500 loss 0.0715 lr 0.000035
[Epoch 4] step 11600 loss 0.0448 lr 0.000035
[Epoch 4] step 11700 loss 0.0265 lr 0.000035
[Epoch 4] step 11800 loss 0.0748 lr 0.000035
[Epoch 4] step 11900 loss 0.0598 lr 0.000034
[Validation] global_step 57000 loss 0.2223 accuracy 0.4688
Validation metrics did not improve. Patience: 4/10
[Epoch 4] step 12000 loss 0.1180 lr 0.000034
[Epoch 4] step 12100 loss 0.0179 lr 0.000034
[Epoch 4] step 12200 loss 0.0784 lr 0.000034
[Epoch 4] step 12300 loss 0.0417 lr 0.000034
[Epoch 4] step 12400 loss 0.0389 lr 0.000034
[Epoch 4] step 12500 loss 0.2280 lr 0.000034
[Epoch 4] step 12600 loss 0.0554 lr 0.000034
[Epoch 4] step 12700 loss 0.0693 lr 0.000034
[Epoch 4] step 12800 loss 0.1480 lr 0.000034
[Epoch 4] step 12900 loss 0.1133 lr 0.000034
[Epoch 4] step 13000 loss 0.0357 lr 0.000034
[Epoch 4] step 13100 loss 0.0399 lr 0.000034
[Epoch 4] step 13200 loss 0.0838 lr 0.000034
[Epoch 4] step 13300 loss 0.0498 lr 0.000034
[Epoch 4] step 13400 loss 0.0226 lr 0.000034
[Epoch 4] step 13500 loss 0.1123 lr 0.000034
[Epoch 4] step 13600 loss 0.0920 lr 0.000034
[Epoch 4] step 13700 loss 0.0461 lr 0.000034
[Epoch 4] step 13800 loss 0.0625 lr 0.000034
[Epoch 4] step 13900 loss 0.0759 lr 0.000034
[Epoch 4] step 14000 loss 0.0600 lr 0.000034
[Epoch 4] step 14100 loss 0.1202 lr 0.000034
[Epoch 4] step 14200 loss 0.0722 lr 0.000034
[Epoch 4] step 14300 loss 0.0291 lr 0.000034
[Epoch 4] step 14400 loss 0.0654 lr 0.000034
[Epoch 4] step 14500 loss 0.0223 lr 0.000034
[Epoch 4] step 14600 loss 0.0241 lr 0.000033
[Epoch 4] step 14700 loss 0.0438 lr 0.000033
[Epoch 4] step 14800 loss 0.0650 lr 0.000033
[Epoch 4] step 14900 loss 0.0261 lr 0.000033
[Validation] global_step 60000 loss 0.2217 accuracy 0.4727
Validation metrics did not improve. Patience: 5/10
Epoch 4 avg loss 0.0662
[Epoch 5] step 0 loss 0.0459 lr 0.000033
[Epoch 5] step 100 loss 0.1242 lr 0.000033
[Epoch 5] step 200 loss 0.1118 lr 0.000033
[Epoch 5] step 300 loss 0.0959 lr 0.000033
[Epoch 5] step 400 loss 0.0548 lr 0.000033
[Epoch 5] step 500 loss 0.0401 lr 0.000033
[Epoch 5] step 600 loss 0.1307 lr 0.000033
[Epoch 5] step 700 loss 0.0409 lr 0.000033
[Epoch 5] step 800 loss 0.0171 lr 0.000033
[Epoch 5] step 900 loss 0.0505 lr 0.000033
[Epoch 5] step 1000 loss 0.0714 lr 0.000033
[Epoch 5] step 1100 loss 0.0695 lr 0.000033
[Epoch 5] step 1200 loss 0.0145 lr 0.000033
[Epoch 5] step 1300 loss 0.0688 lr 0.000033
[Epoch 5] step 1400 loss 0.1045 lr 0.000033
[Epoch 5] step 1500 loss 0.1106 lr 0.000033
[Epoch 5] step 1600 loss 0.2368 lr 0.000033
[Epoch 5] step 1700 loss 0.0443 lr 0.000033
[Epoch 5] step 1800 loss 0.0353 lr 0.000033
[Epoch 5] step 1900 loss 0.0185 lr 0.000033
[Epoch 5] step 2000 loss 0.0210 lr 0.000033
[Epoch 5] step 2100 loss 0.0695 lr 0.000033
[Epoch 5] step 2200 loss 0.1049 lr 0.000033
[Epoch 5] step 2300 loss 0.1181 lr 0.000032
[Epoch 5] step 2400 loss 0.1028 lr 0.000032
[Epoch 5] step 2500 loss 0.0312 lr 0.000032
[Epoch 5] step 2600 loss 0.0152 lr 0.000032
[Epoch 5] step 2700 loss 0.0544 lr 0.000032
[Epoch 5] step 2800 loss 0.0568 lr 0.000032
[Epoch 5] step 2900 loss 0.0177 lr 0.000032
[Validation] global_step 63000 loss 0.2286 accuracy 0.4844
Validation metrics did not improve. Patience: 6/10
[Epoch 5] step 3000 loss 0.0334 lr 0.000032
[Epoch 5] step 3100 loss 0.0840 lr 0.000032
[Epoch 5] step 3200 loss 0.1661 lr 0.000032
[Epoch 5] step 3300 loss 0.0258 lr 0.000032
[Epoch 5] step 3400 loss 0.0504 lr 0.000032
[Epoch 5] step 3500 loss 0.1646 lr 0.000032
[Epoch 5] step 3600 loss 0.0432 lr 0.000032
[Epoch 5] step 3700 loss 0.1347 lr 0.000032
[Epoch 5] step 3800 loss 0.0302 lr 0.000032
[Epoch 5] step 3900 loss 0.0898 lr 0.000032
[Epoch 5] step 4000 loss 0.0622 lr 0.000032
[Epoch 5] step 4100 loss 0.0452 lr 0.000032
[Epoch 5] step 4200 loss 0.0764 lr 0.000032
[Epoch 5] step 4300 loss 0.0161 lr 0.000032
[Epoch 5] step 4400 loss 0.1673 lr 0.000032
[Epoch 5] step 4500 loss 0.0737 lr 0.000032
[Epoch 5] step 4600 loss 0.0271 lr 0.000032
[Epoch 5] step 4700 loss 0.0647 lr 0.000032
[Epoch 5] step 4800 loss 0.0940 lr 0.000032
[Epoch 5] step 4900 loss 0.0365 lr 0.000032
[Epoch 5] step 5000 loss 0.0316 lr 0.000031
[Epoch 5] step 5100 loss 0.1020 lr 0.000031
[Epoch 5] step 5200 loss 0.2108 lr 0.000031
[Epoch 5] step 5300 loss 0.0385 lr 0.000031
[Epoch 5] step 5400 loss 0.0402 lr 0.000031
[Epoch 5] step 5500 loss 0.1973 lr 0.000031
[Epoch 5] step 5600 loss 0.0308 lr 0.000031
[Epoch 5] step 5700 loss 0.0993 lr 0.000031
[Epoch 5] step 5800 loss 0.0627 lr 0.000031
[Epoch 5] step 5900 loss 0.0751 lr 0.000031
[Validation] global_step 66000 loss 0.2210 accuracy 0.4922
Validation metrics did not improve. Patience: 7/10
[Epoch 5] step 6000 loss 0.0888 lr 0.000031
[Epoch 5] step 6100 loss 0.0397 lr 0.000031
[Epoch 5] step 6200 loss 0.0325 lr 0.000031
[Epoch 5] step 6300 loss 0.0655 lr 0.000031
[Epoch 5] step 6400 loss 0.0287 lr 0.000031
[Epoch 5] step 6500 loss 0.0453 lr 0.000031
[Epoch 5] step 6600 loss 0.0181 lr 0.000031
[Epoch 5] step 6700 loss 0.0221 lr 0.000031
[Epoch 5] step 6800 loss 0.0696 lr 0.000031
[Epoch 5] step 6900 loss 0.0505 lr 0.000031
[Epoch 5] step 7000 loss 0.0270 lr 0.000031
[Epoch 5] step 7100 loss 0.0622 lr 0.000031
[Epoch 5] step 7200 loss 0.1718 lr 0.000031
[Epoch 5] step 7300 loss 0.0707 lr 0.000031
[Epoch 5] step 7400 loss 0.0206 lr 0.000031
[Epoch 5] step 7500 loss 0.0333 lr 0.000031
[Epoch 5] step 7600 loss 0.0303 lr 0.000031
[Epoch 5] step 7700 loss 0.0800 lr 0.000030
[Epoch 5] step 7800 loss 0.0692 lr 0.000030
[Epoch 5] step 7900 loss 0.0586 lr 0.000030
[Epoch 5] step 8000 loss 0.1139 lr 0.000030
[Epoch 5] step 8100 loss 0.1274 lr 0.000030
[Epoch 5] step 8200 loss 0.0362 lr 0.000030
[Epoch 5] step 8300 loss 0.0427 lr 0.000030
[Epoch 5] step 8400 loss 0.0345 lr 0.000030
[Epoch 5] step 8500 loss 0.0621 lr 0.000030
[Epoch 5] step 8600 loss 0.2099 lr 0.000030
[Epoch 5] step 8700 loss 0.0672 lr 0.000030
[Epoch 5] step 8800 loss 0.0381 lr 0.000030
[Epoch 5] step 8900 loss 0.0576 lr 0.000030
[Validation] global_step 69000 loss 0.2125 accuracy 0.5078
Validation loss improved from 0.2138 to 0.2125
[Epoch 5] step 9000 loss 0.1515 lr 0.000030
[Epoch 5] step 9100 loss 0.0390 lr 0.000030
[Epoch 5] step 9200 loss 0.0527 lr 0.000030
[Epoch 5] step 9300 loss 0.0873 lr 0.000030
[Epoch 5] step 9400 loss 0.1021 lr 0.000030
[Epoch 5] step 9500 loss 0.0698 lr 0.000030
[Epoch 5] step 9600 loss 0.0237 lr 0.000030
[Epoch 5] step 9700 loss 0.0791 lr 0.000030
[Epoch 5] step 9800 loss 0.0285 lr 0.000030
[Epoch 5] step 9900 loss 0.0393 lr 0.000030
[Epoch 5] step 10000 loss 0.0297 lr 0.000030
[Epoch 5] step 10100 loss 0.0367 lr 0.000030
[Epoch 5] step 10200 loss 0.0669 lr 0.000030
[Epoch 5] step 10300 loss 0.1239 lr 0.000030
[Epoch 5] step 10400 loss 0.0177 lr 0.000029
[Epoch 5] step 10500 loss 0.0733 lr 0.000029
[Epoch 5] step 10600 loss 0.0666 lr 0.000029
[Epoch 5] step 10700 loss 0.1001 lr 0.000029
[Epoch 5] step 10800 loss 0.0309 lr 0.000029
[Epoch 5] step 10900 loss 0.0783 lr 0.000029
[Epoch 5] step 11000 loss 0.0504 lr 0.000029
[Epoch 5] step 11100 loss 0.0129 lr 0.000029
[Epoch 5] step 11200 loss 0.0165 lr 0.000029
[Epoch 5] step 11300 loss 0.0771 lr 0.000029
[Epoch 5] step 11400 loss 0.0538 lr 0.000029
[Epoch 5] step 11500 loss 0.0188 lr 0.000029
[Epoch 5] step 11600 loss 0.0320 lr 0.000029
[Epoch 5] step 11700 loss 0.0259 lr 0.000029
[Epoch 5] step 11800 loss 0.0857 lr 0.000029
[Epoch 5] step 11900 loss 0.0123 lr 0.000029
[Validation] global_step 72000 loss 0.2349 accuracy 0.4922
Validation metrics did not improve. Patience: 1/10
[Epoch 5] step 12000 loss 0.0841 lr 0.000029
[Epoch 5] step 12100 loss 0.0926 lr 0.000029
[Epoch 5] step 12200 loss 0.0685 lr 0.000029
[Epoch 5] step 12300 loss 0.0425 lr 0.000029
[Epoch 5] step 12400 loss 0.0827 lr 0.000029
[Epoch 5] step 12500 loss 0.0628 lr 0.000029
[Epoch 5] step 12600 loss 0.0742 lr 0.000029
[Epoch 5] step 12700 loss 0.1436 lr 0.000029
[Epoch 5] step 12800 loss 0.0377 lr 0.000029
[Epoch 5] step 12900 loss 0.0208 lr 0.000029
[Epoch 5] step 13000 loss 0.1024 lr 0.000029
[Epoch 5] step 13100 loss 0.0580 lr 0.000028
[Epoch 5] step 13200 loss 0.0656 lr 0.000028
[Epoch 5] step 13300 loss 0.0957 lr 0.000028
[Epoch 5] step 13400 loss 0.0394 lr 0.000028
[Epoch 5] step 13500 loss 0.0852 lr 0.000028
[Epoch 5] step 13600 loss 0.0459 lr 0.000028
[Epoch 5] step 13700 loss 0.0316 lr 0.000028
[Epoch 5] step 13800 loss 0.0586 lr 0.000028
[Epoch 5] step 13900 loss 0.0469 lr 0.000028
[Epoch 5] step 14000 loss 0.0282 lr 0.000028
[Epoch 5] step 14100 loss 0.0510 lr 0.000028
[Epoch 5] step 14200 loss 0.0179 lr 0.000028
[Epoch 5] step 14300 loss 0.0695 lr 0.000028
[Epoch 5] step 14400 loss 0.0825 lr 0.000028
[Epoch 5] step 14500 loss 0.0808 lr 0.000028
[Epoch 5] step 14600 loss 0.0671 lr 0.000028
[Epoch 5] step 14700 loss 0.0094 lr 0.000028
[Epoch 5] step 14800 loss 0.0079 lr 0.000028
[Epoch 5] step 14900 loss 0.0378 lr 0.000028
[Validation] global_step 75000 loss 0.2317 accuracy 0.4844
Validation metrics did not improve. Patience: 2/10
Epoch 5 avg loss 0.0636
[Epoch 6] step 0 loss 0.0663 lr 0.000028
[Epoch 6] step 100 loss 0.0377 lr 0.000028
[Epoch 6] step 200 loss 0.0335 lr 0.000028
[Epoch 6] step 300 loss 0.0975 lr 0.000028
[Epoch 6] step 400 loss 0.0484 lr 0.000028
[Epoch 6] step 500 loss 0.0835 lr 0.000028
[Epoch 6] step 600 loss 0.0995 lr 0.000028
[Epoch 6] step 700 loss 0.0396 lr 0.000028
[Epoch 6] step 800 loss 0.0151 lr 0.000027
[Epoch 6] step 900 loss 0.0368 lr 0.000027
[Epoch 6] step 1000 loss 0.0463 lr 0.000027
[Epoch 6] step 1100 loss 0.0564 lr 0.000027
[Epoch 6] step 1200 loss 0.0530 lr 0.000027
[Epoch 6] step 1300 loss 0.0279 lr 0.000027
[Epoch 6] step 1400 loss 0.0145 lr 0.000027
[Epoch 6] step 1500 loss 0.0710 lr 0.000027
[Epoch 6] step 1600 loss 0.0231 lr 0.000027
[Epoch 6] step 1700 loss 0.0291 lr 0.000027
[Epoch 6] step 1800 loss 0.0761 lr 0.000027
[Epoch 6] step 1900 loss 0.0204 lr 0.000027
[Epoch 6] step 2000 loss 0.1616 lr 0.000027
[Epoch 6] step 2100 loss 0.0764 lr 0.000027
[Epoch 6] step 2200 loss 0.0462 lr 0.000027
[Epoch 6] step 2300 loss 0.0482 lr 0.000027
[Epoch 6] step 2400 loss 0.0548 lr 0.000027
[Epoch 6] step 2500 loss 0.0494 lr 0.000027
[Epoch 6] step 2600 loss 0.0489 lr 0.000027
[Epoch 6] step 2700 loss 0.0618 lr 0.000027
[Epoch 6] step 2800 loss 0.1499 lr 0.000027
[Epoch 6] step 2900 loss 0.0220 lr 0.000027
[Validation] global_step 78000 loss 0.2194 accuracy 0.4961
Validation metrics did not improve. Patience: 3/10
[Epoch 6] step 3000 loss 0.0934 lr 0.000027
[Epoch 6] step 3100 loss 0.0572 lr 0.000027
[Epoch 6] step 3200 loss 0.0530 lr 0.000027
[Epoch 6] step 3300 loss 0.0523 lr 0.000027
[Epoch 6] step 3400 loss 0.0632 lr 0.000027
[Epoch 6] step 3500 loss 0.0755 lr 0.000026
[Epoch 6] step 3600 loss 0.0696 lr 0.000026
[Epoch 6] step 3700 loss 0.0353 lr 0.000026
[Epoch 6] step 3800 loss 0.0482 lr 0.000026
[Epoch 6] step 3900 loss 0.1172 lr 0.000026
[Epoch 6] step 4000 loss 0.0787 lr 0.000026
[Epoch 6] step 4100 loss 0.0349 lr 0.000026
[Epoch 6] step 4200 loss 0.0223 lr 0.000026
[Epoch 6] step 4300 loss 0.0595 lr 0.000026
[Epoch 6] step 4400 loss 0.1102 lr 0.000026
[Epoch 6] step 4500 loss 0.0449 lr 0.000026
[Epoch 6] step 4600 loss 0.0369 lr 0.000026
[Epoch 6] step 4700 loss 0.1275 lr 0.000026
[Epoch 6] step 4800 loss 0.0344 lr 0.000026
[Epoch 6] step 4900 loss 0.0682 lr 0.000026
[Epoch 6] step 5000 loss 0.0174 lr 0.000026
[Epoch 6] step 5100 loss 0.0401 lr 0.000026
[Epoch 6] step 5200 loss 0.0241 lr 0.000026
[Epoch 6] step 5300 loss 0.0099 lr 0.000026
[Epoch 6] step 5400 loss 0.0834 lr 0.000026
[Epoch 6] step 5500 loss 0.0356 lr 0.000026
[Epoch 6] step 5600 loss 0.1261 lr 0.000026
[Epoch 6] step 5700 loss 0.0147 lr 0.000026
[Epoch 6] step 5800 loss 0.1289 lr 0.000026
[Epoch 6] step 5900 loss 0.0354 lr 0.000026
[Validation] global_step 81000 loss 0.2206 accuracy 0.5117
Validation metrics did not improve. Patience: 4/10
[Epoch 6] step 6000 loss 0.2244 lr 0.000026
[Epoch 6] step 6100 loss 0.0193 lr 0.000026
[Epoch 6] step 6200 loss 0.0374 lr 0.000025
[Epoch 6] step 6300 loss 0.0521 lr 0.000025
[Epoch 6] step 6400 loss 0.0350 lr 0.000025
[Epoch 6] step 6500 loss 0.0139 lr 0.000025
[Epoch 6] step 6600 loss 0.0506 lr 0.000025
[Epoch 6] step 6700 loss 0.1350 lr 0.000025
[Epoch 6] step 6800 loss 0.0949 lr 0.000025
[Epoch 6] step 6900 loss 0.1426 lr 0.000025
[Epoch 6] step 7000 loss 0.0349 lr 0.000025
[Epoch 6] step 7100 loss 0.0151 lr 0.000025
[Epoch 6] step 7200 loss 0.0133 lr 0.000025
[Epoch 6] step 7300 loss 0.0729 lr 0.000025
[Epoch 6] step 7400 loss 0.0485 lr 0.000025
[Epoch 6] step 7500 loss 0.0425 lr 0.000025
[Epoch 6] step 7600 loss 0.0446 lr 0.000025
[Epoch 6] step 7700 loss 0.0589 lr 0.000025
[Epoch 6] step 7800 loss 0.2876 lr 0.000025
[Epoch 6] step 7900 loss 0.0905 lr 0.000025
[Epoch 6] step 8000 loss 0.0493 lr 0.000025
[Epoch 6] step 8100 loss 0.1243 lr 0.000025
[Epoch 6] step 8200 loss 0.1263 lr 0.000025
[Epoch 6] step 8300 loss 0.0965 lr 0.000025
[Epoch 6] step 8400 loss 0.0144 lr 0.000025
[Epoch 6] step 8500 loss 0.0466 lr 0.000025
[Epoch 6] step 8600 loss 0.0191 lr 0.000025
[Epoch 6] step 8700 loss 0.0804 lr 0.000025
[Epoch 6] step 8800 loss 0.0487 lr 0.000025
[Epoch 6] step 8900 loss 0.0178 lr 0.000024
[Validation] global_step 84000 loss 0.2283 accuracy 0.4883
Validation metrics did not improve. Patience: 5/10
[Epoch 6] step 9000 loss 0.0256 lr 0.000024
[Epoch 6] step 9100 loss 0.0602 lr 0.000024
[Epoch 6] step 9200 loss 0.0379 lr 0.000024
[Epoch 6] step 9300 loss 0.0653 lr 0.000024
[Epoch 6] step 9400 loss 0.0477 lr 0.000024
[Epoch 6] step 9500 loss 0.0391 lr 0.000024
[Epoch 6] step 9600 loss 0.1416 lr 0.000024
[Epoch 6] step 9700 loss 0.0501 lr 0.000024
[Epoch 6] step 9800 loss 0.0991 lr 0.000024
[Epoch 6] step 9900 loss 0.0311 lr 0.000024
[Epoch 6] step 10000 loss 0.0445 lr 0.000024
[Epoch 6] step 10100 loss 0.0597 lr 0.000024
[Epoch 6] step 10200 loss 0.0486 lr 0.000024
[Epoch 6] step 10300 loss 0.0644 lr 0.000024
[Epoch 6] step 10400 loss 0.0244 lr 0.000024
[Epoch 6] step 10500 loss 0.0557 lr 0.000024
[Epoch 6] step 10600 loss 0.0559 lr 0.000024
[Epoch 6] step 10700 loss 0.0793 lr 0.000024
[Epoch 6] step 10800 loss 0.1319 lr 0.000024
[Epoch 6] step 10900 loss 0.0491 lr 0.000024
[Epoch 6] step 11000 loss 0.0894 lr 0.000024
[Epoch 6] step 11100 loss 0.0430 lr 0.000024
[Epoch 6] step 11200 loss 0.0432 lr 0.000024
[Epoch 6] step 11300 loss 0.0536 lr 0.000024
[Epoch 6] step 11400 loss 0.0159 lr 0.000024
[Epoch 6] step 11500 loss 0.1163 lr 0.000024
[Epoch 6] step 11600 loss 0.0935 lr 0.000023
[Epoch 6] step 11700 loss 0.0185 lr 0.000023
[Epoch 6] step 11800 loss 0.0337 lr 0.000023
[Epoch 6] step 11900 loss 0.0742 lr 0.000023
[Validation] global_step 87000 loss 0.2235 accuracy 0.5000
Validation metrics did not improve. Patience: 6/10
[Epoch 6] step 12000 loss 0.2107 lr 0.000023
[Epoch 6] step 12100 loss 0.0607 lr 0.000023
[Epoch 6] step 12200 loss 0.0983 lr 0.000023
[Epoch 6] step 12300 loss 0.0869 lr 0.000023
[Epoch 6] step 12400 loss 0.0431 lr 0.000023
[Epoch 6] step 12500 loss 0.1042 lr 0.000023
[Epoch 6] step 12600 loss 0.0158 lr 0.000023
[Epoch 6] step 12700 loss 0.0435 lr 0.000023
[Epoch 6] step 12800 loss 0.0406 lr 0.000023
[Epoch 6] step 12900 loss 0.0693 lr 0.000023
[Epoch 6] step 13000 loss 0.0254 lr 0.000023
[Epoch 6] step 13100 loss 0.0357 lr 0.000023
[Epoch 6] step 13200 loss 0.1089 lr 0.000023
[Epoch 6] step 13300 loss 0.1376 lr 0.000023
[Epoch 6] step 13400 loss 0.0240 lr 0.000023
[Epoch 6] step 13500 loss 0.0596 lr 0.000023
[Epoch 6] step 13600 loss 0.0566 lr 0.000023
[Epoch 6] step 13700 loss 0.0392 lr 0.000023
[Epoch 6] step 13800 loss 0.0622 lr 0.000023
[Epoch 6] step 13900 loss 0.0361 lr 0.000023
[Epoch 6] step 14000 loss 0.1542 lr 0.000023
[Epoch 6] step 14100 loss 0.1316 lr 0.000023
[Epoch 6] step 14200 loss 0.0728 lr 0.000023
[Epoch 6] step 14300 loss 0.0863 lr 0.000022
[Epoch 6] step 14400 loss 0.0141 lr 0.000022
[Epoch 6] step 14500 loss 0.0274 lr 0.000022
[Epoch 6] step 14600 loss 0.0588 lr 0.000022
[Epoch 6] step 14700 loss 0.0632 lr 0.000022
[Epoch 6] step 14800 loss 0.0749 lr 0.000022
[Epoch 6] step 14900 loss 0.0387 lr 0.000022
[Validation] global_step 90000 loss 0.2130 accuracy 0.5078
Validation metrics did not improve. Patience: 7/10
Epoch 6 avg loss 0.0625
[Epoch 7] step 0 loss 0.0245 lr 0.000022
[Epoch 7] step 100 loss 0.0267 lr 0.000022
[Epoch 7] step 200 loss 0.0694 lr 0.000022
[Epoch 7] step 300 loss 0.0765 lr 0.000022
[Epoch 7] step 400 loss 0.0458 lr 0.000022
[Epoch 7] step 500 loss 0.0445 lr 0.000022
[Epoch 7] step 600 loss 0.0892 lr 0.000022
[Epoch 7] step 700 loss 0.0837 lr 0.000022
[Epoch 7] step 800 loss 0.0635 lr 0.000022
[Epoch 7] step 900 loss 0.0198 lr 0.000022
[Epoch 7] step 1000 loss 0.0657 lr 0.000022
[Epoch 7] step 1100 loss 0.0955 lr 0.000022
[Epoch 7] step 1200 loss 0.0207 lr 0.000022
[Epoch 7] step 1300 loss 0.0674 lr 0.000022
[Epoch 7] step 1400 loss 0.0831 lr 0.000022
[Epoch 7] step 1500 loss 0.0216 lr 0.000022
[Epoch 7] step 1600 loss 0.0844 lr 0.000022
[Epoch 7] step 1700 loss 0.0666 lr 0.000022
[Epoch 7] step 1800 loss 0.0565 lr 0.000022
[Epoch 7] step 1900 loss 0.0323 lr 0.000022
[Epoch 7] step 2000 loss 0.1036 lr 0.000021
[Epoch 7] step 2100 loss 0.0552 lr 0.000021
[Epoch 7] step 2200 loss 0.0414 lr 0.000021
[Epoch 7] step 2300 loss 0.1042 lr 0.000021
[Epoch 7] step 2400 loss 0.0697 lr 0.000021
[Epoch 7] step 2500 loss 0.0405 lr 0.000021
[Epoch 7] step 2600 loss 0.0237 lr 0.000021
[Epoch 7] step 2700 loss 0.0227 lr 0.000021
[Epoch 7] step 2800 loss 0.0172 lr 0.000021
[Epoch 7] step 2900 loss 0.0843 lr 0.000021
[Validation] global_step 93000 loss 0.2145 accuracy 0.5273
Validation accuracy improved from 0.5117 to 0.5273
[Epoch 7] step 3000 loss 0.0359 lr 0.000021
[Epoch 7] step 3100 loss 0.2022 lr 0.000021
[Epoch 7] step 3200 loss 0.0507 lr 0.000021
[Epoch 7] step 3300 loss 0.0646 lr 0.000021
[Epoch 7] step 3400 loss 0.1106 lr 0.000021
[Epoch 7] step 3500 loss 0.0386 lr 0.000021
[Epoch 7] step 3600 loss 0.0768 lr 0.000021
[Epoch 7] step 3700 loss 0.0401 lr 0.000021
[Epoch 7] step 3800 loss 0.0542 lr 0.000021
[Epoch 7] step 3900 loss 0.0153 lr 0.000021
[Epoch 7] step 4000 loss 0.0702 lr 0.000021
[Epoch 7] step 4100 loss 0.0066 lr 0.000021
[Epoch 7] step 4200 loss 0.0580 lr 0.000021
[Epoch 7] step 4300 loss 0.1135 lr 0.000021
[Epoch 7] step 4400 loss 0.1184 lr 0.000021
[Epoch 7] step 4500 loss 0.0877 lr 0.000021
[Epoch 7] step 4600 loss 0.0395 lr 0.000021
[Epoch 7] step 4700 loss 0.0574 lr 0.000020
[Epoch 7] step 4800 loss 0.0230 lr 0.000020
[Epoch 7] step 4900 loss 0.1071 lr 0.000020
[Epoch 7] step 5000 loss 0.0287 lr 0.000020
[Epoch 7] step 5100 loss 0.1093 lr 0.000020
[Epoch 7] step 5200 loss 0.0586 lr 0.000020
[Epoch 7] step 5300 loss 0.0386 lr 0.000020
[Epoch 7] step 5400 loss 0.0892 lr 0.000020
[Epoch 7] step 5500 loss 0.0258 lr 0.000020
[Epoch 7] step 5600 loss 0.0066 lr 0.000020
[Epoch 7] step 5700 loss 0.0171 lr 0.000020
[Epoch 7] step 5800 loss 0.0401 lr 0.000020
[Epoch 7] step 5900 loss 0.1006 lr 0.000020
[Validation] global_step 96000 loss 0.2121 accuracy 0.5156
Validation loss improved from 0.2125 to 0.2121
[Epoch 7] step 6000 loss 0.0493 lr 0.000020
[Epoch 7] step 6100 loss 0.0325 lr 0.000020
[Epoch 7] step 6200 loss 0.0324 lr 0.000020
[Epoch 7] step 6300 loss 0.0515 lr 0.000020
[Epoch 7] step 6400 loss 0.0341 lr 0.000020
[Epoch 7] step 6500 loss 0.0446 lr 0.000020
[Epoch 7] step 6600 loss 0.0529 lr 0.000020
[Epoch 7] step 6700 loss 0.1107 lr 0.000020
[Epoch 7] step 6800 loss 0.0611 lr 0.000020
[Epoch 7] step 6900 loss 0.0246 lr 0.000020
[Epoch 7] step 7000 loss 0.0398 lr 0.000020
[Epoch 7] step 7100 loss 0.0653 lr 0.000020
[Epoch 7] step 7200 loss 0.2374 lr 0.000020
[Epoch 7] step 7300 loss 0.0309 lr 0.000020
[Epoch 7] step 7400 loss 0.0875 lr 0.000019
[Epoch 7] step 7500 loss 0.2196 lr 0.000019
[Epoch 7] step 7600 loss 0.0290 lr 0.000019
[Epoch 7] step 7700 loss 0.1098 lr 0.000019
[Epoch 7] step 7800 loss 0.0846 lr 0.000019
[Epoch 7] step 7900 loss 0.0451 lr 0.000019
[Epoch 7] step 8000 loss 0.0534 lr 0.000019
[Epoch 7] step 8100 loss 0.0303 lr 0.000019
[Epoch 7] step 8200 loss 0.0154 lr 0.000019
[Epoch 7] step 8300 loss 0.0310 lr 0.000019
[Epoch 7] step 8400 loss 0.0614 lr 0.000019
[Epoch 7] step 8500 loss 0.0331 lr 0.000019
[Epoch 7] step 8600 loss 0.0091 lr 0.000019
[Epoch 7] step 8700 loss 0.0643 lr 0.000019
[Epoch 7] step 8800 loss 0.0526 lr 0.000019
[Epoch 7] step 8900 loss 0.0588 lr 0.000019
[Validation] global_step 99000 loss 0.2077 accuracy 0.5469
Validation accuracy improved from 0.5273 to 0.5469, Validation loss improved from 0.2121 to 0.2077
[Epoch 7] step 9000 loss 0.0521 lr 0.000019
[Epoch 7] step 9100 loss 0.0446 lr 0.000019
[Epoch 7] step 9200 loss 0.1149 lr 0.000019
[Epoch 7] step 9300 loss 0.0355 lr 0.000019
[Epoch 7] step 9400 loss 0.0744 lr 0.000019
[Epoch 7] step 9500 loss 0.0073 lr 0.000019
[Epoch 7] step 9600 loss 0.0333 lr 0.000019
[Epoch 7] step 9700 loss 0.0686 lr 0.000019
[Epoch 7] step 9800 loss 0.1072 lr 0.000019
[Epoch 7] step 9900 loss 0.0353 lr 0.000019
[Epoch 7] step 10000 loss 0.0461 lr 0.000019
[Epoch 7] step 10100 loss 0.0339 lr 0.000018
[Epoch 7] step 10200 loss 0.0501 lr 0.000018
[Epoch 7] step 10300 loss 0.1681 lr 0.000018
[Epoch 7] step 10400 loss 0.0551 lr 0.000018
[Epoch 7] step 10500 loss 0.0337 lr 0.000018
[Epoch 7] step 10600 loss 0.0396 lr 0.000018
[Epoch 7] step 10700 loss 0.0242 lr 0.000018
[Epoch 7] step 10800 loss 0.0162 lr 0.000018
[Epoch 7] step 10900 loss 0.0991 lr 0.000018
[Epoch 7] step 11000 loss 0.3367 lr 0.000018
[Epoch 7] step 11100 loss 0.0457 lr 0.000018
[Epoch 7] step 11200 loss 0.0330 lr 0.000018
[Epoch 7] step 11300 loss 0.0723 lr 0.000018
[Epoch 7] step 11400 loss 0.0521 lr 0.000018
[Epoch 7] step 11500 loss 0.1492 lr 0.000018
[Epoch 7] step 11600 loss 0.0246 lr 0.000018
[Epoch 7] step 11700 loss 0.0410 lr 0.000018
[Epoch 7] step 11800 loss 0.0471 lr 0.000018
[Epoch 7] step 11900 loss 0.0516 lr 0.000018
[Validation] global_step 102000 loss 0.1985 accuracy 0.4883
Validation loss improved from 0.2077 to 0.1985
[Epoch 7] step 12000 loss 0.0603 lr 0.000018
[Epoch 7] step 12100 loss 0.0375 lr 0.000018
[Epoch 7] step 12200 loss 0.1075 lr 0.000018
[Epoch 7] step 12300 loss 0.1415 lr 0.000018
[Epoch 7] step 12400 loss 0.0804 lr 0.000018
[Epoch 7] step 12500 loss 0.0275 lr 0.000018
[Epoch 7] step 12600 loss 0.0856 lr 0.000018
[Epoch 7] step 12700 loss 0.0709 lr 0.000018
[Epoch 7] step 12800 loss 0.0328 lr 0.000017
[Epoch 7] step 12900 loss 0.0778 lr 0.000017
[Epoch 7] step 13000 loss 0.1393 lr 0.000017
[Epoch 7] step 13100 loss 0.0524 lr 0.000017
[Epoch 7] step 13200 loss 0.0192 lr 0.000017
[Epoch 7] step 13300 loss 0.0117 lr 0.000017
[Epoch 7] step 13400 loss 0.0433 lr 0.000017
[Epoch 7] step 13500 loss 0.1537 lr 0.000017
[Epoch 7] step 13600 loss 0.0802 lr 0.000017
[Epoch 7] step 13700 loss 0.0364 lr 0.000017
[Epoch 7] step 13800 loss 0.0249 lr 0.000017
[Epoch 7] step 13900 loss 0.1057 lr 0.000017
[Epoch 7] step 14000 loss 0.1160 lr 0.000017
[Epoch 7] step 14100 loss 0.0962 lr 0.000017
[Epoch 7] step 14200 loss 0.0187 lr 0.000017
[Epoch 7] step 14300 loss 0.0270 lr 0.000017
[Epoch 7] step 14400 loss 0.0138 lr 0.000017
[Epoch 7] step 14500 loss 0.0808 lr 0.000017
[Epoch 7] step 14600 loss 0.0665 lr 0.000017
[Epoch 7] step 14700 loss 0.0553 lr 0.000017
[Epoch 7] step 14800 loss 0.0307 lr 0.000017
[Epoch 7] step 14900 loss 0.0485 lr 0.000017
[Validation] global_step 105000 loss 0.2031 accuracy 0.5312
Validation metrics did not improve. Patience: 1/10
Epoch 7 avg loss 0.0594
[Epoch 8] step 0 loss 0.0636 lr 0.000017
[Epoch 8] step 100 loss 0.0937 lr 0.000017
[Epoch 8] step 200 loss 0.0448 lr 0.000017
[Epoch 8] step 300 loss 0.1109 lr 0.000017
[Epoch 8] step 400 loss 0.0104 lr 0.000017
[Epoch 8] step 500 loss 0.0578 lr 0.000016
[Epoch 8] step 600 loss 0.0642 lr 0.000016
[Epoch 8] step 700 loss 0.0743 lr 0.000016
[Epoch 8] step 800 loss 0.0422 lr 0.000016
[Epoch 8] step 900 loss 0.0265 lr 0.000016
[Epoch 8] step 1000 loss 0.0480 lr 0.000016
[Epoch 8] step 1100 loss 0.0563 lr 0.000016
[Epoch 8] step 1200 loss 0.0398 lr 0.000016
[Epoch 8] step 1300 loss 0.0806 lr 0.000016
[Epoch 8] step 1400 loss 0.0047 lr 0.000016
[Epoch 8] step 1500 loss 0.0411 lr 0.000016
[Epoch 8] step 1600 loss 0.0420 lr 0.000016
[Epoch 8] step 1700 loss 0.0248 lr 0.000016
[Epoch 8] step 1800 loss 0.0438 lr 0.000016
[Epoch 8] step 1900 loss 0.0966 lr 0.000016
[Epoch 8] step 2000 loss 0.2094 lr 0.000016
[Epoch 8] step 2100 loss 0.0536 lr 0.000016
[Epoch 8] step 2200 loss 0.0189 lr 0.000016
[Epoch 8] step 2300 loss 0.0214 lr 0.000016
[Epoch 8] step 2400 loss 0.0349 lr 0.000016
[Epoch 8] step 2500 loss 0.0712 lr 0.000016
[Epoch 8] step 2600 loss 0.0511 lr 0.000016
[Epoch 8] step 2700 loss 0.0812 lr 0.000016
[Epoch 8] step 2800 loss 0.0405 lr 0.000016
[Epoch 8] step 2900 loss 0.0358 lr 0.000016
[Validation] global_step 108000 loss 0.2038 accuracy 0.5469
Validation metrics did not improve. Patience: 2/10
[Epoch 8] step 3000 loss 0.0185 lr 0.000016
[Epoch 8] step 3100 loss 0.0337 lr 0.000016
[Epoch 8] step 3200 loss 0.0434 lr 0.000015
[Epoch 8] step 3300 loss 0.0486 lr 0.000015
[Epoch 8] step 3400 loss 0.0423 lr 0.000015
[Epoch 8] step 3500 loss 0.0094 lr 0.000015
[Epoch 8] step 3600 loss 0.0290 lr 0.000015
[Epoch 8] step 3700 loss 0.0674 lr 0.000015
[Epoch 8] step 3800 loss 0.0488 lr 0.000015
[Epoch 8] step 3900 loss 0.0490 lr 0.000015
[Epoch 8] step 4000 loss 0.0456 lr 0.000015
[Epoch 8] step 4100 loss 0.0656 lr 0.000015
[Epoch 8] step 4200 loss 0.0432 lr 0.000015
[Epoch 8] step 4300 loss 0.0752 lr 0.000015
[Epoch 8] step 4400 loss 0.0415 lr 0.000015
[Epoch 8] step 4500 loss 0.0201 lr 0.000015
[Epoch 8] step 4600 loss 0.0091 lr 0.000015
[Epoch 8] step 4700 loss 0.0283 lr 0.000015
[Epoch 8] step 4800 loss 0.0126 lr 0.000015
[Epoch 8] step 4900 loss 0.0280 lr 0.000015
[Epoch 8] step 5000 loss 0.0081 lr 0.000015
[Epoch 8] step 5100 loss 0.0234 lr 0.000015
[Epoch 8] step 5200 loss 0.1046 lr 0.000015
[Epoch 8] step 5300 loss 0.0461 lr 0.000015
[Epoch 8] step 5400 loss 0.0673 lr 0.000015
[Epoch 8] step 5500 loss 0.0082 lr 0.000015
[Epoch 8] step 5600 loss 0.0200 lr 0.000015
[Epoch 8] step 5700 loss 0.0765 lr 0.000015
[Epoch 8] step 5800 loss 0.0087 lr 0.000015
[Epoch 8] step 5900 loss 0.0283 lr 0.000014
[Validation] global_step 111000 loss 0.2021 accuracy 0.5352
Validation metrics did not improve. Patience: 3/10
[Epoch 8] step 6000 loss 0.0102 lr 0.000014
[Epoch 8] step 6100 loss 0.0251 lr 0.000014
[Epoch 8] step 6200 loss 0.0422 lr 0.000014
[Epoch 8] step 6300 loss 0.0416 lr 0.000014
[Epoch 8] step 6400 loss 0.1180 lr 0.000014
[Epoch 8] step 6500 loss 0.0419 lr 0.000014
[Epoch 8] step 6600 loss 0.0320 lr 0.000014
[Epoch 8] step 6700 loss 0.0720 lr 0.000014
[Epoch 8] step 6800 loss 0.0189 lr 0.000014
[Epoch 8] step 6900 loss 0.1263 lr 0.000014
[Epoch 8] step 7000 loss 0.0352 lr 0.000014
[Epoch 8] step 7100 loss 0.0387 lr 0.000014
[Epoch 8] step 7200 loss 0.1123 lr 0.000014
[Epoch 8] step 7300 loss 0.0701 lr 0.000014
[Epoch 8] step 7400 loss 0.0626 lr 0.000014
[Epoch 8] step 7500 loss 0.0248 lr 0.000014
[Epoch 8] step 7600 loss 0.0827 lr 0.000014
[Epoch 8] step 7700 loss 0.0225 lr 0.000014
[Epoch 8] step 7800 loss 0.0686 lr 0.000014
[Epoch 8] step 7900 loss 0.0767 lr 0.000014
[Epoch 8] step 8000 loss 0.0826 lr 0.000014
[Epoch 8] step 8100 loss 0.0614 lr 0.000014
[Epoch 8] step 8200 loss 0.0895 lr 0.000014
[Epoch 8] step 8300 loss 0.0472 lr 0.000014
[Epoch 8] step 8400 loss 0.0279 lr 0.000014
[Epoch 8] step 8500 loss 0.1027 lr 0.000014
[Epoch 8] step 8600 loss 0.0961 lr 0.000013
[Epoch 8] step 8700 loss 0.2257 lr 0.000013
[Epoch 8] step 8800 loss 0.0954 lr 0.000013
[Epoch 8] step 8900 loss 0.1008 lr 0.000013
[Validation] global_step 114000 loss 0.3431 accuracy 0.5117
Validation metrics did not improve. Patience: 4/10
[Epoch 8] step 9000 loss 0.0545 lr 0.000013
[Epoch 8] step 9100 loss 0.0783 lr 0.000013
[Epoch 8] step 9200 loss 0.0878 lr 0.000013
[Epoch 8] step 9300 loss 0.1192 lr 0.000013
[Epoch 8] step 9400 loss 0.1199 lr 0.000013
[Epoch 8] step 9500 loss 0.1505 lr 0.000013
[Epoch 8] step 9600 loss 0.1159 lr 0.000013
[Epoch 8] step 9700 loss 0.2090 lr 0.000013
[Epoch 8] step 9800 loss 0.2204 lr 0.000013
[Epoch 8] step 9900 loss 0.2355 lr 0.000013
[Epoch 8] step 10000 loss 0.3340 lr 0.000013
[Epoch 8] step 10100 loss 0.3067 lr 0.000013
[Epoch 8] step 10200 loss 0.3670 lr 0.000013
[Epoch 8] step 10300 loss 0.3860 lr 0.000013
[Epoch 8] step 10400 loss 0.3482 lr 0.000013
[Epoch 8] step 10500 loss 0.4013 lr 0.000013
[Epoch 8] step 10600 loss nan lr 0.000013
[Epoch 8] step 10700 loss nan lr 0.000013
[Epoch 8] step 10800 loss nan lr 0.000013
[Epoch 8] step 10900 loss nan lr 0.000013
[Epoch 8] step 11000 loss nan lr 0.000013
[Epoch 8] step 11100 loss nan lr 0.000013
[Epoch 8] step 11200 loss nan lr 0.000013
[Epoch 8] step 11300 loss nan lr 0.000012
[Epoch 8] step 11400 loss nan lr 0.000012
[Epoch 8] step 11500 loss nan lr 0.000012
[Epoch 8] step 11600 loss nan lr 0.000012
[Epoch 8] step 11700 loss nan lr 0.000012
[Epoch 8] step 11800 loss nan lr 0.000012
[Epoch 8] step 11900 loss nan lr 0.000012
