===== Training started at 0 =====
Batch size: 2, LR: 5e-05, Epochs: 10
Steps per file: 50, Grad. accum: 4, Warmup rate: 0.1
Validation dataset loaded with 128 steps, using seed 42, max files 128, steps/file 1, batch size 8
Total validation batches: 16
Warmup steps: 3750, Total optimizer steps: 37500
[Epoch 1] step 0 loss 0.3878 lr 0.000000
[Epoch 1] step 100 loss 0.6660 lr 0.000000
[Epoch 1] step 200 loss 0.2659 lr 0.000001
[Epoch 1] step 300 loss 0.2506 lr 0.000001
[Epoch 1] step 400 loss 0.3883 lr 0.000001
[Epoch 1] step 500 loss 0.3189 lr 0.000002
[Epoch 1] step 600 loss 0.2090 lr 0.000002
[Epoch 1] step 700 loss 0.0909 lr 0.000002
[Epoch 1] step 800 loss 0.2492 lr 0.000003
[Epoch 1] step 900 loss 0.1243 lr 0.000003
[Epoch 1] step 1000 loss 0.0472 lr 0.000003
[Epoch 1] step 1100 loss 0.0690 lr 0.000004
[Epoch 1] step 1200 loss 0.1363 lr 0.000004
[Epoch 1] step 1300 loss 0.1971 lr 0.000004
[Epoch 1] step 1400 loss 0.0993 lr 0.000005
[Epoch 1] step 1500 loss 0.0753 lr 0.000005
[Epoch 1] step 1600 loss 0.0499 lr 0.000005
[Epoch 1] step 1700 loss 0.1086 lr 0.000006
[Epoch 1] step 1800 loss 0.1079 lr 0.000006
[Epoch 1] step 1900 loss 0.0290 lr 0.000006
[Epoch 1] step 2000 loss 0.0999 lr 0.000007
[Epoch 1] step 2100 loss 0.0312 lr 0.000007
[Epoch 1] step 2200 loss 0.0154 lr 0.000007
[Epoch 1] step 2300 loss 0.0783 lr 0.000008
[Epoch 1] step 2400 loss 0.0773 lr 0.000008
[Epoch 1] step 2500 loss 0.0312 lr 0.000008
[Epoch 1] step 2600 loss 0.0168 lr 0.000009
[Epoch 1] step 2700 loss 0.0545 lr 0.000009
[Epoch 1] step 2800 loss 0.0750 lr 0.000009
[Epoch 1] step 2900 loss 0.1228 lr 0.000010
[Epoch 1] step 3000 loss 0.0563 lr 0.000010
[Epoch 1] step 3100 loss 0.0265 lr 0.000010
[Epoch 1] step 3200 loss 0.1765 lr 0.000011
[Epoch 1] step 3300 loss 0.2084 lr 0.000011
[Epoch 1] step 3400 loss 0.0374 lr 0.000011
[Epoch 1] step 3500 loss 0.1563 lr 0.000012
[Epoch 1] step 3600 loss 0.0709 lr 0.000012
[Epoch 1] step 3700 loss 0.0342 lr 0.000012
[Epoch 1] step 3800 loss 0.0837 lr 0.000013
[Epoch 1] step 3900 loss 0.0244 lr 0.000013
[Epoch 1] step 4000 loss 0.0532 lr 0.000013
[Epoch 1] step 4100 loss 0.0620 lr 0.000014
[Epoch 1] step 4200 loss 0.0288 lr 0.000014
[Epoch 1] step 4300 loss 0.0006 lr 0.000014
[Epoch 1] step 4400 loss 0.0293 lr 0.000015
[Epoch 1] step 4500 loss 0.0192 lr 0.000015
[Epoch 1] step 4600 loss 0.0287 lr 0.000015
[Epoch 1] step 4700 loss 0.0486 lr 0.000016
[Epoch 1] step 4800 loss 0.1039 lr 0.000016
[Epoch 1] step 4900 loss 0.0630 lr 0.000016
[Validation] global_step 5000 loss 0.2227 accuracy 0.4258
Validation accuracy improved from 0.0000 to 0.4258, Validation loss improved from inf to 0.2227
[Epoch 1] step 5000 loss 0.0249 lr 0.000017
[Epoch 1] step 5100 loss 0.0508 lr 0.000017
[Epoch 1] step 5200 loss 0.3668 lr 0.000017
[Epoch 1] step 5300 loss 0.0572 lr 0.000018
[Epoch 1] step 5400 loss 0.0305 lr 0.000018
[Epoch 1] step 5500 loss 0.0477 lr 0.000018
[Epoch 1] step 5600 loss 0.0212 lr 0.000019
[Epoch 1] step 5700 loss 0.1748 lr 0.000019
[Epoch 1] step 5800 loss 0.1380 lr 0.000019
[Epoch 1] step 5900 loss 0.0375 lr 0.000020
[Epoch 1] step 6000 loss 0.0791 lr 0.000020
[Epoch 1] step 6100 loss 0.0258 lr 0.000020
[Epoch 1] step 6200 loss 0.0235 lr 0.000021
[Epoch 1] step 6300 loss 0.0899 lr 0.000021
[Epoch 1] step 6400 loss 0.0617 lr 0.000021
[Epoch 1] step 6500 loss 0.0313 lr 0.000022
[Epoch 1] step 6600 loss 0.1381 lr 0.000022
[Epoch 1] step 6700 loss 0.0582 lr 0.000022
[Epoch 1] step 6800 loss 0.0159 lr 0.000023
[Epoch 1] step 6900 loss 0.0196 lr 0.000023
[Epoch 1] step 7000 loss 0.2009 lr 0.000023
[Epoch 1] step 7100 loss 0.0289 lr 0.000024
[Epoch 1] step 7200 loss 0.1613 lr 0.000024
[Epoch 1] step 7300 loss 0.0441 lr 0.000024
[Epoch 1] step 7400 loss 0.0291 lr 0.000025
[Epoch 1] step 7500 loss 0.0877 lr 0.000025
[Epoch 1] step 7600 loss 0.0189 lr 0.000025
[Epoch 1] step 7700 loss 0.0739 lr 0.000026
[Epoch 1] step 7800 loss 0.0163 lr 0.000026
[Epoch 1] step 7900 loss 0.0418 lr 0.000026
[Epoch 1] step 8000 loss 0.0504 lr 0.000027
[Epoch 1] step 8100 loss 0.0744 lr 0.000027
[Epoch 1] step 8200 loss 0.0787 lr 0.000027
[Epoch 1] step 8300 loss 0.1875 lr 0.000028
[Epoch 1] step 8400 loss 0.0848 lr 0.000028
[Epoch 1] step 8500 loss 0.0949 lr 0.000028
[Epoch 1] step 8600 loss 0.0516 lr 0.000029
[Epoch 1] step 8700 loss 0.0513 lr 0.000029
[Epoch 1] step 8800 loss 0.0131 lr 0.000029
[Epoch 1] step 8900 loss 0.0322 lr 0.000030
[Epoch 1] step 9000 loss 0.0577 lr 0.000030
[Epoch 1] step 9100 loss 0.0289 lr 0.000030
[Epoch 1] step 9200 loss 0.0379 lr 0.000031
[Epoch 1] step 9300 loss 0.1216 lr 0.000031
[Epoch 1] step 9400 loss 0.0164 lr 0.000031
[Epoch 1] step 9500 loss 0.0587 lr 0.000032
[Epoch 1] step 9600 loss 0.0525 lr 0.000032
[Epoch 1] step 9700 loss 0.0618 lr 0.000032
[Epoch 1] step 9800 loss 0.0581 lr 0.000033
[Epoch 1] step 9900 loss 0.0642 lr 0.000033
[Validation] global_step 10000 loss 0.2079 accuracy 0.4609
Validation accuracy improved from 0.4258 to 0.4609, Validation loss improved from 0.2227 to 0.2079
[Epoch 1] step 10000 loss 0.0309 lr 0.000033
[Epoch 1] step 10100 loss 0.0689 lr 0.000034
[Epoch 1] step 10200 loss 0.1223 lr 0.000034
[Epoch 1] step 10300 loss 0.0508 lr 0.000034
[Epoch 1] step 10400 loss 0.0493 lr 0.000035
[Epoch 1] step 10500 loss 0.1051 lr 0.000035
[Epoch 1] step 10600 loss 0.0279 lr 0.000035
[Epoch 1] step 10700 loss 0.0311 lr 0.000036
[Epoch 1] step 10800 loss 0.1333 lr 0.000036
[Epoch 1] step 10900 loss 0.0171 lr 0.000036
[Epoch 1] step 11000 loss 0.0932 lr 0.000037
[Epoch 1] step 11100 loss 0.0618 lr 0.000037
[Epoch 1] step 11200 loss 0.0527 lr 0.000037
[Epoch 1] step 11300 loss 0.0437 lr 0.000038
[Epoch 1] step 11400 loss 0.2368 lr 0.000038
[Epoch 1] step 11500 loss 0.0195 lr 0.000038
[Epoch 1] step 11600 loss 0.0337 lr 0.000039
[Epoch 1] step 11700 loss 0.1199 lr 0.000039
[Epoch 1] step 11800 loss 0.0360 lr 0.000039
[Epoch 1] step 11900 loss 0.0218 lr 0.000040
[Epoch 1] step 12000 loss 0.0405 lr 0.000040
[Epoch 1] step 12100 loss 0.0641 lr 0.000040
[Epoch 1] step 12200 loss 0.0103 lr 0.000041
[Epoch 1] step 12300 loss 0.0859 lr 0.000041
[Epoch 1] step 12400 loss 0.0552 lr 0.000041
[Epoch 1] step 12500 loss 0.1974 lr 0.000042
[Epoch 1] step 12600 loss 0.0816 lr 0.000042
[Epoch 1] step 12700 loss 0.0467 lr 0.000042
[Epoch 1] step 12800 loss 0.0195 lr 0.000043
[Epoch 1] step 12900 loss 0.0242 lr 0.000043
[Epoch 1] step 13000 loss 0.0347 lr 0.000043
[Epoch 1] step 13100 loss 0.1124 lr 0.000044
[Epoch 1] step 13200 loss 0.0843 lr 0.000044
[Epoch 1] step 13300 loss 0.1008 lr 0.000044
[Epoch 1] step 13400 loss 0.0696 lr 0.000045
[Epoch 1] step 13500 loss 0.0525 lr 0.000045
[Epoch 1] step 13600 loss 0.1259 lr 0.000045
[Epoch 1] step 13700 loss 0.0507 lr 0.000046
[Epoch 1] step 13800 loss 0.0172 lr 0.000046
[Epoch 1] step 13900 loss 0.0458 lr 0.000046
[Epoch 1] step 14000 loss 0.0484 lr 0.000047
[Epoch 1] step 14100 loss 0.0552 lr 0.000047
[Epoch 1] step 14200 loss 0.0395 lr 0.000047
[Epoch 1] step 14300 loss 0.1243 lr 0.000048
[Epoch 1] step 14400 loss 0.0670 lr 0.000048
[Epoch 1] step 14500 loss 0.0463 lr 0.000048
[Epoch 1] step 14600 loss 0.1881 lr 0.000049
[Epoch 1] step 14700 loss 0.0237 lr 0.000049
[Epoch 1] step 14800 loss 0.0278 lr 0.000049
[Epoch 1] step 14900 loss 0.0418 lr 0.000050
[Validation] global_step 15000 loss 0.2349 accuracy 0.4531
Validation metrics did not improve. Patience: 1/10
Epoch 1 avg loss 0.0843
[Epoch 2] step 0 loss 0.0593 lr 0.000050
[Epoch 2] step 100 loss 0.0435 lr 0.000050
[Epoch 2] step 200 loss 0.0435 lr 0.000050
[Epoch 2] step 300 loss 0.0799 lr 0.000050
[Epoch 2] step 400 loss 0.0239 lr 0.000050
[Epoch 2] step 500 loss 0.0952 lr 0.000050
[Epoch 2] step 600 loss 0.0215 lr 0.000050
[Epoch 2] step 700 loss 0.0113 lr 0.000050
[Epoch 2] step 800 loss 0.0919 lr 0.000050
[Epoch 2] step 900 loss 0.0599 lr 0.000050
[Epoch 2] step 1000 loss 0.1328 lr 0.000050
[Epoch 2] step 1100 loss 0.0709 lr 0.000050
[Epoch 2] step 1200 loss 0.0363 lr 0.000050
[Epoch 2] step 1300 loss 0.0548 lr 0.000050
[Epoch 2] step 1400 loss 0.0904 lr 0.000049
[Epoch 2] step 1500 loss 0.0075 lr 0.000049
[Epoch 2] step 1600 loss 0.0628 lr 0.000049
[Epoch 2] step 1700 loss 0.0886 lr 0.000049
[Epoch 2] step 1800 loss 0.0685 lr 0.000049
[Epoch 2] step 1900 loss 0.0578 lr 0.000049
[Epoch 2] step 2000 loss 0.1443 lr 0.000049
[Epoch 2] step 2100 loss 0.0708 lr 0.000049
[Epoch 2] step 2200 loss 0.0541 lr 0.000049
[Epoch 2] step 2300 loss 0.0322 lr 0.000049
[Epoch 2] step 2400 loss 0.0670 lr 0.000049
[Epoch 2] step 2500 loss 0.0529 lr 0.000049
[Epoch 2] step 2600 loss 0.0858 lr 0.000049
[Epoch 2] step 2700 loss 0.0174 lr 0.000049
[Epoch 2] step 2800 loss 0.0457 lr 0.000049
[Epoch 2] step 2900 loss 0.0351 lr 0.000049
[Epoch 2] step 3000 loss 0.0061 lr 0.000049
[Epoch 2] step 3100 loss 0.0172 lr 0.000049
[Epoch 2] step 3200 loss 0.0893 lr 0.000049
[Epoch 2] step 3300 loss 0.0762 lr 0.000049
[Epoch 2] step 3400 loss 0.0416 lr 0.000049
[Epoch 2] step 3500 loss 0.1071 lr 0.000049
[Epoch 2] step 3600 loss 0.0363 lr 0.000049
[Epoch 2] step 3700 loss 0.0911 lr 0.000049
[Epoch 2] step 3800 loss 0.1123 lr 0.000049
[Epoch 2] step 3900 loss 0.1374 lr 0.000049
[Epoch 2] step 4000 loss 0.1939 lr 0.000049
[Epoch 2] step 4100 loss 0.0528 lr 0.000048
[Epoch 2] step 4200 loss 0.0194 lr 0.000048
[Epoch 2] step 4300 loss 0.0346 lr 0.000048
[Epoch 2] step 4400 loss 0.0608 lr 0.000048
[Epoch 2] step 4500 loss 0.0105 lr 0.000048
[Epoch 2] step 4600 loss 0.0286 lr 0.000048
[Epoch 2] step 4700 loss 0.1225 lr 0.000048
[Epoch 2] step 4800 loss 0.1212 lr 0.000048
[Epoch 2] step 4900 loss 0.0516 lr 0.000048
[Validation] global_step 20000 loss 0.2504 accuracy 0.4414
Validation metrics did not improve. Patience: 2/10
[Epoch 2] step 5000 loss 0.0574 lr 0.000048
[Epoch 2] step 5100 loss 0.0347 lr 0.000048
[Epoch 2] step 5200 loss 0.0536 lr 0.000048
[Epoch 2] step 5300 loss 0.0973 lr 0.000048
[Epoch 2] step 5400 loss 0.1249 lr 0.000048
[Epoch 2] step 5500 loss 0.0446 lr 0.000048
[Epoch 2] step 5600 loss 0.0933 lr 0.000048
[Epoch 2] step 5700 loss 0.0458 lr 0.000048
[Epoch 2] step 5800 loss 0.0316 lr 0.000048
[Epoch 2] step 5900 loss 0.1836 lr 0.000048
[Epoch 2] step 6000 loss 0.0664 lr 0.000048
[Epoch 2] step 6100 loss 0.0701 lr 0.000048
[Epoch 2] step 6200 loss 0.0166 lr 0.000048
[Epoch 2] step 6300 loss 0.0297 lr 0.000048
[Epoch 2] step 6400 loss 0.0888 lr 0.000048
[Epoch 2] step 6500 loss 0.0698 lr 0.000048
[Epoch 2] step 6600 loss 0.0518 lr 0.000048
[Epoch 2] step 6700 loss 0.0624 lr 0.000048
[Epoch 2] step 6800 loss 0.0255 lr 0.000047
[Epoch 2] step 6900 loss 0.0352 lr 0.000047
[Epoch 2] step 7000 loss 0.1143 lr 0.000047
[Epoch 2] step 7100 loss 0.0766 lr 0.000047
[Epoch 2] step 7200 loss 0.0300 lr 0.000047
[Epoch 2] step 7300 loss 0.0864 lr 0.000047
[Epoch 2] step 7400 loss 0.0571 lr 0.000047
[Epoch 2] step 7500 loss 0.0497 lr 0.000047
[Epoch 2] step 7600 loss 0.1092 lr 0.000047
[Epoch 2] step 7700 loss 0.1666 lr 0.000047
[Epoch 2] step 7800 loss 0.0673 lr 0.000047
[Epoch 2] step 7900 loss 0.0716 lr 0.000047
[Epoch 2] step 8000 loss 0.1064 lr 0.000047
[Epoch 2] step 8100 loss 0.0471 lr 0.000047
[Epoch 2] step 8200 loss 0.0534 lr 0.000047
[Epoch 2] step 8300 loss 0.1081 lr 0.000047
[Epoch 2] step 8400 loss 0.0346 lr 0.000047
[Epoch 2] step 8500 loss 0.0179 lr 0.000047
[Epoch 2] step 8600 loss 0.0958 lr 0.000047
[Epoch 2] step 8700 loss 0.0841 lr 0.000047
[Epoch 2] step 8800 loss 0.1303 lr 0.000047
[Epoch 2] step 8900 loss 0.0472 lr 0.000047
[Epoch 2] step 9000 loss 0.0684 lr 0.000047
[Epoch 2] step 9100 loss 0.0496 lr 0.000047
[Epoch 2] step 9200 loss 0.0709 lr 0.000047
[Epoch 2] step 9300 loss 0.0532 lr 0.000047
[Epoch 2] step 9400 loss 0.0718 lr 0.000047
[Epoch 2] step 9500 loss 0.0452 lr 0.000046
[Epoch 2] step 9600 loss 0.0484 lr 0.000046
[Epoch 2] step 9700 loss 0.0880 lr 0.000046
[Epoch 2] step 9800 loss 0.1178 lr 0.000046
[Epoch 2] step 9900 loss 0.1127 lr 0.000046
[Validation] global_step 25000 loss 0.2667 accuracy 0.4219
Validation metrics did not improve. Patience: 3/10
[Epoch 2] step 10000 loss 0.0392 lr 0.000046
[Epoch 2] step 10100 loss 0.0724 lr 0.000046
[Epoch 2] step 10200 loss 0.0736 lr 0.000046
[Epoch 2] step 10300 loss 0.0529 lr 0.000046
[Epoch 2] step 10400 loss 0.0739 lr 0.000046
[Epoch 2] step 10500 loss 0.0082 lr 0.000046
[Epoch 2] step 10600 loss 0.1267 lr 0.000046
[Epoch 2] step 10700 loss 0.0870 lr 0.000046
[Epoch 2] step 10800 loss 0.1353 lr 0.000046
[Epoch 2] step 10900 loss 0.0499 lr 0.000046
[Epoch 2] step 11000 loss 0.0596 lr 0.000046
[Epoch 2] step 11100 loss 0.0266 lr 0.000046
[Epoch 2] step 11200 loss 0.0287 lr 0.000046
[Epoch 2] step 11300 loss 0.0587 lr 0.000046
[Epoch 2] step 11400 loss 0.0336 lr 0.000046
[Epoch 2] step 11500 loss 0.0535 lr 0.000046
[Epoch 2] step 11600 loss 0.0585 lr 0.000046
[Epoch 2] step 11700 loss 0.1203 lr 0.000046
[Epoch 2] step 11800 loss 0.0291 lr 0.000046
[Epoch 2] step 11900 loss 0.0364 lr 0.000046
[Epoch 2] step 12000 loss 0.0261 lr 0.000046
[Epoch 2] step 12100 loss 0.1174 lr 0.000046
[Epoch 2] step 12200 loss 0.0528 lr 0.000045
[Epoch 2] step 12300 loss 0.0465 lr 0.000045
[Epoch 2] step 12400 loss 0.0762 lr 0.000045
[Epoch 2] step 12500 loss 0.0539 lr 0.000045
[Epoch 2] step 12600 loss 0.0760 lr 0.000045
[Epoch 2] step 12700 loss 0.0971 lr 0.000045
[Epoch 2] step 12800 loss 0.0590 lr 0.000045
[Epoch 2] step 12900 loss 0.0865 lr 0.000045
[Epoch 2] step 13000 loss 0.1038 lr 0.000045
[Epoch 2] step 13100 loss 0.0346 lr 0.000045
[Epoch 2] step 13200 loss 0.1232 lr 0.000045
[Epoch 2] step 13300 loss 0.1669 lr 0.000045
[Epoch 2] step 13400 loss 0.0553 lr 0.000045
[Epoch 2] step 13500 loss 0.0694 lr 0.000045
[Epoch 2] step 13600 loss 0.0762 lr 0.000045
[Epoch 2] step 13700 loss 0.0818 lr 0.000045
[Epoch 2] step 13800 loss 0.0285 lr 0.000045
[Epoch 2] step 13900 loss 0.1468 lr 0.000045
[Epoch 2] step 14000 loss 0.0185 lr 0.000045
[Epoch 2] step 14100 loss 0.1518 lr 0.000045
[Epoch 2] step 14200 loss 0.0463 lr 0.000045
[Epoch 2] step 14300 loss 0.0782 lr 0.000045
[Epoch 2] step 14400 loss 0.0700 lr 0.000045
[Epoch 2] step 14500 loss 0.0563 lr 0.000045
[Epoch 2] step 14600 loss 0.0835 lr 0.000045
[Epoch 2] step 14700 loss 0.0762 lr 0.000045
[Epoch 2] step 14800 loss 0.0287 lr 0.000045
[Epoch 2] step 14900 loss 0.1351 lr 0.000044
[Validation] global_step 30000 loss 0.2674 accuracy 0.4453
Validation metrics did not improve. Patience: 4/10
Epoch 2 avg loss 0.0723
[Epoch 3] step 0 loss 0.3108 lr 0.000044
[Epoch 3] step 100 loss 0.0675 lr 0.000044
[Epoch 3] step 200 loss 0.0538 lr 0.000044
[Epoch 3] step 300 loss 0.0519 lr 0.000044
[Epoch 3] step 400 loss 0.1072 lr 0.000044
[Epoch 3] step 500 loss 0.0588 lr 0.000044
[Epoch 3] step 600 loss 0.0544 lr 0.000044
[Epoch 3] step 700 loss 0.1373 lr 0.000044
[Epoch 3] step 800 loss 0.0525 lr 0.000044
[Epoch 3] step 900 loss 0.1154 lr 0.000044
[Epoch 3] step 1000 loss 0.0736 lr 0.000044
[Epoch 3] step 1100 loss 0.0347 lr 0.000044
[Epoch 3] step 1200 loss 0.0940 lr 0.000044
[Epoch 3] step 1300 loss 0.0354 lr 0.000044
[Epoch 3] step 1400 loss 0.0253 lr 0.000044
[Epoch 3] step 1500 loss 0.0901 lr 0.000044
[Epoch 3] step 1600 loss 0.1030 lr 0.000044
[Epoch 3] step 1700 loss 0.0714 lr 0.000044
[Epoch 3] step 1800 loss 0.0786 lr 0.000044
[Epoch 3] step 1900 loss 0.0348 lr 0.000044
[Epoch 3] step 2000 loss 0.0515 lr 0.000044
[Epoch 3] step 2100 loss 0.0431 lr 0.000044
[Epoch 3] step 2200 loss 0.0574 lr 0.000044
[Epoch 3] step 2300 loss 0.0516 lr 0.000044
[Epoch 3] step 2400 loss 0.0706 lr 0.000044
[Epoch 3] step 2500 loss 0.0689 lr 0.000044
[Epoch 3] step 2600 loss 0.0253 lr 0.000043
[Epoch 3] step 2700 loss 0.0525 lr 0.000043
[Epoch 3] step 2800 loss 0.0172 lr 0.000043
[Epoch 3] step 2900 loss 0.0564 lr 0.000043
[Epoch 3] step 3000 loss 0.0141 lr 0.000043
[Epoch 3] step 3100 loss 0.0417 lr 0.000043
[Epoch 3] step 3200 loss 0.0442 lr 0.000043
[Epoch 3] step 3300 loss 0.1442 lr 0.000043
[Epoch 3] step 3400 loss 0.0254 lr 0.000043
[Epoch 3] step 3500 loss 0.0622 lr 0.000043
[Epoch 3] step 3600 loss 0.0769 lr 0.000043
[Epoch 3] step 3700 loss 0.0705 lr 0.000043
[Epoch 3] step 3800 loss 0.0895 lr 0.000043
[Epoch 3] step 3900 loss 0.0365 lr 0.000043
[Epoch 3] step 4000 loss 0.0275 lr 0.000043
[Epoch 3] step 4100 loss 0.0130 lr 0.000043
[Epoch 3] step 4200 loss 0.0291 lr 0.000043
[Epoch 3] step 4300 loss 0.0539 lr 0.000043
[Epoch 3] step 4400 loss 0.0942 lr 0.000043
[Epoch 3] step 4500 loss 0.0392 lr 0.000043
[Epoch 3] step 4600 loss 0.0215 lr 0.000043
[Epoch 3] step 4700 loss 0.0668 lr 0.000043
[Epoch 3] step 4800 loss 0.0204 lr 0.000043
[Epoch 3] step 4900 loss 0.0446 lr 0.000043
[Validation] global_step 35000 loss 0.2842 accuracy 0.4062
Validation metrics did not improve. Patience: 5/10
[Epoch 3] step 5000 loss 0.0490 lr 0.000043
[Epoch 3] step 5100 loss 0.0408 lr 0.000043
[Epoch 3] step 5200 loss 0.0164 lr 0.000043
[Epoch 3] step 5300 loss 0.0271 lr 0.000042
[Epoch 3] step 5400 loss 0.2381 lr 0.000042
[Epoch 3] step 5500 loss 0.0215 lr 0.000042
[Epoch 3] step 5600 loss 0.0460 lr 0.000042
[Epoch 3] step 5700 loss 0.0579 lr 0.000042
[Epoch 3] step 5800 loss 0.1094 lr 0.000042
[Epoch 3] step 5900 loss 0.1519 lr 0.000042
[Epoch 3] step 6000 loss 0.0431 lr 0.000042
[Epoch 3] step 6100 loss 0.0208 lr 0.000042
[Epoch 3] step 6200 loss 0.0659 lr 0.000042
[Epoch 3] step 6300 loss 0.0527 lr 0.000042
[Epoch 3] step 6400 loss 0.1923 lr 0.000042
[Epoch 3] step 6500 loss 0.1738 lr 0.000042
[Epoch 3] step 6600 loss 0.0956 lr 0.000042
[Epoch 3] step 6700 loss 0.0183 lr 0.000042
[Epoch 3] step 6800 loss 0.1124 lr 0.000042
[Epoch 3] step 6900 loss 0.0365 lr 0.000042
[Epoch 3] step 7000 loss 0.0793 lr 0.000042
[Epoch 3] step 7100 loss 0.0737 lr 0.000042
[Epoch 3] step 7200 loss 0.0157 lr 0.000042
[Epoch 3] step 7300 loss 0.1086 lr 0.000042
[Epoch 3] step 7400 loss 0.0534 lr 0.000042
[Epoch 3] step 7500 loss 0.0675 lr 0.000042
[Epoch 3] step 7600 loss 0.0896 lr 0.000042
[Epoch 3] step 7700 loss 0.1161 lr 0.000042
[Epoch 3] step 7800 loss 0.0671 lr 0.000042
[Epoch 3] step 7900 loss 0.2975 lr 0.000042
[Epoch 3] step 8000 loss 0.0562 lr 0.000041
[Epoch 3] step 8100 loss 0.1850 lr 0.000041
[Epoch 3] step 8200 loss 0.0725 lr 0.000041
[Epoch 3] step 8300 loss 0.0420 lr 0.000041
[Epoch 3] step 8400 loss 0.3886 lr 0.000041
[Epoch 3] step 8500 loss 0.0285 lr 0.000041
[Epoch 3] step 8600 loss 0.0650 lr 0.000041
[Epoch 3] step 8700 loss 0.0199 lr 0.000041
[Epoch 3] step 8800 loss 0.1082 lr 0.000041
[Epoch 3] step 8900 loss 0.0463 lr 0.000041
[Epoch 3] step 9000 loss 0.0894 lr 0.000041
[Epoch 3] step 9100 loss 0.0675 lr 0.000041
[Epoch 3] step 9200 loss 0.0655 lr 0.000041
[Epoch 3] step 9300 loss 0.0525 lr 0.000041
[Epoch 3] step 9400 loss 0.0704 lr 0.000041
[Epoch 3] step 9500 loss 0.0616 lr 0.000041
[Epoch 3] step 9600 loss 0.0462 lr 0.000041
[Epoch 3] step 9700 loss 0.0751 lr 0.000041
[Epoch 3] step 9800 loss 0.0340 lr 0.000041
[Epoch 3] step 9900 loss 0.0511 lr 0.000041
[Validation] global_step 40000 loss 0.2562 accuracy 0.4688
Validation accuracy improved from 0.4609 to 0.4688
[Epoch 3] step 10000 loss 0.0462 lr 0.000041
[Epoch 3] step 10100 loss 0.0780 lr 0.000041
[Epoch 3] step 10200 loss 0.0781 lr 0.000041
[Epoch 3] step 10300 loss 0.0809 lr 0.000041
[Epoch 3] step 10400 loss 0.1383 lr 0.000041
[Epoch 3] step 10500 loss 0.0466 lr 0.000041
[Epoch 3] step 10600 loss 0.0421 lr 0.000041
[Epoch 3] step 10700 loss 0.0417 lr 0.000040
[Epoch 3] step 10800 loss 0.0743 lr 0.000040
[Epoch 3] step 10900 loss 0.1755 lr 0.000040
[Epoch 3] step 11000 loss 0.0754 lr 0.000040
[Epoch 3] step 11100 loss 0.0390 lr 0.000040
[Epoch 3] step 11200 loss 0.0382 lr 0.000040
[Epoch 3] step 11300 loss 0.0506 lr 0.000040
[Epoch 3] step 11400 loss 0.0346 lr 0.000040
[Epoch 3] step 11500 loss 0.0746 lr 0.000040
[Epoch 3] step 11600 loss 0.0733 lr 0.000040
[Epoch 3] step 11700 loss 0.1917 lr 0.000040
[Epoch 3] step 11800 loss 0.0894 lr 0.000040
[Epoch 3] step 11900 loss 0.0470 lr 0.000040
[Epoch 3] step 12000 loss 0.2094 lr 0.000040
[Epoch 3] step 12100 loss 0.0526 lr 0.000040
[Epoch 3] step 12200 loss 0.0886 lr 0.000040
[Epoch 3] step 12300 loss 0.0811 lr 0.000040
[Epoch 3] step 12400 loss 0.0677 lr 0.000040
[Epoch 3] step 12500 loss 0.0891 lr 0.000040
[Epoch 3] step 12600 loss 0.0285 lr 0.000040
[Epoch 3] step 12700 loss 0.0292 lr 0.000040
[Epoch 3] step 12800 loss 0.0390 lr 0.000040
[Epoch 3] step 12900 loss 0.0623 lr 0.000040
[Epoch 3] step 13000 loss 0.0850 lr 0.000040
[Epoch 3] step 13100 loss 0.0726 lr 0.000040
[Epoch 3] step 13200 loss 0.0194 lr 0.000040
[Epoch 3] step 13300 loss 0.0419 lr 0.000040
[Epoch 3] step 13400 loss 0.0680 lr 0.000039
[Epoch 3] step 13500 loss 0.0600 lr 0.000039
[Epoch 3] step 13600 loss 0.0725 lr 0.000039
[Epoch 3] step 13700 loss 0.2828 lr 0.000039
[Epoch 3] step 13800 loss 0.0258 lr 0.000039
[Epoch 3] step 13900 loss 0.0927 lr 0.000039
[Epoch 3] step 14000 loss 0.0534 lr 0.000039
[Epoch 3] step 14100 loss 0.0809 lr 0.000039
[Epoch 3] step 14200 loss 0.1642 lr 0.000039
[Epoch 3] step 14300 loss 0.1142 lr 0.000039
[Epoch 3] step 14400 loss 0.0478 lr 0.000039
[Epoch 3] step 14500 loss 0.1261 lr 0.000039
[Epoch 3] step 14600 loss 0.0438 lr 0.000039
[Epoch 3] step 14700 loss 0.0413 lr 0.000039
[Epoch 3] step 14800 loss 0.0831 lr 0.000039
[Epoch 3] step 14900 loss 0.1000 lr 0.000039
[Validation] global_step 45000 loss 0.2344 accuracy 0.4531
Validation metrics did not improve. Patience: 1/10
Epoch 3 avg loss 0.0723
[Epoch 4] step 0 loss 0.0635 lr 0.000039
[Epoch 4] step 100 loss 0.0717 lr 0.000039
[Epoch 4] step 200 loss 0.0755 lr 0.000039
[Epoch 4] step 300 loss 0.0712 lr 0.000039
[Epoch 4] step 400 loss 0.0997 lr 0.000039
[Epoch 4] step 500 loss 0.0273 lr 0.000039
[Epoch 4] step 600 loss 0.0441 lr 0.000039
[Epoch 4] step 700 loss 0.0458 lr 0.000039
[Epoch 4] step 800 loss 0.1072 lr 0.000039
[Epoch 4] step 900 loss 0.0577 lr 0.000039
[Epoch 4] step 1000 loss 0.0481 lr 0.000039
[Epoch 4] step 1100 loss 0.0643 lr 0.000038
[Epoch 4] step 1200 loss 0.0283 lr 0.000038
[Epoch 4] step 1300 loss 0.0699 lr 0.000038
[Epoch 4] step 1400 loss 0.0891 lr 0.000038
[Epoch 4] step 1500 loss 0.1107 lr 0.000038
[Epoch 4] step 1600 loss 0.0723 lr 0.000038
[Epoch 4] step 1700 loss 0.0510 lr 0.000038
[Epoch 4] step 1800 loss 0.0849 lr 0.000038
[Epoch 4] step 1900 loss 0.0401 lr 0.000038
[Epoch 4] step 2000 loss 0.1574 lr 0.000038
[Epoch 4] step 2100 loss 0.0529 lr 0.000038
[Epoch 4] step 2200 loss 0.0216 lr 0.000038
[Epoch 4] step 2300 loss 0.1791 lr 0.000038
[Epoch 4] step 2400 loss 0.0344 lr 0.000038
[Epoch 4] step 2500 loss 0.0463 lr 0.000038
[Epoch 4] step 2600 loss 0.0300 lr 0.000038
[Epoch 4] step 2700 loss 0.0778 lr 0.000038
[Epoch 4] step 2800 loss 0.1110 lr 0.000038
[Epoch 4] step 2900 loss 0.0972 lr 0.000038
[Epoch 4] step 3000 loss 0.0422 lr 0.000038
[Epoch 4] step 3100 loss 0.0278 lr 0.000038
[Epoch 4] step 3200 loss 0.0375 lr 0.000038
[Epoch 4] step 3300 loss 0.0435 lr 0.000038
[Epoch 4] step 3400 loss 0.0800 lr 0.000038
[Epoch 4] step 3500 loss 0.0459 lr 0.000038
[Epoch 4] step 3600 loss 0.0957 lr 0.000038
[Epoch 4] step 3700 loss 0.0821 lr 0.000038
[Epoch 4] step 3800 loss 0.0500 lr 0.000037
[Epoch 4] step 3900 loss 0.0555 lr 0.000037
[Epoch 4] step 4000 loss 0.0994 lr 0.000037
[Epoch 4] step 4100 loss 0.3105 lr 0.000037
[Epoch 4] step 4200 loss 0.0663 lr 0.000037
[Epoch 4] step 4300 loss 0.0662 lr 0.000037
[Epoch 4] step 4400 loss 0.0461 lr 0.000037
[Epoch 4] step 4500 loss 0.0651 lr 0.000037
[Epoch 4] step 4600 loss 0.0237 lr 0.000037
[Epoch 4] step 4700 loss 0.0757 lr 0.000037
[Epoch 4] step 4800 loss 0.0570 lr 0.000037
[Epoch 4] step 4900 loss 0.0404 lr 0.000037
[Validation] global_step 50000 loss 0.2493 accuracy 0.4883
Validation accuracy improved from 0.4688 to 0.4883
[Epoch 4] step 5000 loss 0.0163 lr 0.000037
[Epoch 4] step 5100 loss 0.0351 lr 0.000037
[Epoch 4] step 5200 loss 0.0716 lr 0.000037
[Epoch 4] step 5300 loss 0.0212 lr 0.000037
[Epoch 4] step 5400 loss 0.0316 lr 0.000037
[Epoch 4] step 5500 loss 0.0565 lr 0.000037
[Epoch 4] step 5600 loss 0.0240 lr 0.000037
[Epoch 4] step 5700 loss 0.1165 lr 0.000037
[Epoch 4] step 5800 loss 0.0285 lr 0.000037
[Epoch 4] step 5900 loss 0.0609 lr 0.000037
[Epoch 4] step 6000 loss 0.0400 lr 0.000037
[Epoch 4] step 6100 loss 0.0431 lr 0.000037
[Epoch 4] step 6200 loss 0.0740 lr 0.000037
[Epoch 4] step 6300 loss 0.0729 lr 0.000037
[Epoch 4] step 6400 loss 0.1553 lr 0.000037
[Epoch 4] step 6500 loss 0.0253 lr 0.000036
[Epoch 4] step 6600 loss 0.0479 lr 0.000036
[Epoch 4] step 6700 loss 0.1715 lr 0.000036
[Epoch 4] step 6800 loss 0.0457 lr 0.000036
[Epoch 4] step 6900 loss 0.0351 lr 0.000036
[Epoch 4] step 7000 loss 0.0887 lr 0.000036
[Epoch 4] step 7100 loss 0.1162 lr 0.000036
[Epoch 4] step 7200 loss 0.0367 lr 0.000036
[Epoch 4] step 7300 loss 0.0366 lr 0.000036
[Epoch 4] step 7400 loss 0.0152 lr 0.000036
[Epoch 4] step 7500 loss 0.0694 lr 0.000036
[Epoch 4] step 7600 loss 0.0564 lr 0.000036
[Epoch 4] step 7700 loss 0.1138 lr 0.000036
[Epoch 4] step 7800 loss 0.0423 lr 0.000036
[Epoch 4] step 7900 loss 0.0680 lr 0.000036
[Epoch 4] step 8000 loss 0.0674 lr 0.000036
[Epoch 4] step 8100 loss 0.0043 lr 0.000036
[Epoch 4] step 8200 loss 0.0916 lr 0.000036
[Epoch 4] step 8300 loss 0.0270 lr 0.000036
[Epoch 4] step 8400 loss 0.1437 lr 0.000036
[Epoch 4] step 8500 loss 0.0956 lr 0.000036
[Epoch 4] step 8600 loss 0.0384 lr 0.000036
[Epoch 4] step 8700 loss 0.0423 lr 0.000036
[Epoch 4] step 8800 loss 0.0787 lr 0.000036
[Epoch 4] step 8900 loss 0.0391 lr 0.000036
[Epoch 4] step 9000 loss 0.0616 lr 0.000036
[Epoch 4] step 9100 loss 0.0317 lr 0.000036
[Epoch 4] step 9200 loss 0.1987 lr 0.000035
[Epoch 4] step 9300 loss 0.1679 lr 0.000035
[Epoch 4] step 9400 loss 0.0157 lr 0.000035
[Epoch 4] step 9500 loss 0.0390 lr 0.000035
[Epoch 4] step 9600 loss 0.0391 lr 0.000035
[Epoch 4] step 9700 loss 0.1249 lr 0.000035
[Epoch 4] step 9800 loss 0.0535 lr 0.000035
[Epoch 4] step 9900 loss 0.0808 lr 0.000035
[Validation] global_step 55000 loss 0.2658 accuracy 0.4414
Validation metrics did not improve. Patience: 1/10
[Epoch 4] step 10000 loss 0.0506 lr 0.000035
[Epoch 4] step 10100 loss 0.0583 lr 0.000035
[Epoch 4] step 10200 loss 0.1055 lr 0.000035
[Epoch 4] step 10300 loss 0.0570 lr 0.000035
[Epoch 4] step 10400 loss 0.0616 lr 0.000035
[Epoch 4] step 10500 loss 0.0517 lr 0.000035
[Epoch 4] step 10600 loss 0.0776 lr 0.000035
[Epoch 4] step 10700 loss 0.0372 lr 0.000035
[Epoch 4] step 10800 loss 0.0490 lr 0.000035
[Epoch 4] step 10900 loss 0.2103 lr 0.000035
[Epoch 4] step 11000 loss 0.0682 lr 0.000035
[Epoch 4] step 11100 loss 0.0266 lr 0.000035
[Epoch 4] step 11200 loss 0.0461 lr 0.000035
[Epoch 4] step 11300 loss 0.0672 lr 0.000035
[Epoch 4] step 11400 loss 0.0631 lr 0.000035
[Epoch 4] step 11500 loss 0.0402 lr 0.000035
[Epoch 4] step 11600 loss 0.0626 lr 0.000035
[Epoch 4] step 11700 loss 0.0842 lr 0.000035
[Epoch 4] step 11800 loss 0.0384 lr 0.000035
[Epoch 4] step 11900 loss 0.0637 lr 0.000034
[Epoch 4] step 12000 loss 0.0586 lr 0.000034
[Epoch 4] step 12100 loss 0.0331 lr 0.000034
[Epoch 4] step 12200 loss 0.0636 lr 0.000034
[Epoch 4] step 12300 loss 0.0243 lr 0.000034
[Epoch 4] step 12400 loss 0.0271 lr 0.000034
[Epoch 4] step 12500 loss 0.0625 lr 0.000034
[Epoch 4] step 12600 loss 0.0256 lr 0.000034
[Epoch 4] step 12700 loss 0.0170 lr 0.000034
[Epoch 4] step 12800 loss 0.0268 lr 0.000034
[Epoch 4] step 12900 loss 0.0598 lr 0.000034
[Epoch 4] step 13000 loss 0.0337 lr 0.000034
[Epoch 4] step 13100 loss 0.0244 lr 0.000034
[Epoch 4] step 13200 loss 0.0431 lr 0.000034
[Epoch 4] step 13300 loss 0.0189 lr 0.000034
[Epoch 4] step 13400 loss 0.0917 lr 0.000034
[Epoch 4] step 13500 loss 0.0305 lr 0.000034
[Epoch 4] step 13600 loss 0.0367 lr 0.000034
[Epoch 4] step 13700 loss 0.0272 lr 0.000034
[Epoch 4] step 13800 loss 0.0694 lr 0.000034
[Epoch 4] step 13900 loss 0.1164 lr 0.000034
[Epoch 4] step 14000 loss 0.0284 lr 0.000034
[Epoch 4] step 14100 loss 0.0411 lr 0.000034
[Epoch 4] step 14200 loss 0.0825 lr 0.000034
[Epoch 4] step 14300 loss 0.0851 lr 0.000034
[Epoch 4] step 14400 loss 0.0944 lr 0.000034
[Epoch 4] step 14500 loss 0.0257 lr 0.000034
[Epoch 4] step 14600 loss 0.0819 lr 0.000033
[Epoch 4] step 14700 loss 0.0283 lr 0.000033
[Epoch 4] step 14800 loss 0.0469 lr 0.000033
[Epoch 4] step 14900 loss 0.0848 lr 0.000033
[Validation] global_step 60000 loss 0.2692 accuracy 0.4922
Validation accuracy improved from 0.4883 to 0.4922
Epoch 4 avg loss 0.0702
[Epoch 5] step 0 loss 0.2166 lr 0.000033
[Epoch 5] step 100 loss 0.1129 lr 0.000033
[Epoch 5] step 200 loss 0.0678 lr 0.000033
[Epoch 5] step 300 loss 0.0615 lr 0.000033
[Epoch 5] step 400 loss 0.0434 lr 0.000033
[Epoch 5] step 500 loss 0.0752 lr 0.000033
[Epoch 5] step 600 loss 0.0452 lr 0.000033
[Epoch 5] step 700 loss 0.0597 lr 0.000033
[Epoch 5] step 800 loss 0.0553 lr 0.000033
[Epoch 5] step 900 loss 0.0750 lr 0.000033
[Epoch 5] step 1000 loss 0.0285 lr 0.000033
[Epoch 5] step 1100 loss 0.0225 lr 0.000033
[Epoch 5] step 1200 loss 0.0935 lr 0.000033
[Epoch 5] step 1300 loss 0.0348 lr 0.000033
[Epoch 5] step 1400 loss 0.0512 lr 0.000033
[Epoch 5] step 1500 loss 0.0286 lr 0.000033
[Epoch 5] step 1600 loss 0.0413 lr 0.000033
[Epoch 5] step 1700 loss 0.0530 lr 0.000033
[Epoch 5] step 1800 loss 0.0590 lr 0.000033
[Epoch 5] step 1900 loss 0.0719 lr 0.000033
[Epoch 5] step 2000 loss 0.1237 lr 0.000033
[Epoch 5] step 2100 loss 0.1099 lr 0.000033
[Epoch 5] step 2200 loss 0.1693 lr 0.000033
[Epoch 5] step 2300 loss 0.1132 lr 0.000032
[Epoch 5] step 2400 loss 0.0305 lr 0.000032
[Epoch 5] step 2500 loss 0.0883 lr 0.000032
[Epoch 5] step 2600 loss 0.0695 lr 0.000032
[Epoch 5] step 2700 loss 0.0752 lr 0.000032
[Epoch 5] step 2800 loss 0.1078 lr 0.000032
[Epoch 5] step 2900 loss 0.0726 lr 0.000032
[Epoch 5] step 3000 loss 0.1397 lr 0.000032
[Epoch 5] step 3100 loss 0.1467 lr 0.000032
[Epoch 5] step 3200 loss 0.2320 lr 0.000032
[Epoch 5] step 3300 loss 0.2578 lr 0.000032
[Epoch 5] step 3400 loss 0.3229 lr 0.000032
[Epoch 5] step 3500 loss 0.3303 lr 0.000032
[Epoch 5] step 3600 loss 0.4147 lr 0.000032
[Epoch 5] step 3700 loss nan lr 0.000032
[Epoch 5] step 3800 loss nan lr 0.000032
[Epoch 5] step 3900 loss nan lr 0.000032
[Epoch 5] step 4000 loss nan lr 0.000032
[Epoch 5] step 4100 loss nan lr 0.000032
[Epoch 5] step 4200 loss nan lr 0.000032
[Epoch 5] step 4300 loss nan lr 0.000032
[Epoch 5] step 4400 loss nan lr 0.000032
[Epoch 5] step 4500 loss nan lr 0.000032
[Epoch 5] step 4600 loss nan lr 0.000032
[Epoch 5] step 4700 loss nan lr 0.000032
[Epoch 5] step 4800 loss nan lr 0.000032
[Epoch 5] step 4900 loss nan lr 0.000032
